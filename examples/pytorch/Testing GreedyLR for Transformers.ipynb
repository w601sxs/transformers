{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109ba453-d065-4aa3-ab70-a054b49a28d0",
   "metadata": {},
   "source": [
    "# Testing ⏭ GreedLR Scheduler for 🤗 Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4360d05-6e8a-4951-a611-7b4b345a71b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ff579-2386-4114-b011-92c064f6f2ee",
   "metadata": {},
   "source": [
    "### Need to reinstall from source to register changes\n",
    "\n",
    "(may need to restart kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b0058d-4f24-43e4-af9d-510a5f02247d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: accelerate>=0.12.0 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 1)) (0.17.1)\n",
      "Requirement already satisfied: datasets>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 3)) (0.1.97)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 4)) (3.20.3)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: py7zr in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 6)) (0.20.4)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (5.6.7)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.5)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.8.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.13.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2023.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (6.0.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.70.14)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (4.9.2)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (2022.10.31)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3->-r translation/requirements.txt (line 7)) (65.7.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3->-r translation/requirements.txt (line 7)) (0.40.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.13.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.8)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.15.4)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (3.17)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.2.3)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.6.7)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Obtaining file:///root/transformers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (1.21.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (2022.10.31)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (23.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (0.13.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (0.13.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (2.28.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev1) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.27.0.dev1) (3.15.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2.8)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.0.dev1\n",
      "    Uninstalling transformers-4.27.0.dev1:\n",
      "      Successfully uninstalled transformers-4.27.0.dev1\n",
      "  Running setup.py develop for transformers\n",
      "Successfully installed transformers\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r translation/requirements.txt\n",
    "%pip install -e ~/transformers/ #Or wherever you downloaded this source "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea6e78-81cf-414a-a3d4-0a25fe776125",
   "metadata": {},
   "source": [
    "Add test folders to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2dee55-2640-4b77-a261-b81d634e8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "SRC_DIRS = [\n",
    "    os.path.join('./', dirname) for dirname in [\n",
    "        \"text-generation\",\n",
    "        \"text-classification\",\n",
    "        \"token-classification\",\n",
    "        \"language-modeling\",\n",
    "        \"multiple-choice\",\n",
    "        \"question-answering\",\n",
    "        \"summarization\",\n",
    "        \"translation\",\n",
    "        \"image-classification\",\n",
    "        \"speech-recognition\",\n",
    "        \"audio-classification\",\n",
    "        \"speech-pretraining\",\n",
    "        \"image-pretraining\",\n",
    "        \"semantic-segmentation\",\n",
    "    ]\n",
    "]\n",
    "sys.path.extend(SRC_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c394a69-2fa5-4b3a-928b-ea8c8d7e5bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation import run_translation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b803785-a826-44cc-808f-ae4e7c53ab73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a8cb0-9242-4b31-a495-3a68de2dde60",
   "metadata": {},
   "source": [
    "### Default AdamW_HF with LambdaLR (linear, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b193adaa-5083-48cb-993e-2c753f4f447a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10/2023 14:57:27 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "04/10/2023 14:57:27 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp0pqt2l0x/runs/Apr10_14-57-27_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_warmup,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp0pqt2l0x,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp0pqt2l0x,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "04/10/2023 14:57:28 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/opus100/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704\n",
      "04/10/2023 14:57:28 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "04/10/2023 14:57:28 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704\n",
      "04/10/2023 14:57:28 - WARNING - datasets.builder - Found cached dataset opus100 (/root/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704)\n",
      "04/10/2023 14:57:28 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0ad961c0db4ae09e0c51a09ac289f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-04-10 14:57:28,591 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-10 14:57:28,603 >> Model config BlenderbotSmallConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot_small-90M\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotSmallForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 8,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 8,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"xlm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot-small\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 54944\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:668] 2023-04-10 14:57:28,642 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-10 14:57:28,643 >> Model config BlenderbotSmallConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot_small-90M\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotSmallForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 8,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 8,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"xlm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot-small\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 54944\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:57:28,662 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:57:28,662 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:57:28,663 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:57:28,663 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:57:28,664 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/special_tokens_map.json\n",
      "[INFO|configuration_utils.py:668] 2023-04-10 14:57:28,667 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-10 14:57:28,669 >> Model config BlenderbotSmallConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot_small-90M\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotSmallForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 8,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 8,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"xlm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot-small\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 54944\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-04-10 14:57:28,765 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-04-10 14:57:28,923 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 20,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 10,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-04-10 14:57:29,796 >> All model checkpoint weights were used when initializing BlenderbotSmallForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-04-10 14:57:29,797 >> All the weights of BlenderbotSmallForConditionalGeneration were initialized from the model checkpoint at facebook/blenderbot_small-90M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BlenderbotSmallForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-04-10 14:57:29,841 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-04-10 14:57:29,842 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 20,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 10,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10/2023 14:57:31 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704/cache-5159bf82c4e89f14.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-04-10 14:57:33,105 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-04-10 14:57:33,115 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-04-10 14:57:33,116 >>   Num examples = 1000000\n",
      "[INFO|trainer.py:1760] 2023-04-10 14:57:33,116 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-04-10 14:57:33,117 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1762] 2023-04-10 14:57:33,118 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1763] 2023-04-10 14:57:33,119 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-04-10 14:57:33,119 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-04-10 14:57:33,120 >>   Number of trainable parameters = 87508992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='768' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 768/1000 00:47 < 00:14, 16.03 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.638200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.347400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.984200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.653800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.229300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.887400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.235400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.824100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.950500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.929700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.439900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.135200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.898100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.621100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.180600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.747400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.666500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.440600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.269700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.226700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.933100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.772400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.181200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.867400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.159900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.896200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.939400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.383200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.560100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.779400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.133700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.283800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.529900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.648300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>5.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.514300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.185100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.869600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>5.077300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>5.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.472300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.361900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.881000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>5.067900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.598800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>4.455000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>5.307800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.807400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>4.959800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.660700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.716700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>4.987800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.998300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.422300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-92d4cebfc802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"argv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mrun_translation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# print(result[\"eval_bleu\"]>30)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/examples/pytorch/translation/run_translation.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlast_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;31m# trainer.save_model()  # Saves the tokenizer too for easy upload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m         )\n\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1916\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                 if (\n",
      "\u001b[0;32m~/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2665\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m         )\n\u001b[1;32m   1320\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         )\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue."
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path facebook/blenderbot_small-90M\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name opus100\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ca578d-b857-4b0f-9973-77ca99913e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/tmp0pqt2l0x/trainer_state.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5772e8bd3261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0malllogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{tmp_dir}/trainer_state.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malllogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/tmp0pqt2l0x/trainer_state.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7667a-875f-410b-89a7-8c9207fcc745",
   "metadata": {},
   "source": [
    "### With GreedyLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195b9170-1e41-441c-b2d1-e6799ab74db0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10/2023 14:58:55 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "04/10/2023 14:58:55 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmplhpunqm1/runs/Apr10_14-58-55_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=greedy,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=1e-05,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmplhpunqm1,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmplhpunqm1,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "04/10/2023 14:58:56 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/opus100/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704\n",
      "04/10/2023 14:58:56 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "04/10/2023 14:58:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704\n",
      "04/10/2023 14:58:56 - WARNING - datasets.builder - Found cached dataset opus100 (/root/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704)\n",
      "04/10/2023 14:58:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6851a97d2e5e4b87a7d456738b25a96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-04-10 14:58:56,465 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-10 14:58:56,477 >> Model config BlenderbotSmallConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot_small-90M\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotSmallForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 8,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 8,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"xlm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot-small\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 54944\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:668] 2023-04-10 14:58:56,514 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-10 14:58:56,515 >> Model config BlenderbotSmallConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot_small-90M\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotSmallForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 8,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 8,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"xlm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot-small\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 54944\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:58:56,534 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:58:56,535 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:58:56,535 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:58:56,536 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-04-10 14:58:56,536 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/special_tokens_map.json\n",
      "[INFO|configuration_utils.py:668] 2023-04-10 14:58:56,540 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-04-10 14:58:56,542 >> Model config BlenderbotSmallConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot_small-90M\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotSmallForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 8,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 8,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"xlm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot-small\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 54944\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-04-10 14:58:56,638 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-04-10 14:58:56,795 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 20,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 10,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-04-10 14:58:57,698 >> All model checkpoint weights were used when initializing BlenderbotSmallForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-04-10 14:58:57,700 >> All the weights of BlenderbotSmallForConditionalGeneration were initialized from the model checkpoint at facebook/blenderbot_small-90M.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BlenderbotSmallForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-04-10 14:58:57,744 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot_small-90M/snapshots/22edc296c6a0ff86e422c6726a3d0409bc12c6c8/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-04-10 14:58:57,745 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"min_length\": 20,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 10,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/10/2023 14:58:58 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/opus100/de-en/0.0.0/256f3196b69901fb0c79810ef468e2c4ed84fbd563719920b1ff1fdc750f7704/cache-5159bf82c4e89f14.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-04-10 14:59:01,018 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-04-10 14:59:01,028 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-04-10 14:59:01,029 >>   Num examples = 1000000\n",
      "[INFO|trainer.py:1760] 2023-04-10 14:59:01,029 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-04-10 14:59:01,030 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1762] 2023-04-10 14:59:01,030 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1763] 2023-04-10 14:59:01,031 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-04-10 14:59:01,031 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-04-10 14:59:01,033 >>   Number of trainable parameters = 87508992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreedyLR settings: patience=10 smooth=True min_lr=1e-05 factor=0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='767' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 767/1000 00:49 < 00:14, 15.61 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.134500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.638300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.347600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.984500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.654100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.229800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.888100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.236200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.186600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.825900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.933300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.139500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.903800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.627800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.188800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.756300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.675100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.448100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.157700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.284300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.394200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.038300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.891300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.246100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.794300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.381100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.894900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.189700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.931200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.283000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.879800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.603000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.823800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.179100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.264400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.570400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.696100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>5.150600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.657400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.573800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.234500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.925400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.871300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>5.131100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>5.158300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.535000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.943700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>5.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.665500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>4.532400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.786500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>5.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.889900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>5.042800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.737700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.800400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.063100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>5.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.510900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7ba34d343549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"argv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mrun_translation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# print(result[\"eval_bleu\"]>30)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/examples/pytorch/translation/run_translation.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlast_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;31m# trainer.save_model()  # Saves the tokenizer too for easy upload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m         )\n\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1916\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m                 if (\n",
      "\u001b[0;32m~/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2665\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2667\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1318\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1319\u001b[0m         )\n\u001b[1;32m   1320\u001b[0m         \u001b[0mlm_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_logits_bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         )\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpositions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: philox_cuda_state for an unexpected CUDA generator used during capture. In regions captured by CUDA graphs, you may only use the default CUDA RNG generator on the device that's current when capture begins. If you need a non-default (user-supplied) generator, or a generator on another device, please file an issue."
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path facebook/blenderbot_small-90M\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name opus100\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca37c9e-a80a-40e8-982f-319a088edad5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/tmpzmfucr9a/trainer_state.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a5ede6a830ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0malllogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{tmp_dir}/trainer_state.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malllogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_history'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -r {tmp_dir}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/tmpzmfucr9a/trainer_state.json'"
     ]
    }
   ],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d4f6b-5eda-4e06-89c4-1d608d2e886e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696dc61a-178f-4213-98c9-130d03d5b38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafae40a-f887-47ab-8f5e-1948128b8d72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-',label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-',label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c195ead-5cf7-46ac-899b-02bf7b4c75ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c77c7e-75eb-4946-8fa9-1665c89e96ca",
   "metadata": {},
   "source": [
    "## 2. Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "350de744-e910-4bd1-86f8-b4e388d58a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_qa as run_squad\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e736f06-d6e3-46af-a6e4-317ff5623090",
   "metadata": {},
   "source": [
    "### Default ADAMHF / Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "b8317c07-cd7b-4130-a7ca-af5448577575",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-24 18:01:41,866 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-24 18:01:41,867 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/24/2023 18:01:41 - WARNING - run_qa - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/24/2023 18:01:41 - INFO - run_qa - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpv8t6xa56/runs/Mar24_18-01-41_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_warmup,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=5000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpv8t6xa56,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpv8t6xa56,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/24/2023 18:01:42 - INFO - datasets.builder - No config specified, defaulting to the single config: squad/plain_text\n",
      "03/24/2023 18:01:42 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/squad/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\n",
      "03/24/2023 18:01:42 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/24/2023 18:01:42 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\n",
      "03/24/2023 18:01:42 - WARNING - datasets.builder - Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "03/24/2023 18:01:42 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e193f6050f6441819135ed673d1ea390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-24 18:01:42,237 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 18:01:42,239 >> Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-24 18:01:42,270 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-24 18:01:42,295 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 18:01:42,296 >> Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:01:42,356 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/sentencepiece.bpe.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:01:42,357 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:01:42,357 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:01:42,358 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:01:42,358 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-24 18:01:42,362 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 18:01:42,363 >> Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-24 18:01:42,824 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/pytorch_model.bin\n",
      "[WARNING|modeling_utils.py:3010] 2023-03-24 18:01:44,943 >> Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3022] 2023-03-24 18:01:44,944 >> Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/24/2023 18:01:45 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-1ce3efe41af06909.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-24 18:01:45,255 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-03-24 18:01:45,262 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-24 18:01:45,263 >>   Num examples = 89597\n",
      "[INFO|trainer.py:1760] 2023-03-24 18:01:45,263 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-24 18:01:45,263 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:1762] 2023-03-24 18:01:45,264 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "[INFO|trainer.py:1763] 2023-03-24 18:01:45,264 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-24 18:01:45,265 >>   Total optimization steps = 5000\n",
      "[INFO|trainer.py:1766] 2023-03-24 18:01:45,266 >>   Number of trainable parameters = 277454594\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 05:52, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.983500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>6.052300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>6.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>6.024100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>6.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>6.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.989400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.974000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.973200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>6.050300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.994900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>6.002500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>6.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.999500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.999600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>6.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>6.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.960200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.989200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.962600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>6.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.995000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>6.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.992900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>6.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.968800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>6.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>5.970300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>5.987600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.971400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>5.957300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.982900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>5.960700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.967000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.960400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.942900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>5.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>6.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>5.921200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.968200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>5.972800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>6.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>5.956300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>5.895100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>5.974400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.925200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>5.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>5.911300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>5.932200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>5.926600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.909800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>5.947300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>5.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>5.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.988100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>5.944500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>5.922900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>5.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.893300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>5.905100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>5.944700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>5.922200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>5.929900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>5.924600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.910300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>5.882900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>5.923500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>5.916200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>5.908500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>5.902400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>5.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>5.953600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>5.884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>5.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.898000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>5.888800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>5.848400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>5.856300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>5.871200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>5.831200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>5.864700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>5.896600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>5.877500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>5.855500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.844700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>5.863200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>5.830300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>5.883300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>5.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>5.818800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>5.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>5.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>5.849300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>5.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>5.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>5.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>5.801700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>5.769100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>5.837300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>5.765400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>5.810700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>5.785700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>5.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>5.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>5.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>5.764200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>5.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>5.721400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>5.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>5.790600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>5.718900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>5.764000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>5.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>5.743900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>5.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>5.715800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>5.709400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>5.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>5.681300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>5.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>5.739000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>5.677800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>5.676400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>5.721700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>5.667700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>5.720100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>5.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>5.716900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>5.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>5.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>5.633500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>5.634700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>5.673300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>5.646600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>5.617700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>5.658100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>5.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>5.595000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>5.677900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>5.671400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>5.690700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>5.589000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>5.656100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>5.634800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>5.584200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>5.644800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>5.732200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>5.616400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>5.751300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>5.631200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>5.565800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>5.627400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>5.655300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>5.568200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>5.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>5.790300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>5.576800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>5.594500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>5.602700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>5.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>5.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>5.646400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>5.617900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>5.595400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>5.671400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>5.538100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>5.615600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>5.680300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>5.549600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>5.533100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>5.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>5.568500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>5.538000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>5.598100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>5.575100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>5.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>5.506500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>5.549500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>5.500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>5.630800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>5.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>5.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>5.506300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.519800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>5.468100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>5.423100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>5.515600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>5.441200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>5.612300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>5.567500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>5.629600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>5.564700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>5.494900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>5.490800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>5.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>5.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>5.452700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>5.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>5.548100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>5.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>5.482300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>5.418300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>5.440100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>5.598100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>5.457800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>5.571100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>5.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>5.504200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>5.617100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>5.454800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>5.490400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>5.550800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>5.471400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>5.453700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>5.454800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>5.416800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>5.411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>5.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>5.478000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>5.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>5.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>5.576700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>5.649700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>5.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>5.576500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>5.432200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>5.333600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>5.455300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>5.490500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>5.514900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>5.459000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>5.327000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>5.491700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.554200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>5.445700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>5.431700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>5.425600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>5.559500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>5.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>5.497700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>5.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>5.507500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>5.467400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>5.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>5.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>5.437400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>5.394800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>5.403800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>5.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>5.375100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>5.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>5.452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>5.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>5.316200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>5.351500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>5.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>5.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>5.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>5.502700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>5.502300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>5.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>5.476400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>5.452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>5.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>5.340100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>5.619700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>5.325700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>5.352600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>5.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>5.451000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>5.310100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>5.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>5.329100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>5.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>5.245800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>5.460300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>5.456200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>5.318600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>5.362900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>5.400900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>5.326700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>5.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>5.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.507000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>5.271700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>5.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>5.504800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>5.442700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>5.495900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>5.426000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>5.408800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>5.295400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>5.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>5.253500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>5.391600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>5.564500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>5.279800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>5.355900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>5.416900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>5.635800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>5.245800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>5.303000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>5.302800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>5.449400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>5.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>5.432000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>5.301600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>5.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>5.156600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>5.383700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>5.261100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>5.357500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>5.296100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>5.338800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>5.370700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>5.229600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>5.333400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>5.331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>5.504400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>5.263500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>5.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>5.533200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>5.250800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>5.227700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>5.260400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>5.264000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>5.295500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>5.393000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>5.503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>5.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3470</td>\n",
       "      <td>5.263200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>5.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3490</td>\n",
       "      <td>5.314700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>5.225300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>5.245700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>5.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>5.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>5.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>5.335500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>5.152800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>5.455100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>5.312000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3590</td>\n",
       "      <td>5.266600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>5.449100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>5.323000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>5.656300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>5.318900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>5.332000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>5.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>5.299100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>5.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>5.376400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>5.275000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>5.259300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3710</td>\n",
       "      <td>5.298200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>5.227500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3730</td>\n",
       "      <td>5.210900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>5.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>5.426100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>5.412300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>5.334900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>5.492200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3790</td>\n",
       "      <td>5.366300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>5.242800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>5.439300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>5.282800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3830</td>\n",
       "      <td>5.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>5.675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>5.340700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>5.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3870</td>\n",
       "      <td>5.592900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>5.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3890</td>\n",
       "      <td>5.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>5.630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3910</td>\n",
       "      <td>5.407000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>5.329700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3930</td>\n",
       "      <td>5.296600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>5.383300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>5.276200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>5.299200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3970</td>\n",
       "      <td>5.394800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>5.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>5.640200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4010</td>\n",
       "      <td>5.159100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>5.398800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4030</td>\n",
       "      <td>5.333300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>5.306700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>5.430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>5.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4070</td>\n",
       "      <td>5.530600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>5.342600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4090</td>\n",
       "      <td>5.310100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>5.292300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4110</td>\n",
       "      <td>5.281200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>5.432700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4130</td>\n",
       "      <td>5.201700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>5.298900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>5.253400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>5.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>5.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>5.609500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4190</td>\n",
       "      <td>5.276300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>5.294100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4210</td>\n",
       "      <td>5.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>5.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4230</td>\n",
       "      <td>5.181300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>5.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>5.244100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>5.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4270</td>\n",
       "      <td>5.170500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>5.201000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4290</td>\n",
       "      <td>5.483700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>5.300300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4310</td>\n",
       "      <td>5.340200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>5.283200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4330</td>\n",
       "      <td>5.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>5.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>5.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>5.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4370</td>\n",
       "      <td>5.163900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>5.198100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4390</td>\n",
       "      <td>5.339500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>5.518700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>5.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>5.198800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4430</td>\n",
       "      <td>5.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>5.319700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>5.230300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>5.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4470</td>\n",
       "      <td>5.211500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4480</td>\n",
       "      <td>5.454800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4490</td>\n",
       "      <td>5.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.453900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4510</td>\n",
       "      <td>5.489500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4520</td>\n",
       "      <td>5.188600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4530</td>\n",
       "      <td>5.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4540</td>\n",
       "      <td>5.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>5.320600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4560</td>\n",
       "      <td>5.419500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4570</td>\n",
       "      <td>5.359200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4580</td>\n",
       "      <td>5.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4590</td>\n",
       "      <td>5.207700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>5.272900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4610</td>\n",
       "      <td>5.167100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4620</td>\n",
       "      <td>5.458500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4630</td>\n",
       "      <td>5.190500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4640</td>\n",
       "      <td>5.245800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>5.194900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4660</td>\n",
       "      <td>5.221900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4670</td>\n",
       "      <td>5.278300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4680</td>\n",
       "      <td>5.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4690</td>\n",
       "      <td>5.299700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>5.199300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4710</td>\n",
       "      <td>5.337800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4720</td>\n",
       "      <td>5.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4730</td>\n",
       "      <td>5.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4740</td>\n",
       "      <td>5.169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>5.450200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4760</td>\n",
       "      <td>5.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4770</td>\n",
       "      <td>5.332700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4780</td>\n",
       "      <td>5.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4790</td>\n",
       "      <td>5.253200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>5.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4810</td>\n",
       "      <td>5.547200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4820</td>\n",
       "      <td>5.361700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4830</td>\n",
       "      <td>5.318500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4840</td>\n",
       "      <td>5.156700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>5.313900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>5.451600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4870</td>\n",
       "      <td>5.360600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4880</td>\n",
       "      <td>5.354800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4890</td>\n",
       "      <td>5.665500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>5.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4910</td>\n",
       "      <td>5.090100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4920</td>\n",
       "      <td>5.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4930</td>\n",
       "      <td>5.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4940</td>\n",
       "      <td>5.184800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>5.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4960</td>\n",
       "      <td>5.181400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4970</td>\n",
       "      <td>5.257300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>5.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4990</td>\n",
       "      <td>5.192200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.595400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-24 18:07:38,069 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-24 18:07:38,073 >> Saving model checkpoint to /tmp/tmpv8t6xa56\n",
      "[INFO|configuration_utils.py:457] 2023-03-24 18:07:38,075 >> Configuration saved in /tmp/tmpv8t6xa56/config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-24 18:07:39,059 >> Model weights saved in /tmp/tmpv8t6xa56/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2163] 2023-03-24 18:07:39,061 >> tokenizer config file saved in /tmp/tmpv8t6xa56/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-03-24 18:07:39,062 >> Special tokens file saved in /tmp/tmpv8t6xa56/special_tokens_map.json\n",
      "[INFO|modelcard.py:449] 2023-03-24 18:07:39,459 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'squad', 'type': 'squad', 'config': 'plain_text', 'split': 'train', 'args': 'plain_text'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.11\n",
      "  total_flos               =  1825136GF\n",
      "  train_loss               =     5.5526\n",
      "  train_runtime            = 0:05:52.80\n",
      "  train_samples            =      89597\n",
      "  train_samples_per_second =     28.344\n",
      "  train_steps_per_second   =     14.172\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    --model_name_or_path xlm-roberta-base\n",
    "    --dataset_name squad\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=2\n",
    "    --per_device_eval_batch_size=1\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "    # --lr_scheduler_type cosine_with_restarts\n",
    "    # --optim adafactor\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_squad.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "e7c5ed56-53bc-47fc-b58e-933d60d304ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b40af-44d6-44fb-9880-338c3b01ac17",
   "metadata": {},
   "source": [
    "### Greedy LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "8b2fabf8-33f9-497a-a361-2597cd1b5de4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-24 18:07:40,003 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-24 18:07:40,003 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/24/2023 18:07:40 - WARNING - run_qa - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/24/2023 18:07:40 - INFO - run_qa - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpphb40w_k/runs/Mar24_18-07-40_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=greedy,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=5000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=1e-05,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpphb40w_k,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=2,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpphb40w_k,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/24/2023 18:07:40 - INFO - datasets.builder - No config specified, defaulting to the single config: squad/plain_text\n",
      "03/24/2023 18:07:40 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/squad/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\n",
      "03/24/2023 18:07:40 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/24/2023 18:07:40 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\n",
      "03/24/2023 18:07:40 - WARNING - datasets.builder - Found cached dataset squad (/root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n",
      "03/24/2023 18:07:40 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1950c986f549adb1701f2fb08926be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-24 18:07:40,331 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 18:07:40,332 >> Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-24 18:07:40,362 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-24 18:07:40,387 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 18:07:40,388 >> Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:07:40,446 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/sentencepiece.bpe.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:07:40,447 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:07:40,448 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:07:40,448 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-24 18:07:40,449 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-24 18:07:40,453 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 18:07:40,454 >> Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"xlm-roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-24 18:07:40,915 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--xlm-roberta-base/snapshots/42f548f32366559214515ec137cdd16002968bf6/pytorch_model.bin\n",
      "[WARNING|modeling_utils.py:3010] 2023-03-24 18:07:43,024 >> Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForQuestionAnswering: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3022] 2023-03-24 18:07:43,026 >> Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/24/2023 18:07:43 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453/cache-1ce3efe41af06909.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-24 18:07:43,333 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-03-24 18:07:43,339 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-24 18:07:43,340 >>   Num examples = 89597\n",
      "[INFO|trainer.py:1760] 2023-03-24 18:07:43,340 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-24 18:07:43,340 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1762] 2023-03-24 18:07:43,341 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1763] 2023-03-24 18:07:43,341 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-24 18:07:43,342 >>   Total optimization steps = 5000\n",
      "[INFO|trainer.py:1766] 2023-03-24 18:07:43,343 >>   Number of trainable parameters = 277454594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreedyLR settings: patience=10 smooth=True min_lr=1e-05 factor=0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 09:06, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>6.095200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>6.081000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>6.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>6.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>6.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>6.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>6.036700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>6.036300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>6.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>6.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>6.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>6.061700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>6.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.991100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>6.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.969100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>6.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>6.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>6.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>6.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>6.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>6.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.980700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.996300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>6.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>6.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>6.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>6.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>6.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.980700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>6.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>5.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>6.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>6.032600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>6.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.989100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>5.999000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>6.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>6.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>6.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>5.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>5.996900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>5.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>5.989700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>5.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>5.998700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>5.968900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>5.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.995400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>5.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>6.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>6.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>6.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>6.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>5.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.972700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>5.982600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>6.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>6.001100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>6.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>5.970400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>5.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>5.983600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>5.964000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>5.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>5.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>5.960400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>6.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>5.993200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>5.963100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>5.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>5.971400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>5.990500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>5.993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>5.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.962100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>6.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>5.966900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>5.972800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>6.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>5.985800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>5.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>6.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>5.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>5.979800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.999700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>5.966700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>6.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>5.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>5.958400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>5.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>5.981900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>6.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>5.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>5.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>5.984600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>6.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>5.958800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>5.983700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>5.987800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>5.965200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>5.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>5.977100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>5.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>6.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>5.980200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>5.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>5.962600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>5.962800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>5.969800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>6.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>6.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>5.981200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>5.973500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>5.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>5.957700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>6.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>5.985300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>5.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>5.986700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>5.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>5.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>6.002100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>5.928700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>5.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>5.970600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>5.971100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>6.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>5.929200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>5.948300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>5.969900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>5.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>5.969300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>5.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>6.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>5.998000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>6.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>5.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>6.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>5.945600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>6.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>5.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>5.940800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>5.971100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>5.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>5.977600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>5.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>6.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>5.967800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>5.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>5.983800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>5.956100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>5.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>5.988400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>5.971000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>5.991400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>5.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>5.956600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>5.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>5.962500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>5.959300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>6.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>5.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>6.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>5.969700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>5.966800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>6.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>5.987300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>5.965600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>5.992500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>5.964200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>5.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>5.969300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>5.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>5.980200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>5.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>5.956300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>5.947700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>5.973100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>5.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>5.966900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>5.945700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>5.986500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>5.956000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>5.981600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.969700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>5.964100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>5.961900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>5.969600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>5.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>5.998600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>5.951700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>6.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>5.955800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>5.974700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>5.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>5.992600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>5.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>5.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>5.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>5.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>6.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>6.001800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>5.961500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>5.962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>5.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>6.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>5.960700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>5.966100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>5.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>5.965700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>5.967600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>6.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>5.985000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>5.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>5.953000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>5.946300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>5.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>5.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>5.956900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>5.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>5.969600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>5.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>5.992800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>5.966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>5.950800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>5.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>5.963900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>5.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>5.969000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>5.960600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>5.977900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>6.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>5.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>5.940900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>5.947600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>5.954200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>5.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>5.966300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>5.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>5.965800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>5.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>5.981200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>5.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>5.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>5.957700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>5.974400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>5.993000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>6.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>5.970500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>5.954100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>5.974700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>5.943600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>5.973300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>5.966500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>5.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>5.956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>5.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>5.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>5.965300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>5.944500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>5.960400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>5.972200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>5.983800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>5.969300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>5.969400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>5.935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>5.942200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>5.945600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>5.926700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>5.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>5.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>5.963100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>5.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>5.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>5.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>5.953100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>5.966400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>5.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>5.934300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>6.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>5.982000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>5.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>5.950400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>5.942900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>5.956400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>5.931100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>5.977700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>5.988600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>5.963900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>5.965200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>5.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>5.974100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>5.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>5.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>5.961400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>5.952700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>5.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>5.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>5.955900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>5.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>5.934200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3190</td>\n",
       "      <td>5.954500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>5.950600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>5.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3220</td>\n",
       "      <td>5.954700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3230</td>\n",
       "      <td>5.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3240</td>\n",
       "      <td>5.991600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>5.934900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3260</td>\n",
       "      <td>5.940400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3270</td>\n",
       "      <td>5.999900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3280</td>\n",
       "      <td>5.945800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3290</td>\n",
       "      <td>5.962900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>5.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3310</td>\n",
       "      <td>5.961900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3320</td>\n",
       "      <td>5.964200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3330</td>\n",
       "      <td>5.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3340</td>\n",
       "      <td>5.959300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>5.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3360</td>\n",
       "      <td>5.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3370</td>\n",
       "      <td>5.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3380</td>\n",
       "      <td>5.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3390</td>\n",
       "      <td>5.934800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>5.928900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3410</td>\n",
       "      <td>5.922900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3420</td>\n",
       "      <td>5.950700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3430</td>\n",
       "      <td>5.979700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3440</td>\n",
       "      <td>5.914500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>5.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3460</td>\n",
       "      <td>5.926600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3470</td>\n",
       "      <td>5.935600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3480</td>\n",
       "      <td>5.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3490</td>\n",
       "      <td>5.967400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>5.956200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3510</td>\n",
       "      <td>5.958100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3520</td>\n",
       "      <td>5.935700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3530</td>\n",
       "      <td>5.938500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3540</td>\n",
       "      <td>5.938000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>5.955500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3560</td>\n",
       "      <td>5.963900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3570</td>\n",
       "      <td>5.935700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3580</td>\n",
       "      <td>5.934700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3590</td>\n",
       "      <td>5.935800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>5.941500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3610</td>\n",
       "      <td>5.924100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3620</td>\n",
       "      <td>5.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3630</td>\n",
       "      <td>5.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3640</td>\n",
       "      <td>5.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>5.947300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3660</td>\n",
       "      <td>5.918300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3670</td>\n",
       "      <td>5.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3680</td>\n",
       "      <td>5.957000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3690</td>\n",
       "      <td>5.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>5.947200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3710</td>\n",
       "      <td>5.970800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3720</td>\n",
       "      <td>5.947900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3730</td>\n",
       "      <td>5.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3740</td>\n",
       "      <td>5.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>5.923400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3760</td>\n",
       "      <td>5.943500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3770</td>\n",
       "      <td>5.901800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3780</td>\n",
       "      <td>5.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3790</td>\n",
       "      <td>5.916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>5.917500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3810</td>\n",
       "      <td>5.955600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3820</td>\n",
       "      <td>5.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3830</td>\n",
       "      <td>5.921300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3840</td>\n",
       "      <td>5.939900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>5.933600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3860</td>\n",
       "      <td>5.959200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3870</td>\n",
       "      <td>5.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3880</td>\n",
       "      <td>5.950900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3890</td>\n",
       "      <td>5.941200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>5.962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3910</td>\n",
       "      <td>5.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3920</td>\n",
       "      <td>5.986800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3930</td>\n",
       "      <td>5.925100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3940</td>\n",
       "      <td>5.927100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>5.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3960</td>\n",
       "      <td>5.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3970</td>\n",
       "      <td>5.927500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3980</td>\n",
       "      <td>5.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3990</td>\n",
       "      <td>5.928100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4010</td>\n",
       "      <td>5.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4020</td>\n",
       "      <td>5.928700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4030</td>\n",
       "      <td>5.936300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4040</td>\n",
       "      <td>5.942400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>5.928300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4060</td>\n",
       "      <td>5.971200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4070</td>\n",
       "      <td>5.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4080</td>\n",
       "      <td>5.943100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4090</td>\n",
       "      <td>5.935100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>5.913200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4110</td>\n",
       "      <td>5.926500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4120</td>\n",
       "      <td>5.915100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4130</td>\n",
       "      <td>5.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4140</td>\n",
       "      <td>5.925400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>5.930600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4160</td>\n",
       "      <td>5.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4170</td>\n",
       "      <td>5.944100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4180</td>\n",
       "      <td>5.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4190</td>\n",
       "      <td>5.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>5.948900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4210</td>\n",
       "      <td>5.962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4220</td>\n",
       "      <td>5.916100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4230</td>\n",
       "      <td>5.965300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4240</td>\n",
       "      <td>5.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>5.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4260</td>\n",
       "      <td>5.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4270</td>\n",
       "      <td>5.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4280</td>\n",
       "      <td>5.934500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4290</td>\n",
       "      <td>5.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>5.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4310</td>\n",
       "      <td>5.951200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4320</td>\n",
       "      <td>5.912400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4330</td>\n",
       "      <td>5.941700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4340</td>\n",
       "      <td>5.948800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>5.947100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4360</td>\n",
       "      <td>5.950500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4370</td>\n",
       "      <td>5.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4380</td>\n",
       "      <td>5.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4390</td>\n",
       "      <td>5.934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>5.938400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4410</td>\n",
       "      <td>5.927200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4420</td>\n",
       "      <td>5.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4430</td>\n",
       "      <td>5.934700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4440</td>\n",
       "      <td>5.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>5.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4460</td>\n",
       "      <td>5.940600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4470</td>\n",
       "      <td>5.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4480</td>\n",
       "      <td>5.923400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4490</td>\n",
       "      <td>5.905200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.924900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4510</td>\n",
       "      <td>5.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4520</td>\n",
       "      <td>5.954400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4530</td>\n",
       "      <td>5.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4540</td>\n",
       "      <td>5.948200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>5.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4560</td>\n",
       "      <td>5.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4570</td>\n",
       "      <td>5.925600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4580</td>\n",
       "      <td>5.953100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4590</td>\n",
       "      <td>5.925900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>5.928600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4610</td>\n",
       "      <td>5.896900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4620</td>\n",
       "      <td>5.914300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4630</td>\n",
       "      <td>5.957400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4640</td>\n",
       "      <td>5.957600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>5.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4660</td>\n",
       "      <td>5.923700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4670</td>\n",
       "      <td>5.889300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4680</td>\n",
       "      <td>5.946900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4690</td>\n",
       "      <td>5.925100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>5.934700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4710</td>\n",
       "      <td>5.900600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4720</td>\n",
       "      <td>5.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4730</td>\n",
       "      <td>5.903200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4740</td>\n",
       "      <td>5.947600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>5.939400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4760</td>\n",
       "      <td>5.915900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4770</td>\n",
       "      <td>5.954800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4780</td>\n",
       "      <td>5.895700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4790</td>\n",
       "      <td>5.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>5.910100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4810</td>\n",
       "      <td>5.909600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4820</td>\n",
       "      <td>5.931200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4830</td>\n",
       "      <td>5.892900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4840</td>\n",
       "      <td>5.895100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>5.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4860</td>\n",
       "      <td>5.897000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4870</td>\n",
       "      <td>5.915500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4880</td>\n",
       "      <td>5.925300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4890</td>\n",
       "      <td>5.927700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>5.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4910</td>\n",
       "      <td>5.944500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4920</td>\n",
       "      <td>5.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4930</td>\n",
       "      <td>5.929900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4940</td>\n",
       "      <td>5.913900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>5.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4960</td>\n",
       "      <td>5.916800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4970</td>\n",
       "      <td>5.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4980</td>\n",
       "      <td>5.919400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4990</td>\n",
       "      <td>5.934100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>5.918300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-24 18:16:49,859 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-24 18:16:49,863 >> Saving model checkpoint to /tmp/tmpphb40w_k\n",
      "[INFO|configuration_utils.py:457] 2023-03-24 18:16:49,864 >> Configuration saved in /tmp/tmpphb40w_k/config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-24 18:16:50,847 >> Model weights saved in /tmp/tmpphb40w_k/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2163] 2023-03-24 18:16:50,849 >> tokenizer config file saved in /tmp/tmpphb40w_k/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-03-24 18:16:50,850 >> Special tokens file saved in /tmp/tmpphb40w_k/special_tokens_map.json\n",
      "[INFO|modelcard.py:449] 2023-03-24 18:16:51,264 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Question Answering', 'type': 'question-answering'}, 'dataset': {'name': 'squad', 'type': 'squad', 'config': 'plain_text', 'split': 'train', 'args': 'plain_text'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.22\n",
      "  total_flos               =  3650273GF\n",
      "  train_loss               =     5.9639\n",
      "  train_runtime            = 0:09:06.51\n",
      "  train_samples            =      89597\n",
      "  train_samples_per_second =     36.595\n",
      "  train_steps_per_second   =      9.149\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    --model_name_or_path xlm-roberta-base\n",
    "    --dataset_name squad\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --per_device_eval_batch_size=2\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_squad.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "919c2f59-2765-4f74-9860-d616bab549c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "f641246a-0668-4fcd-a298-1f9eb9f68ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "18e6e45a-246d-4aa5-83e0-f508cf5536ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "55deca4e-7319-4529-a03d-c27624fe977f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.32290000000000063"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de0731-21f6-4e6a-9cf4-5594cd7b00db",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbae73ed-7336-4eb2-bed2-3ffe8e522976",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchvision) (4.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: torch==1.13.1 in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch==1.13.1->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (65.7.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (0.40.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.0.4)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "5b274bc4-e96e-4e39-82ab-1f0eadecbe20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_image_classification\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "fc22a59a-5a94-4488-bd6e-f2e8e7b7062a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-24 15:08:20,285 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-24 15:08:20,286 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/24/2023 15:08:20 - WARNING - run_image_classification - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/24/2023 15:08:20 - INFO - run_image_classification - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpqtgpb1b0/runs/Mar24_15-08-20_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_warmup,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=accuracy,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpqtgpb1b0,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=64,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpqtgpb1b0,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/24/2023 15:08:20 - INFO - datasets.builder - Using custom data configuration Maysee--tiny-imagenet-b0676a0e6b48ef45\n",
      "03/24/2023 15:08:20 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/24/2023 15:08:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\n",
      "03/24/2023 15:08:20 - WARNING - datasets.builder - Found cached dataset parquet (/root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "03/24/2023 15:08:20 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a195619296aa419c8d88cbd98173fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/24/2023 15:08:20 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b0fb943218e6befa.arrow\n",
      "03/24/2023 15:08:20 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-fc5ce1ae43a8f6a5.arrow\n",
      "03/24/2023 15:08:20 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-18842866901c8da8.arrow and /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-6389ebf601dcdb17.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-24 15:08:20,744 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/2ddc9d4e473d7ba52128f0df4723e478fa14fb80/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 15:08:20,746 >> Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"finetuning_task\": \"image-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"n01443537\",\n",
      "    \"1\": \"n01629819\",\n",
      "    \"10\": \"n01784675\",\n",
      "    \"100\": \"n03447447\",\n",
      "    \"101\": \"n03544143\",\n",
      "    \"102\": \"n03584254\",\n",
      "    \"103\": \"n03599486\",\n",
      "    \"104\": \"n03617480\",\n",
      "    \"105\": \"n03637318\",\n",
      "    \"106\": \"n03649909\",\n",
      "    \"107\": \"n03662601\",\n",
      "    \"108\": \"n03670208\",\n",
      "    \"109\": \"n03706229\",\n",
      "    \"11\": \"n01882714\",\n",
      "    \"110\": \"n03733131\",\n",
      "    \"111\": \"n03763968\",\n",
      "    \"112\": \"n03770439\",\n",
      "    \"113\": \"n03796401\",\n",
      "    \"114\": \"n03814639\",\n",
      "    \"115\": \"n03837869\",\n",
      "    \"116\": \"n03838899\",\n",
      "    \"117\": \"n03854065\",\n",
      "    \"118\": \"n03891332\",\n",
      "    \"119\": \"n03902125\",\n",
      "    \"12\": \"n01910747\",\n",
      "    \"120\": \"n03930313\",\n",
      "    \"121\": \"n03937543\",\n",
      "    \"122\": \"n03970156\",\n",
      "    \"123\": \"n03977966\",\n",
      "    \"124\": \"n03980874\",\n",
      "    \"125\": \"n03983396\",\n",
      "    \"126\": \"n03992509\",\n",
      "    \"127\": \"n04008634\",\n",
      "    \"128\": \"n04023962\",\n",
      "    \"129\": \"n04070727\",\n",
      "    \"13\": \"n01917289\",\n",
      "    \"130\": \"n04074963\",\n",
      "    \"131\": \"n04099969\",\n",
      "    \"132\": \"n04118538\",\n",
      "    \"133\": \"n04133789\",\n",
      "    \"134\": \"n04146614\",\n",
      "    \"135\": \"n04149813\",\n",
      "    \"136\": \"n04179913\",\n",
      "    \"137\": \"n04251144\",\n",
      "    \"138\": \"n04254777\",\n",
      "    \"139\": \"n04259630\",\n",
      "    \"14\": \"n01944390\",\n",
      "    \"140\": \"n04265275\",\n",
      "    \"141\": \"n04275548\",\n",
      "    \"142\": \"n04285008\",\n",
      "    \"143\": \"n04311004\",\n",
      "    \"144\": \"n04328186\",\n",
      "    \"145\": \"n04356056\",\n",
      "    \"146\": \"n04366367\",\n",
      "    \"147\": \"n04371430\",\n",
      "    \"148\": \"n04376876\",\n",
      "    \"149\": \"n04398044\",\n",
      "    \"15\": \"n01950731\",\n",
      "    \"150\": \"n04399382\",\n",
      "    \"151\": \"n04417672\",\n",
      "    \"152\": \"n04456115\",\n",
      "    \"153\": \"n04465666\",\n",
      "    \"154\": \"n04486054\",\n",
      "    \"155\": \"n04487081\",\n",
      "    \"156\": \"n04501370\",\n",
      "    \"157\": \"n04507155\",\n",
      "    \"158\": \"n04532106\",\n",
      "    \"159\": \"n04532670\",\n",
      "    \"16\": \"n01983481\",\n",
      "    \"160\": \"n04540053\",\n",
      "    \"161\": \"n04560804\",\n",
      "    \"162\": \"n04562935\",\n",
      "    \"163\": \"n04596742\",\n",
      "    \"164\": \"n04598010\",\n",
      "    \"165\": \"n06596364\",\n",
      "    \"166\": \"n07056680\",\n",
      "    \"167\": \"n07583066\",\n",
      "    \"168\": \"n07614500\",\n",
      "    \"169\": \"n07615774\",\n",
      "    \"17\": \"n01984695\",\n",
      "    \"170\": \"n07646821\",\n",
      "    \"171\": \"n07647870\",\n",
      "    \"172\": \"n07657664\",\n",
      "    \"173\": \"n07695742\",\n",
      "    \"174\": \"n07711569\",\n",
      "    \"175\": \"n07715103\",\n",
      "    \"176\": \"n07720875\",\n",
      "    \"177\": \"n07749582\",\n",
      "    \"178\": \"n07753592\",\n",
      "    \"179\": \"n07768694\",\n",
      "    \"18\": \"n02002724\",\n",
      "    \"180\": \"n07871810\",\n",
      "    \"181\": \"n07873807\",\n",
      "    \"182\": \"n07875152\",\n",
      "    \"183\": \"n07920052\",\n",
      "    \"184\": \"n07975909\",\n",
      "    \"185\": \"n08496334\",\n",
      "    \"186\": \"n08620881\",\n",
      "    \"187\": \"n08742578\",\n",
      "    \"188\": \"n09193705\",\n",
      "    \"189\": \"n09246464\",\n",
      "    \"19\": \"n02056570\",\n",
      "    \"190\": \"n09256479\",\n",
      "    \"191\": \"n09332890\",\n",
      "    \"192\": \"n09428293\",\n",
      "    \"193\": \"n12267677\",\n",
      "    \"194\": \"n12520864\",\n",
      "    \"195\": \"n13001041\",\n",
      "    \"196\": \"n13652335\",\n",
      "    \"197\": \"n13652994\",\n",
      "    \"198\": \"n13719102\",\n",
      "    \"199\": \"n14991210\",\n",
      "    \"2\": \"n01641577\",\n",
      "    \"20\": \"n02058221\",\n",
      "    \"21\": \"n02074367\",\n",
      "    \"22\": \"n02094433\",\n",
      "    \"23\": \"n02099601\",\n",
      "    \"24\": \"n02099712\",\n",
      "    \"25\": \"n02106662\",\n",
      "    \"26\": \"n02113799\",\n",
      "    \"27\": \"n02123045\",\n",
      "    \"28\": \"n02123394\",\n",
      "    \"29\": \"n02124075\",\n",
      "    \"3\": \"n01644900\",\n",
      "    \"30\": \"n02125311\",\n",
      "    \"31\": \"n02129165\",\n",
      "    \"32\": \"n02132136\",\n",
      "    \"33\": \"n02165456\",\n",
      "    \"34\": \"n02226429\",\n",
      "    \"35\": \"n02231487\",\n",
      "    \"36\": \"n02233338\",\n",
      "    \"37\": \"n02236044\",\n",
      "    \"38\": \"n02268443\",\n",
      "    \"39\": \"n02279972\",\n",
      "    \"4\": \"n01698640\",\n",
      "    \"40\": \"n02281406\",\n",
      "    \"41\": \"n02321529\",\n",
      "    \"42\": \"n02364673\",\n",
      "    \"43\": \"n02395406\",\n",
      "    \"44\": \"n02403003\",\n",
      "    \"45\": \"n02410509\",\n",
      "    \"46\": \"n02415577\",\n",
      "    \"47\": \"n02423022\",\n",
      "    \"48\": \"n02437312\",\n",
      "    \"49\": \"n02480495\",\n",
      "    \"5\": \"n01742172\",\n",
      "    \"50\": \"n02481823\",\n",
      "    \"51\": \"n02486410\",\n",
      "    \"52\": \"n02504458\",\n",
      "    \"53\": \"n02509815\",\n",
      "    \"54\": \"n02666347\",\n",
      "    \"55\": \"n02669723\",\n",
      "    \"56\": \"n02699494\",\n",
      "    \"57\": \"n02769748\",\n",
      "    \"58\": \"n02788148\",\n",
      "    \"59\": \"n02791270\",\n",
      "    \"6\": \"n01768244\",\n",
      "    \"60\": \"n02793495\",\n",
      "    \"61\": \"n02795169\",\n",
      "    \"62\": \"n02802426\",\n",
      "    \"63\": \"n02808440\",\n",
      "    \"64\": \"n02814533\",\n",
      "    \"65\": \"n02814860\",\n",
      "    \"66\": \"n02815834\",\n",
      "    \"67\": \"n02823428\",\n",
      "    \"68\": \"n02837789\",\n",
      "    \"69\": \"n02841315\",\n",
      "    \"7\": \"n01770393\",\n",
      "    \"70\": \"n02843684\",\n",
      "    \"71\": \"n02883205\",\n",
      "    \"72\": \"n02892201\",\n",
      "    \"73\": \"n02909870\",\n",
      "    \"74\": \"n02917067\",\n",
      "    \"75\": \"n02927161\",\n",
      "    \"76\": \"n02948072\",\n",
      "    \"77\": \"n02950826\",\n",
      "    \"78\": \"n02963159\",\n",
      "    \"79\": \"n02977058\",\n",
      "    \"8\": \"n01774384\",\n",
      "    \"80\": \"n02988304\",\n",
      "    \"81\": \"n03014705\",\n",
      "    \"82\": \"n03026506\",\n",
      "    \"83\": \"n03042490\",\n",
      "    \"84\": \"n03085013\",\n",
      "    \"85\": \"n03089624\",\n",
      "    \"86\": \"n03100240\",\n",
      "    \"87\": \"n03126707\",\n",
      "    \"88\": \"n03160309\",\n",
      "    \"89\": \"n03179701\",\n",
      "    \"9\": \"n01774750\",\n",
      "    \"90\": \"n03201208\",\n",
      "    \"91\": \"n03255030\",\n",
      "    \"92\": \"n03355925\",\n",
      "    \"93\": \"n03373237\",\n",
      "    \"94\": \"n03388043\",\n",
      "    \"95\": \"n03393912\",\n",
      "    \"96\": \"n03400231\",\n",
      "    \"97\": \"n03404251\",\n",
      "    \"98\": \"n03424325\",\n",
      "    \"99\": \"n03444034\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"n01443537\": \"0\",\n",
      "    \"n01629819\": \"1\",\n",
      "    \"n01641577\": \"2\",\n",
      "    \"n01644900\": \"3\",\n",
      "    \"n01698640\": \"4\",\n",
      "    \"n01742172\": \"5\",\n",
      "    \"n01768244\": \"6\",\n",
      "    \"n01770393\": \"7\",\n",
      "    \"n01774384\": \"8\",\n",
      "    \"n01774750\": \"9\",\n",
      "    \"n01784675\": \"10\",\n",
      "    \"n01882714\": \"11\",\n",
      "    \"n01910747\": \"12\",\n",
      "    \"n01917289\": \"13\",\n",
      "    \"n01944390\": \"14\",\n",
      "    \"n01950731\": \"15\",\n",
      "    \"n01983481\": \"16\",\n",
      "    \"n01984695\": \"17\",\n",
      "    \"n02002724\": \"18\",\n",
      "    \"n02056570\": \"19\",\n",
      "    \"n02058221\": \"20\",\n",
      "    \"n02074367\": \"21\",\n",
      "    \"n02094433\": \"22\",\n",
      "    \"n02099601\": \"23\",\n",
      "    \"n02099712\": \"24\",\n",
      "    \"n02106662\": \"25\",\n",
      "    \"n02113799\": \"26\",\n",
      "    \"n02123045\": \"27\",\n",
      "    \"n02123394\": \"28\",\n",
      "    \"n02124075\": \"29\",\n",
      "    \"n02125311\": \"30\",\n",
      "    \"n02129165\": \"31\",\n",
      "    \"n02132136\": \"32\",\n",
      "    \"n02165456\": \"33\",\n",
      "    \"n02226429\": \"34\",\n",
      "    \"n02231487\": \"35\",\n",
      "    \"n02233338\": \"36\",\n",
      "    \"n02236044\": \"37\",\n",
      "    \"n02268443\": \"38\",\n",
      "    \"n02279972\": \"39\",\n",
      "    \"n02281406\": \"40\",\n",
      "    \"n02321529\": \"41\",\n",
      "    \"n02364673\": \"42\",\n",
      "    \"n02395406\": \"43\",\n",
      "    \"n02403003\": \"44\",\n",
      "    \"n02410509\": \"45\",\n",
      "    \"n02415577\": \"46\",\n",
      "    \"n02423022\": \"47\",\n",
      "    \"n02437312\": \"48\",\n",
      "    \"n02480495\": \"49\",\n",
      "    \"n02481823\": \"50\",\n",
      "    \"n02486410\": \"51\",\n",
      "    \"n02504458\": \"52\",\n",
      "    \"n02509815\": \"53\",\n",
      "    \"n02666347\": \"54\",\n",
      "    \"n02669723\": \"55\",\n",
      "    \"n02699494\": \"56\",\n",
      "    \"n02769748\": \"57\",\n",
      "    \"n02788148\": \"58\",\n",
      "    \"n02791270\": \"59\",\n",
      "    \"n02793495\": \"60\",\n",
      "    \"n02795169\": \"61\",\n",
      "    \"n02802426\": \"62\",\n",
      "    \"n02808440\": \"63\",\n",
      "    \"n02814533\": \"64\",\n",
      "    \"n02814860\": \"65\",\n",
      "    \"n02815834\": \"66\",\n",
      "    \"n02823428\": \"67\",\n",
      "    \"n02837789\": \"68\",\n",
      "    \"n02841315\": \"69\",\n",
      "    \"n02843684\": \"70\",\n",
      "    \"n02883205\": \"71\",\n",
      "    \"n02892201\": \"72\",\n",
      "    \"n02909870\": \"73\",\n",
      "    \"n02917067\": \"74\",\n",
      "    \"n02927161\": \"75\",\n",
      "    \"n02948072\": \"76\",\n",
      "    \"n02950826\": \"77\",\n",
      "    \"n02963159\": \"78\",\n",
      "    \"n02977058\": \"79\",\n",
      "    \"n02988304\": \"80\",\n",
      "    \"n03014705\": \"81\",\n",
      "    \"n03026506\": \"82\",\n",
      "    \"n03042490\": \"83\",\n",
      "    \"n03085013\": \"84\",\n",
      "    \"n03089624\": \"85\",\n",
      "    \"n03100240\": \"86\",\n",
      "    \"n03126707\": \"87\",\n",
      "    \"n03160309\": \"88\",\n",
      "    \"n03179701\": \"89\",\n",
      "    \"n03201208\": \"90\",\n",
      "    \"n03255030\": \"91\",\n",
      "    \"n03355925\": \"92\",\n",
      "    \"n03373237\": \"93\",\n",
      "    \"n03388043\": \"94\",\n",
      "    \"n03393912\": \"95\",\n",
      "    \"n03400231\": \"96\",\n",
      "    \"n03404251\": \"97\",\n",
      "    \"n03424325\": \"98\",\n",
      "    \"n03444034\": \"99\",\n",
      "    \"n03447447\": \"100\",\n",
      "    \"n03544143\": \"101\",\n",
      "    \"n03584254\": \"102\",\n",
      "    \"n03599486\": \"103\",\n",
      "    \"n03617480\": \"104\",\n",
      "    \"n03637318\": \"105\",\n",
      "    \"n03649909\": \"106\",\n",
      "    \"n03662601\": \"107\",\n",
      "    \"n03670208\": \"108\",\n",
      "    \"n03706229\": \"109\",\n",
      "    \"n03733131\": \"110\",\n",
      "    \"n03763968\": \"111\",\n",
      "    \"n03770439\": \"112\",\n",
      "    \"n03796401\": \"113\",\n",
      "    \"n03814639\": \"114\",\n",
      "    \"n03837869\": \"115\",\n",
      "    \"n03838899\": \"116\",\n",
      "    \"n03854065\": \"117\",\n",
      "    \"n03891332\": \"118\",\n",
      "    \"n03902125\": \"119\",\n",
      "    \"n03930313\": \"120\",\n",
      "    \"n03937543\": \"121\",\n",
      "    \"n03970156\": \"122\",\n",
      "    \"n03977966\": \"123\",\n",
      "    \"n03980874\": \"124\",\n",
      "    \"n03983396\": \"125\",\n",
      "    \"n03992509\": \"126\",\n",
      "    \"n04008634\": \"127\",\n",
      "    \"n04023962\": \"128\",\n",
      "    \"n04070727\": \"129\",\n",
      "    \"n04074963\": \"130\",\n",
      "    \"n04099969\": \"131\",\n",
      "    \"n04118538\": \"132\",\n",
      "    \"n04133789\": \"133\",\n",
      "    \"n04146614\": \"134\",\n",
      "    \"n04149813\": \"135\",\n",
      "    \"n04179913\": \"136\",\n",
      "    \"n04251144\": \"137\",\n",
      "    \"n04254777\": \"138\",\n",
      "    \"n04259630\": \"139\",\n",
      "    \"n04265275\": \"140\",\n",
      "    \"n04275548\": \"141\",\n",
      "    \"n04285008\": \"142\",\n",
      "    \"n04311004\": \"143\",\n",
      "    \"n04328186\": \"144\",\n",
      "    \"n04356056\": \"145\",\n",
      "    \"n04366367\": \"146\",\n",
      "    \"n04371430\": \"147\",\n",
      "    \"n04376876\": \"148\",\n",
      "    \"n04398044\": \"149\",\n",
      "    \"n04399382\": \"150\",\n",
      "    \"n04417672\": \"151\",\n",
      "    \"n04456115\": \"152\",\n",
      "    \"n04465666\": \"153\",\n",
      "    \"n04486054\": \"154\",\n",
      "    \"n04487081\": \"155\",\n",
      "    \"n04501370\": \"156\",\n",
      "    \"n04507155\": \"157\",\n",
      "    \"n04532106\": \"158\",\n",
      "    \"n04532670\": \"159\",\n",
      "    \"n04540053\": \"160\",\n",
      "    \"n04560804\": \"161\",\n",
      "    \"n04562935\": \"162\",\n",
      "    \"n04596742\": \"163\",\n",
      "    \"n04598010\": \"164\",\n",
      "    \"n06596364\": \"165\",\n",
      "    \"n07056680\": \"166\",\n",
      "    \"n07583066\": \"167\",\n",
      "    \"n07614500\": \"168\",\n",
      "    \"n07615774\": \"169\",\n",
      "    \"n07646821\": \"170\",\n",
      "    \"n07647870\": \"171\",\n",
      "    \"n07657664\": \"172\",\n",
      "    \"n07695742\": \"173\",\n",
      "    \"n07711569\": \"174\",\n",
      "    \"n07715103\": \"175\",\n",
      "    \"n07720875\": \"176\",\n",
      "    \"n07749582\": \"177\",\n",
      "    \"n07753592\": \"178\",\n",
      "    \"n07768694\": \"179\",\n",
      "    \"n07871810\": \"180\",\n",
      "    \"n07873807\": \"181\",\n",
      "    \"n07875152\": \"182\",\n",
      "    \"n07920052\": \"183\",\n",
      "    \"n07975909\": \"184\",\n",
      "    \"n08496334\": \"185\",\n",
      "    \"n08620881\": \"186\",\n",
      "    \"n08742578\": \"187\",\n",
      "    \"n09193705\": \"188\",\n",
      "    \"n09246464\": \"189\",\n",
      "    \"n09256479\": \"190\",\n",
      "    \"n09332890\": \"191\",\n",
      "    \"n09428293\": \"192\",\n",
      "    \"n12267677\": \"193\",\n",
      "    \"n12520864\": \"194\",\n",
      "    \"n13001041\": \"195\",\n",
      "    \"n13652335\": \"196\",\n",
      "    \"n13652994\": \"197\",\n",
      "    \"n13719102\": \"198\",\n",
      "    \"n14991210\": \"199\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-24 15:08:20,762 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/2ddc9d4e473d7ba52128f0df4723e478fa14fb80/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:3019] 2023-03-24 15:08:21,521 >> All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "[WARNING|modeling_utils.py:3041] 2023-03-24 15:08:21,522 >> Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([200, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([200]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-03-24 15:08:21,551 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/2ddc9d4e473d7ba52128f0df4723e478fa14fb80/preprocessor_config.json\n",
      "[INFO|configuration_utils.py:668] 2023-03-24 15:08:21,577 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/2ddc9d4e473d7ba52128f0df4723e478fa14fb80/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 15:08:21,586 >> Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"tench, Tinca tinca\",\n",
      "    \"1\": \"goldfish, Carassius auratus\",\n",
      "    \"2\": \"great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\",\n",
      "    \"3\": \"tiger shark, Galeocerdo cuvieri\",\n",
      "    \"4\": \"hammerhead, hammerhead shark\",\n",
      "    \"5\": \"electric ray, crampfish, numbfish, torpedo\",\n",
      "    \"6\": \"stingray\",\n",
      "    \"7\": \"cock\",\n",
      "    \"8\": \"hen\",\n",
      "    \"9\": \"ostrich, Struthio camelus\",\n",
      "    \"10\": \"brambling, Fringilla montifringilla\",\n",
      "    \"11\": \"goldfinch, Carduelis carduelis\",\n",
      "    \"12\": \"house finch, linnet, Carpodacus mexicanus\",\n",
      "    \"13\": \"junco, snowbird\",\n",
      "    \"14\": \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\",\n",
      "    \"15\": \"robin, American robin, Turdus migratorius\",\n",
      "    \"16\": \"bulbul\",\n",
      "    \"17\": \"jay\",\n",
      "    \"18\": \"magpie\",\n",
      "    \"19\": \"chickadee\",\n",
      "    \"20\": \"water ouzel, dipper\",\n",
      "    \"21\": \"kite\",\n",
      "    \"22\": \"bald eagle, American eagle, Haliaeetus leucocephalus\",\n",
      "    \"23\": \"vulture\",\n",
      "    \"24\": \"great grey owl, great gray owl, Strix nebulosa\",\n",
      "    \"25\": \"European fire salamander, Salamandra salamandra\",\n",
      "    \"26\": \"common newt, Triturus vulgaris\",\n",
      "    \"27\": \"eft\",\n",
      "    \"28\": \"spotted salamander, Ambystoma maculatum\",\n",
      "    \"29\": \"axolotl, mud puppy, Ambystoma mexicanum\",\n",
      "    \"30\": \"bullfrog, Rana catesbeiana\",\n",
      "    \"31\": \"tree frog, tree-frog\",\n",
      "    \"32\": \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\",\n",
      "    \"33\": \"loggerhead, loggerhead turtle, Caretta caretta\",\n",
      "    \"34\": \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\",\n",
      "    \"35\": \"mud turtle\",\n",
      "    \"36\": \"terrapin\",\n",
      "    \"37\": \"box turtle, box tortoise\",\n",
      "    \"38\": \"banded gecko\",\n",
      "    \"39\": \"common iguana, iguana, Iguana iguana\",\n",
      "    \"40\": \"American chameleon, anole, Anolis carolinensis\",\n",
      "    \"41\": \"whiptail, whiptail lizard\",\n",
      "    \"42\": \"agama\",\n",
      "    \"43\": \"frilled lizard, Chlamydosaurus kingi\",\n",
      "    \"44\": \"alligator lizard\",\n",
      "    \"45\": \"Gila monster, Heloderma suspectum\",\n",
      "    \"46\": \"green lizard, Lacerta viridis\",\n",
      "    \"47\": \"African chameleon, Chamaeleo chamaeleon\",\n",
      "    \"48\": \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis\",\n",
      "    \"49\": \"African crocodile, Nile crocodile, Crocodylus niloticus\",\n",
      "    \"50\": \"American alligator, Alligator mississipiensis\",\n",
      "    \"51\": \"triceratops\",\n",
      "    \"52\": \"thunder snake, worm snake, Carphophis amoenus\",\n",
      "    \"53\": \"ringneck snake, ring-necked snake, ring snake\",\n",
      "    \"54\": \"hognose snake, puff adder, sand viper\",\n",
      "    \"55\": \"green snake, grass snake\",\n",
      "    \"56\": \"king snake, kingsnake\",\n",
      "    \"57\": \"garter snake, grass snake\",\n",
      "    \"58\": \"water snake\",\n",
      "    \"59\": \"vine snake\",\n",
      "    \"60\": \"night snake, Hypsiglena torquata\",\n",
      "    \"61\": \"boa constrictor, Constrictor constrictor\",\n",
      "    \"62\": \"rock python, rock snake, Python sebae\",\n",
      "    \"63\": \"Indian cobra, Naja naja\",\n",
      "    \"64\": \"green mamba\",\n",
      "    \"65\": \"sea snake\",\n",
      "    \"66\": \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\",\n",
      "    \"67\": \"diamondback, diamondback rattlesnake, Crotalus adamanteus\",\n",
      "    \"68\": \"sidewinder, horned rattlesnake, Crotalus cerastes\",\n",
      "    \"69\": \"trilobite\",\n",
      "    \"70\": \"harvestman, daddy longlegs, Phalangium opilio\",\n",
      "    \"71\": \"scorpion\",\n",
      "    \"72\": \"black and gold garden spider, Argiope aurantia\",\n",
      "    \"73\": \"barn spider, Araneus cavaticus\",\n",
      "    \"74\": \"garden spider, Aranea diademata\",\n",
      "    \"75\": \"black widow, Latrodectus mactans\",\n",
      "    \"76\": \"tarantula\",\n",
      "    \"77\": \"wolf spider, hunting spider\",\n",
      "    \"78\": \"tick\",\n",
      "    \"79\": \"centipede\",\n",
      "    \"80\": \"black grouse\",\n",
      "    \"81\": \"ptarmigan\",\n",
      "    \"82\": \"ruffed grouse, partridge, Bonasa umbellus\",\n",
      "    \"83\": \"prairie chicken, prairie grouse, prairie fowl\",\n",
      "    \"84\": \"peacock\",\n",
      "    \"85\": \"quail\",\n",
      "    \"86\": \"partridge\",\n",
      "    \"87\": \"African grey, African gray, Psittacus erithacus\",\n",
      "    \"88\": \"macaw\",\n",
      "    \"89\": \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\",\n",
      "    \"90\": \"lorikeet\",\n",
      "    \"91\": \"coucal\",\n",
      "    \"92\": \"bee eater\",\n",
      "    \"93\": \"hornbill\",\n",
      "    \"94\": \"hummingbird\",\n",
      "    \"95\": \"jacamar\",\n",
      "    \"96\": \"toucan\",\n",
      "    \"97\": \"drake\",\n",
      "    \"98\": \"red-breasted merganser, Mergus serrator\",\n",
      "    \"99\": \"goose\",\n",
      "    \"100\": \"black swan, Cygnus atratus\",\n",
      "    \"101\": \"tusker\",\n",
      "    \"102\": \"echidna, spiny anteater, anteater\",\n",
      "    \"103\": \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\",\n",
      "    \"104\": \"wallaby, brush kangaroo\",\n",
      "    \"105\": \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\",\n",
      "    \"106\": \"wombat\",\n",
      "    \"107\": \"jellyfish\",\n",
      "    \"108\": \"sea anemone, anemone\",\n",
      "    \"109\": \"brain coral\",\n",
      "    \"110\": \"flatworm, platyhelminth\",\n",
      "    \"111\": \"nematode, nematode worm, roundworm\",\n",
      "    \"112\": \"conch\",\n",
      "    \"113\": \"snail\",\n",
      "    \"114\": \"slug\",\n",
      "    \"115\": \"sea slug, nudibranch\",\n",
      "    \"116\": \"chiton, coat-of-mail shell, sea cradle, polyplacophore\",\n",
      "    \"117\": \"chambered nautilus, pearly nautilus, nautilus\",\n",
      "    \"118\": \"Dungeness crab, Cancer magister\",\n",
      "    \"119\": \"rock crab, Cancer irroratus\",\n",
      "    \"120\": \"fiddler crab\",\n",
      "    \"121\": \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica\",\n",
      "    \"122\": \"American lobster, Northern lobster, Maine lobster, Homarus americanus\",\n",
      "    \"123\": \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\",\n",
      "    \"124\": \"crayfish, crawfish, crawdad, crawdaddy\",\n",
      "    \"125\": \"hermit crab\",\n",
      "    \"126\": \"isopod\",\n",
      "    \"127\": \"white stork, Ciconia ciconia\",\n",
      "    \"128\": \"black stork, Ciconia nigra\",\n",
      "    \"129\": \"spoonbill\",\n",
      "    \"130\": \"flamingo\",\n",
      "    \"131\": \"little blue heron, Egretta caerulea\",\n",
      "    \"132\": \"American egret, great white heron, Egretta albus\",\n",
      "    \"133\": \"bittern\",\n",
      "    \"134\": \"crane\",\n",
      "    \"135\": \"limpkin, Aramus pictus\",\n",
      "    \"136\": \"European gallinule, Porphyrio porphyrio\",\n",
      "    \"137\": \"American coot, marsh hen, mud hen, water hen, Fulica americana\",\n",
      "    \"138\": \"bustard\",\n",
      "    \"139\": \"ruddy turnstone, Arenaria interpres\",\n",
      "    \"140\": \"red-backed sandpiper, dunlin, Erolia alpina\",\n",
      "    \"141\": \"redshank, Tringa totanus\",\n",
      "    \"142\": \"dowitcher\",\n",
      "    \"143\": \"oystercatcher, oyster catcher\",\n",
      "    \"144\": \"pelican\",\n",
      "    \"145\": \"king penguin, Aptenodytes patagonica\",\n",
      "    \"146\": \"albatross, mollymawk\",\n",
      "    \"147\": \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\",\n",
      "    \"148\": \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\",\n",
      "    \"149\": \"dugong, Dugong dugon\",\n",
      "    \"150\": \"sea lion\",\n",
      "    \"151\": \"Chihuahua\",\n",
      "    \"152\": \"Japanese spaniel\",\n",
      "    \"153\": \"Maltese dog, Maltese terrier, Maltese\",\n",
      "    \"154\": \"Pekinese, Pekingese, Peke\",\n",
      "    \"155\": \"Shih-Tzu\",\n",
      "    \"156\": \"Blenheim spaniel\",\n",
      "    \"157\": \"papillon\",\n",
      "    \"158\": \"toy terrier\",\n",
      "    \"159\": \"Rhodesian ridgeback\",\n",
      "    \"160\": \"Afghan hound, Afghan\",\n",
      "    \"161\": \"basset, basset hound\",\n",
      "    \"162\": \"beagle\",\n",
      "    \"163\": \"bloodhound, sleuthhound\",\n",
      "    \"164\": \"bluetick\",\n",
      "    \"165\": \"black-and-tan coonhound\",\n",
      "    \"166\": \"Walker hound, Walker foxhound\",\n",
      "    \"167\": \"English foxhound\",\n",
      "    \"168\": \"redbone\",\n",
      "    \"169\": \"borzoi, Russian wolfhound\",\n",
      "    \"170\": \"Irish wolfhound\",\n",
      "    \"171\": \"Italian greyhound\",\n",
      "    \"172\": \"whippet\",\n",
      "    \"173\": \"Ibizan hound, Ibizan Podenco\",\n",
      "    \"174\": \"Norwegian elkhound, elkhound\",\n",
      "    \"175\": \"otterhound, otter hound\",\n",
      "    \"176\": \"Saluki, gazelle hound\",\n",
      "    \"177\": \"Scottish deerhound, deerhound\",\n",
      "    \"178\": \"Weimaraner\",\n",
      "    \"179\": \"Staffordshire bullterrier, Staffordshire bull terrier\",\n",
      "    \"180\": \"American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\",\n",
      "    \"181\": \"Bedlington terrier\",\n",
      "    \"182\": \"Border terrier\",\n",
      "    \"183\": \"Kerry blue terrier\",\n",
      "    \"184\": \"Irish terrier\",\n",
      "    \"185\": \"Norfolk terrier\",\n",
      "    \"186\": \"Norwich terrier\",\n",
      "    \"187\": \"Yorkshire terrier\",\n",
      "    \"188\": \"wire-haired fox terrier\",\n",
      "    \"189\": \"Lakeland terrier\",\n",
      "    \"190\": \"Sealyham terrier, Sealyham\",\n",
      "    \"191\": \"Airedale, Airedale terrier\",\n",
      "    \"192\": \"cairn, cairn terrier\",\n",
      "    \"193\": \"Australian terrier\",\n",
      "    \"194\": \"Dandie Dinmont, Dandie Dinmont terrier\",\n",
      "    \"195\": \"Boston bull, Boston terrier\",\n",
      "    \"196\": \"miniature schnauzer\",\n",
      "    \"197\": \"giant schnauzer\",\n",
      "    \"198\": \"standard schnauzer\",\n",
      "    \"199\": \"Scotch terrier, Scottish terrier, Scottie\",\n",
      "    \"200\": \"Tibetan terrier, chrysanthemum dog\",\n",
      "    \"201\": \"silky terrier, Sydney silky\",\n",
      "    \"202\": \"soft-coated wheaten terrier\",\n",
      "    \"203\": \"West Highland white terrier\",\n",
      "    \"204\": \"Lhasa, Lhasa apso\",\n",
      "    \"205\": \"flat-coated retriever\",\n",
      "    \"206\": \"curly-coated retriever\",\n",
      "    \"207\": \"golden retriever\",\n",
      "    \"208\": \"Labrador retriever\",\n",
      "    \"209\": \"Chesapeake Bay retriever\",\n",
      "    \"210\": \"German short-haired pointer\",\n",
      "    \"211\": \"vizsla, Hungarian pointer\",\n",
      "    \"212\": \"English setter\",\n",
      "    \"213\": \"Irish setter, red setter\",\n",
      "    \"214\": \"Gordon setter\",\n",
      "    \"215\": \"Brittany spaniel\",\n",
      "    \"216\": \"clumber, clumber spaniel\",\n",
      "    \"217\": \"English springer, English springer spaniel\",\n",
      "    \"218\": \"Welsh springer spaniel\",\n",
      "    \"219\": \"cocker spaniel, English cocker spaniel, cocker\",\n",
      "    \"220\": \"Sussex spaniel\",\n",
      "    \"221\": \"Irish water spaniel\",\n",
      "    \"222\": \"kuvasz\",\n",
      "    \"223\": \"schipperke\",\n",
      "    \"224\": \"groenendael\",\n",
      "    \"225\": \"malinois\",\n",
      "    \"226\": \"briard\",\n",
      "    \"227\": \"kelpie\",\n",
      "    \"228\": \"komondor\",\n",
      "    \"229\": \"Old English sheepdog, bobtail\",\n",
      "    \"230\": \"Shetland sheepdog, Shetland sheep dog, Shetland\",\n",
      "    \"231\": \"collie\",\n",
      "    \"232\": \"Border collie\",\n",
      "    \"233\": \"Bouvier des Flandres, Bouviers des Flandres\",\n",
      "    \"234\": \"Rottweiler\",\n",
      "    \"235\": \"German shepherd, German shepherd dog, German police dog, alsatian\",\n",
      "    \"236\": \"Doberman, Doberman pinscher\",\n",
      "    \"237\": \"miniature pinscher\",\n",
      "    \"238\": \"Greater Swiss Mountain dog\",\n",
      "    \"239\": \"Bernese mountain dog\",\n",
      "    \"240\": \"Appenzeller\",\n",
      "    \"241\": \"EntleBucher\",\n",
      "    \"242\": \"boxer\",\n",
      "    \"243\": \"bull mastiff\",\n",
      "    \"244\": \"Tibetan mastiff\",\n",
      "    \"245\": \"French bulldog\",\n",
      "    \"246\": \"Great Dane\",\n",
      "    \"247\": \"Saint Bernard, St Bernard\",\n",
      "    \"248\": \"Eskimo dog, husky\",\n",
      "    \"249\": \"malamute, malemute, Alaskan malamute\",\n",
      "    \"250\": \"Siberian husky\",\n",
      "    \"251\": \"dalmatian, coach dog, carriage dog\",\n",
      "    \"252\": \"affenpinscher, monkey pinscher, monkey dog\",\n",
      "    \"253\": \"basenji\",\n",
      "    \"254\": \"pug, pug-dog\",\n",
      "    \"255\": \"Leonberg\",\n",
      "    \"256\": \"Newfoundland, Newfoundland dog\",\n",
      "    \"257\": \"Great Pyrenees\",\n",
      "    \"258\": \"Samoyed, Samoyede\",\n",
      "    \"259\": \"Pomeranian\",\n",
      "    \"260\": \"chow, chow chow\",\n",
      "    \"261\": \"keeshond\",\n",
      "    \"262\": \"Brabancon griffon\",\n",
      "    \"263\": \"Pembroke, Pembroke Welsh corgi\",\n",
      "    \"264\": \"Cardigan, Cardigan Welsh corgi\",\n",
      "    \"265\": \"toy poodle\",\n",
      "    \"266\": \"miniature poodle\",\n",
      "    \"267\": \"standard poodle\",\n",
      "    \"268\": \"Mexican hairless\",\n",
      "    \"269\": \"timber wolf, grey wolf, gray wolf, Canis lupus\",\n",
      "    \"270\": \"white wolf, Arctic wolf, Canis lupus tundrarum\",\n",
      "    \"271\": \"red wolf, maned wolf, Canis rufus, Canis niger\",\n",
      "    \"272\": \"coyote, prairie wolf, brush wolf, Canis latrans\",\n",
      "    \"273\": \"dingo, warrigal, warragal, Canis dingo\",\n",
      "    \"274\": \"dhole, Cuon alpinus\",\n",
      "    \"275\": \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\",\n",
      "    \"276\": \"hyena, hyaena\",\n",
      "    \"277\": \"red fox, Vulpes vulpes\",\n",
      "    \"278\": \"kit fox, Vulpes macrotis\",\n",
      "    \"279\": \"Arctic fox, white fox, Alopex lagopus\",\n",
      "    \"280\": \"grey fox, gray fox, Urocyon cinereoargenteus\",\n",
      "    \"281\": \"tabby, tabby cat\",\n",
      "    \"282\": \"tiger cat\",\n",
      "    \"283\": \"Persian cat\",\n",
      "    \"284\": \"Siamese cat, Siamese\",\n",
      "    \"285\": \"Egyptian cat\",\n",
      "    \"286\": \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\",\n",
      "    \"287\": \"lynx, catamount\",\n",
      "    \"288\": \"leopard, Panthera pardus\",\n",
      "    \"289\": \"snow leopard, ounce, Panthera uncia\",\n",
      "    \"290\": \"jaguar, panther, Panthera onca, Felis onca\",\n",
      "    \"291\": \"lion, king of beasts, Panthera leo\",\n",
      "    \"292\": \"tiger, Panthera tigris\",\n",
      "    \"293\": \"cheetah, chetah, Acinonyx jubatus\",\n",
      "    \"294\": \"brown bear, bruin, Ursus arctos\",\n",
      "    \"295\": \"American black bear, black bear, Ursus americanus, Euarctos americanus\",\n",
      "    \"296\": \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\",\n",
      "    \"297\": \"sloth bear, Melursus ursinus, Ursus ursinus\",\n",
      "    \"298\": \"mongoose\",\n",
      "    \"299\": \"meerkat, mierkat\",\n",
      "    \"300\": \"tiger beetle\",\n",
      "    \"301\": \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\",\n",
      "    \"302\": \"ground beetle, carabid beetle\",\n",
      "    \"303\": \"long-horned beetle, longicorn, longicorn beetle\",\n",
      "    \"304\": \"leaf beetle, chrysomelid\",\n",
      "    \"305\": \"dung beetle\",\n",
      "    \"306\": \"rhinoceros beetle\",\n",
      "    \"307\": \"weevil\",\n",
      "    \"308\": \"fly\",\n",
      "    \"309\": \"bee\",\n",
      "    \"310\": \"ant, emmet, pismire\",\n",
      "    \"311\": \"grasshopper, hopper\",\n",
      "    \"312\": \"cricket\",\n",
      "    \"313\": \"walking stick, walkingstick, stick insect\",\n",
      "    \"314\": \"cockroach, roach\",\n",
      "    \"315\": \"mantis, mantid\",\n",
      "    \"316\": \"cicada, cicala\",\n",
      "    \"317\": \"leafhopper\",\n",
      "    \"318\": \"lacewing, lacewing fly\",\n",
      "    \"319\": \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\",\n",
      "    \"320\": \"damselfly\",\n",
      "    \"321\": \"admiral\",\n",
      "    \"322\": \"ringlet, ringlet butterfly\",\n",
      "    \"323\": \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\",\n",
      "    \"324\": \"cabbage butterfly\",\n",
      "    \"325\": \"sulphur butterfly, sulfur butterfly\",\n",
      "    \"326\": \"lycaenid, lycaenid butterfly\",\n",
      "    \"327\": \"starfish, sea star\",\n",
      "    \"328\": \"sea urchin\",\n",
      "    \"329\": \"sea cucumber, holothurian\",\n",
      "    \"330\": \"wood rabbit, cottontail, cottontail rabbit\",\n",
      "    \"331\": \"hare\",\n",
      "    \"332\": \"Angora, Angora rabbit\",\n",
      "    \"333\": \"hamster\",\n",
      "    \"334\": \"porcupine, hedgehog\",\n",
      "    \"335\": \"fox squirrel, eastern fox squirrel, Sciurus niger\",\n",
      "    \"336\": \"marmot\",\n",
      "    \"337\": \"beaver\",\n",
      "    \"338\": \"guinea pig, Cavia cobaya\",\n",
      "    \"339\": \"sorrel\",\n",
      "    \"340\": \"zebra\",\n",
      "    \"341\": \"hog, pig, grunter, squealer, Sus scrofa\",\n",
      "    \"342\": \"wild boar, boar, Sus scrofa\",\n",
      "    \"343\": \"warthog\",\n",
      "    \"344\": \"hippopotamus, hippo, river horse, Hippopotamus amphibius\",\n",
      "    \"345\": \"ox\",\n",
      "    \"346\": \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\",\n",
      "    \"347\": \"bison\",\n",
      "    \"348\": \"ram, tup\",\n",
      "    \"349\": \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\",\n",
      "    \"350\": \"ibex, Capra ibex\",\n",
      "    \"351\": \"hartebeest\",\n",
      "    \"352\": \"impala, Aepyceros melampus\",\n",
      "    \"353\": \"gazelle\",\n",
      "    \"354\": \"Arabian camel, dromedary, Camelus dromedarius\",\n",
      "    \"355\": \"llama\",\n",
      "    \"356\": \"weasel\",\n",
      "    \"357\": \"mink\",\n",
      "    \"358\": \"polecat, fitch, foulmart, foumart, Mustela putorius\",\n",
      "    \"359\": \"black-footed ferret, ferret, Mustela nigripes\",\n",
      "    \"360\": \"otter\",\n",
      "    \"361\": \"skunk, polecat, wood pussy\",\n",
      "    \"362\": \"badger\",\n",
      "    \"363\": \"armadillo\",\n",
      "    \"364\": \"three-toed sloth, ai, Bradypus tridactylus\",\n",
      "    \"365\": \"orangutan, orang, orangutang, Pongo pygmaeus\",\n",
      "    \"366\": \"gorilla, Gorilla gorilla\",\n",
      "    \"367\": \"chimpanzee, chimp, Pan troglodytes\",\n",
      "    \"368\": \"gibbon, Hylobates lar\",\n",
      "    \"369\": \"siamang, Hylobates syndactylus, Symphalangus syndactylus\",\n",
      "    \"370\": \"guenon, guenon monkey\",\n",
      "    \"371\": \"patas, hussar monkey, Erythrocebus patas\",\n",
      "    \"372\": \"baboon\",\n",
      "    \"373\": \"macaque\",\n",
      "    \"374\": \"langur\",\n",
      "    \"375\": \"colobus, colobus monkey\",\n",
      "    \"376\": \"proboscis monkey, Nasalis larvatus\",\n",
      "    \"377\": \"marmoset\",\n",
      "    \"378\": \"capuchin, ringtail, Cebus capucinus\",\n",
      "    \"379\": \"howler monkey, howler\",\n",
      "    \"380\": \"titi, titi monkey\",\n",
      "    \"381\": \"spider monkey, Ateles geoffroyi\",\n",
      "    \"382\": \"squirrel monkey, Saimiri sciureus\",\n",
      "    \"383\": \"Madagascar cat, ring-tailed lemur, Lemur catta\",\n",
      "    \"384\": \"indri, indris, Indri indri, Indri brevicaudatus\",\n",
      "    \"385\": \"Indian elephant, Elephas maximus\",\n",
      "    \"386\": \"African elephant, Loxodonta africana\",\n",
      "    \"387\": \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\",\n",
      "    \"388\": \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\",\n",
      "    \"389\": \"barracouta, snoek\",\n",
      "    \"390\": \"eel\",\n",
      "    \"391\": \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\",\n",
      "    \"392\": \"rock beauty, Holocanthus tricolor\",\n",
      "    \"393\": \"anemone fish\",\n",
      "    \"394\": \"sturgeon\",\n",
      "    \"395\": \"gar, garfish, garpike, billfish, Lepisosteus osseus\",\n",
      "    \"396\": \"lionfish\",\n",
      "    \"397\": \"puffer, pufferfish, blowfish, globefish\",\n",
      "    \"398\": \"abacus\",\n",
      "    \"399\": \"abaya\",\n",
      "    \"400\": \"academic gown, academic robe, judge's robe\",\n",
      "    \"401\": \"accordion, piano accordion, squeeze box\",\n",
      "    \"402\": \"acoustic guitar\",\n",
      "    \"403\": \"aircraft carrier, carrier, flattop, attack aircraft carrier\",\n",
      "    \"404\": \"airliner\",\n",
      "    \"405\": \"airship, dirigible\",\n",
      "    \"406\": \"altar\",\n",
      "    \"407\": \"ambulance\",\n",
      "    \"408\": \"amphibian, amphibious vehicle\",\n",
      "    \"409\": \"analog clock\",\n",
      "    \"410\": \"apiary, bee house\",\n",
      "    \"411\": \"apron\",\n",
      "    \"412\": \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\",\n",
      "    \"413\": \"assault rifle, assault gun\",\n",
      "    \"414\": \"backpack, back pack, knapsack, packsack, rucksack, haversack\",\n",
      "    \"415\": \"bakery, bakeshop, bakehouse\",\n",
      "    \"416\": \"balance beam, beam\",\n",
      "    \"417\": \"balloon\",\n",
      "    \"418\": \"ballpoint, ballpoint pen, ballpen, Biro\",\n",
      "    \"419\": \"Band Aid\",\n",
      "    \"420\": \"banjo\",\n",
      "    \"421\": \"bannister, banister, balustrade, balusters, handrail\",\n",
      "    \"422\": \"barbell\",\n",
      "    \"423\": \"barber chair\",\n",
      "    \"424\": \"barbershop\",\n",
      "    \"425\": \"barn\",\n",
      "    \"426\": \"barometer\",\n",
      "    \"427\": \"barrel, cask\",\n",
      "    \"428\": \"barrow, garden cart, lawn cart, wheelbarrow\",\n",
      "    \"429\": \"baseball\",\n",
      "    \"430\": \"basketball\",\n",
      "    \"431\": \"bassinet\",\n",
      "    \"432\": \"bassoon\",\n",
      "    \"433\": \"bathing cap, swimming cap\",\n",
      "    \"434\": \"bath towel\",\n",
      "    \"435\": \"bathtub, bathing tub, bath, tub\",\n",
      "    \"436\": \"beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\",\n",
      "    \"437\": \"beacon, lighthouse, beacon light, pharos\",\n",
      "    \"438\": \"beaker\",\n",
      "    \"439\": \"bearskin, busby, shako\",\n",
      "    \"440\": \"beer bottle\",\n",
      "    \"441\": \"beer glass\",\n",
      "    \"442\": \"bell cote, bell cot\",\n",
      "    \"443\": \"bib\",\n",
      "    \"444\": \"bicycle-built-for-two, tandem bicycle, tandem\",\n",
      "    \"445\": \"bikini, two-piece\",\n",
      "    \"446\": \"binder, ring-binder\",\n",
      "    \"447\": \"binoculars, field glasses, opera glasses\",\n",
      "    \"448\": \"birdhouse\",\n",
      "    \"449\": \"boathouse\",\n",
      "    \"450\": \"bobsled, bobsleigh, bob\",\n",
      "    \"451\": \"bolo tie, bolo, bola tie, bola\",\n",
      "    \"452\": \"bonnet, poke bonnet\",\n",
      "    \"453\": \"bookcase\",\n",
      "    \"454\": \"bookshop, bookstore, bookstall\",\n",
      "    \"455\": \"bottlecap\",\n",
      "    \"456\": \"bow\",\n",
      "    \"457\": \"bow tie, bow-tie, bowtie\",\n",
      "    \"458\": \"brass, memorial tablet, plaque\",\n",
      "    \"459\": \"brassiere, bra, bandeau\",\n",
      "    \"460\": \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\",\n",
      "    \"461\": \"breastplate, aegis, egis\",\n",
      "    \"462\": \"broom\",\n",
      "    \"463\": \"bucket, pail\",\n",
      "    \"464\": \"buckle\",\n",
      "    \"465\": \"bulletproof vest\",\n",
      "    \"466\": \"bullet train, bullet\",\n",
      "    \"467\": \"butcher shop, meat market\",\n",
      "    \"468\": \"cab, hack, taxi, taxicab\",\n",
      "    \"469\": \"caldron, cauldron\",\n",
      "    \"470\": \"candle, taper, wax light\",\n",
      "    \"471\": \"cannon\",\n",
      "    \"472\": \"canoe\",\n",
      "    \"473\": \"can opener, tin opener\",\n",
      "    \"474\": \"cardigan\",\n",
      "    \"475\": \"car mirror\",\n",
      "    \"476\": \"carousel, carrousel, merry-go-round, roundabout, whirligig\",\n",
      "    \"477\": \"carpenter's kit, tool kit\",\n",
      "    \"478\": \"carton\",\n",
      "    \"479\": \"car wheel\",\n",
      "    \"480\": \"cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\",\n",
      "    \"481\": \"cassette\",\n",
      "    \"482\": \"cassette player\",\n",
      "    \"483\": \"castle\",\n",
      "    \"484\": \"catamaran\",\n",
      "    \"485\": \"CD player\",\n",
      "    \"486\": \"cello, violoncello\",\n",
      "    \"487\": \"cellular telephone, cellular phone, cellphone, cell, mobile phone\",\n",
      "    \"488\": \"chain\",\n",
      "    \"489\": \"chainlink fence\",\n",
      "    \"490\": \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour\",\n",
      "    \"491\": \"chain saw, chainsaw\",\n",
      "    \"492\": \"chest\",\n",
      "    \"493\": \"chiffonier, commode\",\n",
      "    \"494\": \"chime, bell, gong\",\n",
      "    \"495\": \"china cabinet, china closet\",\n",
      "    \"496\": \"Christmas stocking\",\n",
      "    \"497\": \"church, church building\",\n",
      "    \"498\": \"cinema, movie theater, movie theatre, movie house, picture palace\",\n",
      "    \"499\": \"cleaver, meat cleaver, chopper\",\n",
      "    \"500\": \"cliff dwelling\",\n",
      "    \"501\": \"cloak\",\n",
      "    \"502\": \"clog, geta, patten, sabot\",\n",
      "    \"503\": \"cocktail shaker\",\n",
      "    \"504\": \"coffee mug\",\n",
      "    \"505\": \"coffeepot\",\n",
      "    \"506\": \"coil, spiral, volute, whorl, helix\",\n",
      "    \"507\": \"combination lock\",\n",
      "    \"508\": \"computer keyboard, keypad\",\n",
      "    \"509\": \"confectionery, confectionary, candy store\",\n",
      "    \"510\": \"container ship, containership, container vessel\",\n",
      "    \"511\": \"convertible\",\n",
      "    \"512\": \"corkscrew, bottle screw\",\n",
      "    \"513\": \"cornet, horn, trumpet, trump\",\n",
      "    \"514\": \"cowboy boot\",\n",
      "    \"515\": \"cowboy hat, ten-gallon hat\",\n",
      "    \"516\": \"cradle\",\n",
      "    \"517\": \"crane\",\n",
      "    \"518\": \"crash helmet\",\n",
      "    \"519\": \"crate\",\n",
      "    \"520\": \"crib, cot\",\n",
      "    \"521\": \"Crock Pot\",\n",
      "    \"522\": \"croquet ball\",\n",
      "    \"523\": \"crutch\",\n",
      "    \"524\": \"cuirass\",\n",
      "    \"525\": \"dam, dike, dyke\",\n",
      "    \"526\": \"desk\",\n",
      "    \"527\": \"desktop computer\",\n",
      "    \"528\": \"dial telephone, dial phone\",\n",
      "    \"529\": \"diaper, nappy, napkin\",\n",
      "    \"530\": \"digital clock\",\n",
      "    \"531\": \"digital watch\",\n",
      "    \"532\": \"dining table, board\",\n",
      "    \"533\": \"dishrag, dishcloth\",\n",
      "    \"534\": \"dishwasher, dish washer, dishwashing machine\",\n",
      "    \"535\": \"disk brake, disc brake\",\n",
      "    \"536\": \"dock, dockage, docking facility\",\n",
      "    \"537\": \"dogsled, dog sled, dog sleigh\",\n",
      "    \"538\": \"dome\",\n",
      "    \"539\": \"doormat, welcome mat\",\n",
      "    \"540\": \"drilling platform, offshore rig\",\n",
      "    \"541\": \"drum, membranophone, tympan\",\n",
      "    \"542\": \"drumstick\",\n",
      "    \"543\": \"dumbbell\",\n",
      "    \"544\": \"Dutch oven\",\n",
      "    \"545\": \"electric fan, blower\",\n",
      "    \"546\": \"electric guitar\",\n",
      "    \"547\": \"electric locomotive\",\n",
      "    \"548\": \"entertainment center\",\n",
      "    \"549\": \"envelope\",\n",
      "    \"550\": \"espresso maker\",\n",
      "    \"551\": \"face powder\",\n",
      "    \"552\": \"feather boa, boa\",\n",
      "    \"553\": \"file, file cabinet, filing cabinet\",\n",
      "    \"554\": \"fireboat\",\n",
      "    \"555\": \"fire engine, fire truck\",\n",
      "    \"556\": \"fire screen, fireguard\",\n",
      "    \"557\": \"flagpole, flagstaff\",\n",
      "    \"558\": \"flute, transverse flute\",\n",
      "    \"559\": \"folding chair\",\n",
      "    \"560\": \"football helmet\",\n",
      "    \"561\": \"forklift\",\n",
      "    \"562\": \"fountain\",\n",
      "    \"563\": \"fountain pen\",\n",
      "    \"564\": \"four-poster\",\n",
      "    \"565\": \"freight car\",\n",
      "    \"566\": \"French horn, horn\",\n",
      "    \"567\": \"frying pan, frypan, skillet\",\n",
      "    \"568\": \"fur coat\",\n",
      "    \"569\": \"garbage truck, dustcart\",\n",
      "    \"570\": \"gasmask, respirator, gas helmet\",\n",
      "    \"571\": \"gas pump, gasoline pump, petrol pump, island dispenser\",\n",
      "    \"572\": \"goblet\",\n",
      "    \"573\": \"go-kart\",\n",
      "    \"574\": \"golf ball\",\n",
      "    \"575\": \"golfcart, golf cart\",\n",
      "    \"576\": \"gondola\",\n",
      "    \"577\": \"gong, tam-tam\",\n",
      "    \"578\": \"gown\",\n",
      "    \"579\": \"grand piano, grand\",\n",
      "    \"580\": \"greenhouse, nursery, glasshouse\",\n",
      "    \"581\": \"grille, radiator grille\",\n",
      "    \"582\": \"grocery store, grocery, food market, market\",\n",
      "    \"583\": \"guillotine\",\n",
      "    \"584\": \"hair slide\",\n",
      "    \"585\": \"hair spray\",\n",
      "    \"586\": \"half track\",\n",
      "    \"587\": \"hammer\",\n",
      "    \"588\": \"hamper\",\n",
      "    \"589\": \"hand blower, blow dryer, blow drier, hair dryer, hair drier\",\n",
      "    \"590\": \"hand-held computer, hand-held microcomputer\",\n",
      "    \"591\": \"handkerchief, hankie, hanky, hankey\",\n",
      "    \"592\": \"hard disc, hard disk, fixed disk\",\n",
      "    \"593\": \"harmonica, mouth organ, harp, mouth harp\",\n",
      "    \"594\": \"harp\",\n",
      "    \"595\": \"harvester, reaper\",\n",
      "    \"596\": \"hatchet\",\n",
      "    \"597\": \"holster\",\n",
      "    \"598\": \"home theater, home theatre\",\n",
      "    \"599\": \"honeycomb\",\n",
      "    \"600\": \"hook, claw\",\n",
      "    \"601\": \"hoopskirt, crinoline\",\n",
      "    \"602\": \"horizontal bar, high bar\",\n",
      "    \"603\": \"horse cart, horse-cart\",\n",
      "    \"604\": \"hourglass\",\n",
      "    \"605\": \"iPod\",\n",
      "    \"606\": \"iron, smoothing iron\",\n",
      "    \"607\": \"jack-o'-lantern\",\n",
      "    \"608\": \"jean, blue jean, denim\",\n",
      "    \"609\": \"jeep, landrover\",\n",
      "    \"610\": \"jersey, T-shirt, tee shirt\",\n",
      "    \"611\": \"jigsaw puzzle\",\n",
      "    \"612\": \"jinrikisha, ricksha, rickshaw\",\n",
      "    \"613\": \"joystick\",\n",
      "    \"614\": \"kimono\",\n",
      "    \"615\": \"knee pad\",\n",
      "    \"616\": \"knot\",\n",
      "    \"617\": \"lab coat, laboratory coat\",\n",
      "    \"618\": \"ladle\",\n",
      "    \"619\": \"lampshade, lamp shade\",\n",
      "    \"620\": \"laptop, laptop computer\",\n",
      "    \"621\": \"lawn mower, mower\",\n",
      "    \"622\": \"lens cap, lens cover\",\n",
      "    \"623\": \"letter opener, paper knife, paperknife\",\n",
      "    \"624\": \"library\",\n",
      "    \"625\": \"lifeboat\",\n",
      "    \"626\": \"lighter, light, igniter, ignitor\",\n",
      "    \"627\": \"limousine, limo\",\n",
      "    \"628\": \"liner, ocean liner\",\n",
      "    \"629\": \"lipstick, lip rouge\",\n",
      "    \"630\": \"Loafer\",\n",
      "    \"631\": \"lotion\",\n",
      "    \"632\": \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\",\n",
      "    \"633\": \"loupe, jeweler's loupe\",\n",
      "    \"634\": \"lumbermill, sawmill\",\n",
      "    \"635\": \"magnetic compass\",\n",
      "    \"636\": \"mailbag, postbag\",\n",
      "    \"637\": \"mailbox, letter box\",\n",
      "    \"638\": \"maillot\",\n",
      "    \"639\": \"maillot, tank suit\",\n",
      "    \"640\": \"manhole cover\",\n",
      "    \"641\": \"maraca\",\n",
      "    \"642\": \"marimba, xylophone\",\n",
      "    \"643\": \"mask\",\n",
      "    \"644\": \"matchstick\",\n",
      "    \"645\": \"maypole\",\n",
      "    \"646\": \"maze, labyrinth\",\n",
      "    \"647\": \"measuring cup\",\n",
      "    \"648\": \"medicine chest, medicine cabinet\",\n",
      "    \"649\": \"megalith, megalithic structure\",\n",
      "    \"650\": \"microphone, mike\",\n",
      "    \"651\": \"microwave, microwave oven\",\n",
      "    \"652\": \"military uniform\",\n",
      "    \"653\": \"milk can\",\n",
      "    \"654\": \"minibus\",\n",
      "    \"655\": \"miniskirt, mini\",\n",
      "    \"656\": \"minivan\",\n",
      "    \"657\": \"missile\",\n",
      "    \"658\": \"mitten\",\n",
      "    \"659\": \"mixing bowl\",\n",
      "    \"660\": \"mobile home, manufactured home\",\n",
      "    \"661\": \"Model T\",\n",
      "    \"662\": \"modem\",\n",
      "    \"663\": \"monastery\",\n",
      "    \"664\": \"monitor\",\n",
      "    \"665\": \"moped\",\n",
      "    \"666\": \"mortar\",\n",
      "    \"667\": \"mortarboard\",\n",
      "    \"668\": \"mosque\",\n",
      "    \"669\": \"mosquito net\",\n",
      "    \"670\": \"motor scooter, scooter\",\n",
      "    \"671\": \"mountain bike, all-terrain bike, off-roader\",\n",
      "    \"672\": \"mountain tent\",\n",
      "    \"673\": \"mouse, computer mouse\",\n",
      "    \"674\": \"mousetrap\",\n",
      "    \"675\": \"moving van\",\n",
      "    \"676\": \"muzzle\",\n",
      "    \"677\": \"nail\",\n",
      "    \"678\": \"neck brace\",\n",
      "    \"679\": \"necklace\",\n",
      "    \"680\": \"nipple\",\n",
      "    \"681\": \"notebook, notebook computer\",\n",
      "    \"682\": \"obelisk\",\n",
      "    \"683\": \"oboe, hautboy, hautbois\",\n",
      "    \"684\": \"ocarina, sweet potato\",\n",
      "    \"685\": \"odometer, hodometer, mileometer, milometer\",\n",
      "    \"686\": \"oil filter\",\n",
      "    \"687\": \"organ, pipe organ\",\n",
      "    \"688\": \"oscilloscope, scope, cathode-ray oscilloscope, CRO\",\n",
      "    \"689\": \"overskirt\",\n",
      "    \"690\": \"oxcart\",\n",
      "    \"691\": \"oxygen mask\",\n",
      "    \"692\": \"packet\",\n",
      "    \"693\": \"paddle, boat paddle\",\n",
      "    \"694\": \"paddlewheel, paddle wheel\",\n",
      "    \"695\": \"padlock\",\n",
      "    \"696\": \"paintbrush\",\n",
      "    \"697\": \"pajama, pyjama, pj's, jammies\",\n",
      "    \"698\": \"palace\",\n",
      "    \"699\": \"panpipe, pandean pipe, syrinx\",\n",
      "    \"700\": \"paper towel\",\n",
      "    \"701\": \"parachute, chute\",\n",
      "    \"702\": \"parallel bars, bars\",\n",
      "    \"703\": \"park bench\",\n",
      "    \"704\": \"parking meter\",\n",
      "    \"705\": \"passenger car, coach, carriage\",\n",
      "    \"706\": \"patio, terrace\",\n",
      "    \"707\": \"pay-phone, pay-station\",\n",
      "    \"708\": \"pedestal, plinth, footstall\",\n",
      "    \"709\": \"pencil box, pencil case\",\n",
      "    \"710\": \"pencil sharpener\",\n",
      "    \"711\": \"perfume, essence\",\n",
      "    \"712\": \"Petri dish\",\n",
      "    \"713\": \"photocopier\",\n",
      "    \"714\": \"pick, plectrum, plectron\",\n",
      "    \"715\": \"pickelhaube\",\n",
      "    \"716\": \"picket fence, paling\",\n",
      "    \"717\": \"pickup, pickup truck\",\n",
      "    \"718\": \"pier\",\n",
      "    \"719\": \"piggy bank, penny bank\",\n",
      "    \"720\": \"pill bottle\",\n",
      "    \"721\": \"pillow\",\n",
      "    \"722\": \"ping-pong ball\",\n",
      "    \"723\": \"pinwheel\",\n",
      "    \"724\": \"pirate, pirate ship\",\n",
      "    \"725\": \"pitcher, ewer\",\n",
      "    \"726\": \"plane, carpenter's plane, woodworking plane\",\n",
      "    \"727\": \"planetarium\",\n",
      "    \"728\": \"plastic bag\",\n",
      "    \"729\": \"plate rack\",\n",
      "    \"730\": \"plow, plough\",\n",
      "    \"731\": \"plunger, plumber's helper\",\n",
      "    \"732\": \"Polaroid camera, Polaroid Land camera\",\n",
      "    \"733\": \"pole\",\n",
      "    \"734\": \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\",\n",
      "    \"735\": \"poncho\",\n",
      "    \"736\": \"pool table, billiard table, snooker table\",\n",
      "    \"737\": \"pop bottle, soda bottle\",\n",
      "    \"738\": \"pot, flowerpot\",\n",
      "    \"739\": \"potter's wheel\",\n",
      "    \"740\": \"power drill\",\n",
      "    \"741\": \"prayer rug, prayer mat\",\n",
      "    \"742\": \"printer\",\n",
      "    \"743\": \"prison, prison house\",\n",
      "    \"744\": \"projectile, missile\",\n",
      "    \"745\": \"projector\",\n",
      "    \"746\": \"puck, hockey puck\",\n",
      "    \"747\": \"punching bag, punch bag, punching ball, punchball\",\n",
      "    \"748\": \"purse\",\n",
      "    \"749\": \"quill, quill pen\",\n",
      "    \"750\": \"quilt, comforter, comfort, puff\",\n",
      "    \"751\": \"racer, race car, racing car\",\n",
      "    \"752\": \"racket, racquet\",\n",
      "    \"753\": \"radiator\",\n",
      "    \"754\": \"radio, wireless\",\n",
      "    \"755\": \"radio telescope, radio reflector\",\n",
      "    \"756\": \"rain barrel\",\n",
      "    \"757\": \"recreational vehicle, RV, R.V.\",\n",
      "    \"758\": \"reel\",\n",
      "    \"759\": \"reflex camera\",\n",
      "    \"760\": \"refrigerator, icebox\",\n",
      "    \"761\": \"remote control, remote\",\n",
      "    \"762\": \"restaurant, eating house, eating place, eatery\",\n",
      "    \"763\": \"revolver, six-gun, six-shooter\",\n",
      "    \"764\": \"rifle\",\n",
      "    \"765\": \"rocking chair, rocker\",\n",
      "    \"766\": \"rotisserie\",\n",
      "    \"767\": \"rubber eraser, rubber, pencil eraser\",\n",
      "    \"768\": \"rugby ball\",\n",
      "    \"769\": \"rule, ruler\",\n",
      "    \"770\": \"running shoe\",\n",
      "    \"771\": \"safe\",\n",
      "    \"772\": \"safety pin\",\n",
      "    \"773\": \"saltshaker, salt shaker\",\n",
      "    \"774\": \"sandal\",\n",
      "    \"775\": \"sarong\",\n",
      "    \"776\": \"sax, saxophone\",\n",
      "    \"777\": \"scabbard\",\n",
      "    \"778\": \"scale, weighing machine\",\n",
      "    \"779\": \"school bus\",\n",
      "    \"780\": \"schooner\",\n",
      "    \"781\": \"scoreboard\",\n",
      "    \"782\": \"screen, CRT screen\",\n",
      "    \"783\": \"screw\",\n",
      "    \"784\": \"screwdriver\",\n",
      "    \"785\": \"seat belt, seatbelt\",\n",
      "    \"786\": \"sewing machine\",\n",
      "    \"787\": \"shield, buckler\",\n",
      "    \"788\": \"shoe shop, shoe-shop, shoe store\",\n",
      "    \"789\": \"shoji\",\n",
      "    \"790\": \"shopping basket\",\n",
      "    \"791\": \"shopping cart\",\n",
      "    \"792\": \"shovel\",\n",
      "    \"793\": \"shower cap\",\n",
      "    \"794\": \"shower curtain\",\n",
      "    \"795\": \"ski\",\n",
      "    \"796\": \"ski mask\",\n",
      "    \"797\": \"sleeping bag\",\n",
      "    \"798\": \"slide rule, slipstick\",\n",
      "    \"799\": \"sliding door\",\n",
      "    \"800\": \"slot, one-armed bandit\",\n",
      "    \"801\": \"snorkel\",\n",
      "    \"802\": \"snowmobile\",\n",
      "    \"803\": \"snowplow, snowplough\",\n",
      "    \"804\": \"soap dispenser\",\n",
      "    \"805\": \"soccer ball\",\n",
      "    \"806\": \"sock\",\n",
      "    \"807\": \"solar dish, solar collector, solar furnace\",\n",
      "    \"808\": \"sombrero\",\n",
      "    \"809\": \"soup bowl\",\n",
      "    \"810\": \"space bar\",\n",
      "    \"811\": \"space heater\",\n",
      "    \"812\": \"space shuttle\",\n",
      "    \"813\": \"spatula\",\n",
      "    \"814\": \"speedboat\",\n",
      "    \"815\": \"spider web, spider's web\",\n",
      "    \"816\": \"spindle\",\n",
      "    \"817\": \"sports car, sport car\",\n",
      "    \"818\": \"spotlight, spot\",\n",
      "    \"819\": \"stage\",\n",
      "    \"820\": \"steam locomotive\",\n",
      "    \"821\": \"steel arch bridge\",\n",
      "    \"822\": \"steel drum\",\n",
      "    \"823\": \"stethoscope\",\n",
      "    \"824\": \"stole\",\n",
      "    \"825\": \"stone wall\",\n",
      "    \"826\": \"stopwatch, stop watch\",\n",
      "    \"827\": \"stove\",\n",
      "    \"828\": \"strainer\",\n",
      "    \"829\": \"streetcar, tram, tramcar, trolley, trolley car\",\n",
      "    \"830\": \"stretcher\",\n",
      "    \"831\": \"studio couch, day bed\",\n",
      "    \"832\": \"stupa, tope\",\n",
      "    \"833\": \"submarine, pigboat, sub, U-boat\",\n",
      "    \"834\": \"suit, suit of clothes\",\n",
      "    \"835\": \"sundial\",\n",
      "    \"836\": \"sunglass\",\n",
      "    \"837\": \"sunglasses, dark glasses, shades\",\n",
      "    \"838\": \"sunscreen, sunblock, sun blocker\",\n",
      "    \"839\": \"suspension bridge\",\n",
      "    \"840\": \"swab, swob, mop\",\n",
      "    \"841\": \"sweatshirt\",\n",
      "    \"842\": \"swimming trunks, bathing trunks\",\n",
      "    \"843\": \"swing\",\n",
      "    \"844\": \"switch, electric switch, electrical switch\",\n",
      "    \"845\": \"syringe\",\n",
      "    \"846\": \"table lamp\",\n",
      "    \"847\": \"tank, army tank, armored combat vehicle, armoured combat vehicle\",\n",
      "    \"848\": \"tape player\",\n",
      "    \"849\": \"teapot\",\n",
      "    \"850\": \"teddy, teddy bear\",\n",
      "    \"851\": \"television, television system\",\n",
      "    \"852\": \"tennis ball\",\n",
      "    \"853\": \"thatch, thatched roof\",\n",
      "    \"854\": \"theater curtain, theatre curtain\",\n",
      "    \"855\": \"thimble\",\n",
      "    \"856\": \"thresher, thrasher, threshing machine\",\n",
      "    \"857\": \"throne\",\n",
      "    \"858\": \"tile roof\",\n",
      "    \"859\": \"toaster\",\n",
      "    \"860\": \"tobacco shop, tobacconist shop, tobacconist\",\n",
      "    \"861\": \"toilet seat\",\n",
      "    \"862\": \"torch\",\n",
      "    \"863\": \"totem pole\",\n",
      "    \"864\": \"tow truck, tow car, wrecker\",\n",
      "    \"865\": \"toyshop\",\n",
      "    \"866\": \"tractor\",\n",
      "    \"867\": \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\",\n",
      "    \"868\": \"tray\",\n",
      "    \"869\": \"trench coat\",\n",
      "    \"870\": \"tricycle, trike, velocipede\",\n",
      "    \"871\": \"trimaran\",\n",
      "    \"872\": \"tripod\",\n",
      "    \"873\": \"triumphal arch\",\n",
      "    \"874\": \"trolleybus, trolley coach, trackless trolley\",\n",
      "    \"875\": \"trombone\",\n",
      "    \"876\": \"tub, vat\",\n",
      "    \"877\": \"turnstile\",\n",
      "    \"878\": \"typewriter keyboard\",\n",
      "    \"879\": \"umbrella\",\n",
      "    \"880\": \"unicycle, monocycle\",\n",
      "    \"881\": \"upright, upright piano\",\n",
      "    \"882\": \"vacuum, vacuum cleaner\",\n",
      "    \"883\": \"vase\",\n",
      "    \"884\": \"vault\",\n",
      "    \"885\": \"velvet\",\n",
      "    \"886\": \"vending machine\",\n",
      "    \"887\": \"vestment\",\n",
      "    \"888\": \"viaduct\",\n",
      "    \"889\": \"violin, fiddle\",\n",
      "    \"890\": \"volleyball\",\n",
      "    \"891\": \"waffle iron\",\n",
      "    \"892\": \"wall clock\",\n",
      "    \"893\": \"wallet, billfold, notecase, pocketbook\",\n",
      "    \"894\": \"wardrobe, closet, press\",\n",
      "    \"895\": \"warplane, military plane\",\n",
      "    \"896\": \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\",\n",
      "    \"897\": \"washer, automatic washer, washing machine\",\n",
      "    \"898\": \"water bottle\",\n",
      "    \"899\": \"water jug\",\n",
      "    \"900\": \"water tower\",\n",
      "    \"901\": \"whiskey jug\",\n",
      "    \"902\": \"whistle\",\n",
      "    \"903\": \"wig\",\n",
      "    \"904\": \"window screen\",\n",
      "    \"905\": \"window shade\",\n",
      "    \"906\": \"Windsor tie\",\n",
      "    \"907\": \"wine bottle\",\n",
      "    \"908\": \"wing\",\n",
      "    \"909\": \"wok\",\n",
      "    \"910\": \"wooden spoon\",\n",
      "    \"911\": \"wool, woolen, woollen\",\n",
      "    \"912\": \"worm fence, snake fence, snake-rail fence, Virginia fence\",\n",
      "    \"913\": \"wreck\",\n",
      "    \"914\": \"yawl\",\n",
      "    \"915\": \"yurt\",\n",
      "    \"916\": \"web site, website, internet site, site\",\n",
      "    \"917\": \"comic book\",\n",
      "    \"918\": \"crossword puzzle, crossword\",\n",
      "    \"919\": \"street sign\",\n",
      "    \"920\": \"traffic light, traffic signal, stoplight\",\n",
      "    \"921\": \"book jacket, dust cover, dust jacket, dust wrapper\",\n",
      "    \"922\": \"menu\",\n",
      "    \"923\": \"plate\",\n",
      "    \"924\": \"guacamole\",\n",
      "    \"925\": \"consomme\",\n",
      "    \"926\": \"hot pot, hotpot\",\n",
      "    \"927\": \"trifle\",\n",
      "    \"928\": \"ice cream, icecream\",\n",
      "    \"929\": \"ice lolly, lolly, lollipop, popsicle\",\n",
      "    \"930\": \"French loaf\",\n",
      "    \"931\": \"bagel, beigel\",\n",
      "    \"932\": \"pretzel\",\n",
      "    \"933\": \"cheeseburger\",\n",
      "    \"934\": \"hotdog, hot dog, red hot\",\n",
      "    \"935\": \"mashed potato\",\n",
      "    \"936\": \"head cabbage\",\n",
      "    \"937\": \"broccoli\",\n",
      "    \"938\": \"cauliflower\",\n",
      "    \"939\": \"zucchini, courgette\",\n",
      "    \"940\": \"spaghetti squash\",\n",
      "    \"941\": \"acorn squash\",\n",
      "    \"942\": \"butternut squash\",\n",
      "    \"943\": \"cucumber, cuke\",\n",
      "    \"944\": \"artichoke, globe artichoke\",\n",
      "    \"945\": \"bell pepper\",\n",
      "    \"946\": \"cardoon\",\n",
      "    \"947\": \"mushroom\",\n",
      "    \"948\": \"Granny Smith\",\n",
      "    \"949\": \"strawberry\",\n",
      "    \"950\": \"orange\",\n",
      "    \"951\": \"lemon\",\n",
      "    \"952\": \"fig\",\n",
      "    \"953\": \"pineapple, ananas\",\n",
      "    \"954\": \"banana\",\n",
      "    \"955\": \"jackfruit, jak, jack\",\n",
      "    \"956\": \"custard apple\",\n",
      "    \"957\": \"pomegranate\",\n",
      "    \"958\": \"hay\",\n",
      "    \"959\": \"carbonara\",\n",
      "    \"960\": \"chocolate sauce, chocolate syrup\",\n",
      "    \"961\": \"dough\",\n",
      "    \"962\": \"meat loaf, meatloaf\",\n",
      "    \"963\": \"pizza, pizza pie\",\n",
      "    \"964\": \"potpie\",\n",
      "    \"965\": \"burrito\",\n",
      "    \"966\": \"red wine\",\n",
      "    \"967\": \"espresso\",\n",
      "    \"968\": \"cup\",\n",
      "    \"969\": \"eggnog\",\n",
      "    \"970\": \"alp\",\n",
      "    \"971\": \"bubble\",\n",
      "    \"972\": \"cliff, drop, drop-off\",\n",
      "    \"973\": \"coral reef\",\n",
      "    \"974\": \"geyser\",\n",
      "    \"975\": \"lakeside, lakeshore\",\n",
      "    \"976\": \"promontory, headland, head, foreland\",\n",
      "    \"977\": \"sandbar, sand bar\",\n",
      "    \"978\": \"seashore, coast, seacoast, sea-coast\",\n",
      "    \"979\": \"valley, vale\",\n",
      "    \"980\": \"volcano\",\n",
      "    \"981\": \"ballplayer, baseball player\",\n",
      "    \"982\": \"groom, bridegroom\",\n",
      "    \"983\": \"scuba diver\",\n",
      "    \"984\": \"rapeseed\",\n",
      "    \"985\": \"daisy\",\n",
      "    \"986\": \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\",\n",
      "    \"987\": \"corn\",\n",
      "    \"988\": \"acorn\",\n",
      "    \"989\": \"hip, rose hip, rosehip\",\n",
      "    \"990\": \"buckeye, horse chestnut, conker\",\n",
      "    \"991\": \"coral fungus\",\n",
      "    \"992\": \"agaric\",\n",
      "    \"993\": \"gyromitra\",\n",
      "    \"994\": \"stinkhorn, carrion fungus\",\n",
      "    \"995\": \"earthstar\",\n",
      "    \"996\": \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\",\n",
      "    \"997\": \"bolete\",\n",
      "    \"998\": \"ear, spike, capitulum\",\n",
      "    \"999\": \"toilet tissue, toilet paper, bathroom tissue\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Afghan hound, Afghan\": 160,\n",
      "    \"African chameleon, Chamaeleo chamaeleon\": 47,\n",
      "    \"African crocodile, Nile crocodile, Crocodylus niloticus\": 49,\n",
      "    \"African elephant, Loxodonta africana\": 386,\n",
      "    \"African grey, African gray, Psittacus erithacus\": 87,\n",
      "    \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\": 275,\n",
      "    \"Airedale, Airedale terrier\": 191,\n",
      "    \"American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\": 180,\n",
      "    \"American alligator, Alligator mississipiensis\": 50,\n",
      "    \"American black bear, black bear, Ursus americanus, Euarctos americanus\": 295,\n",
      "    \"American chameleon, anole, Anolis carolinensis\": 40,\n",
      "    \"American coot, marsh hen, mud hen, water hen, Fulica americana\": 137,\n",
      "    \"American egret, great white heron, Egretta albus\": 132,\n",
      "    \"American lobster, Northern lobster, Maine lobster, Homarus americanus\": 122,\n",
      "    \"Angora, Angora rabbit\": 332,\n",
      "    \"Appenzeller\": 240,\n",
      "    \"Arabian camel, dromedary, Camelus dromedarius\": 354,\n",
      "    \"Arctic fox, white fox, Alopex lagopus\": 279,\n",
      "    \"Australian terrier\": 193,\n",
      "    \"Band Aid\": 419,\n",
      "    \"Bedlington terrier\": 181,\n",
      "    \"Bernese mountain dog\": 239,\n",
      "    \"Blenheim spaniel\": 156,\n",
      "    \"Border collie\": 232,\n",
      "    \"Border terrier\": 182,\n",
      "    \"Boston bull, Boston terrier\": 195,\n",
      "    \"Bouvier des Flandres, Bouviers des Flandres\": 233,\n",
      "    \"Brabancon griffon\": 262,\n",
      "    \"Brittany spaniel\": 215,\n",
      "    \"CD player\": 485,\n",
      "    \"Cardigan, Cardigan Welsh corgi\": 264,\n",
      "    \"Chesapeake Bay retriever\": 209,\n",
      "    \"Chihuahua\": 151,\n",
      "    \"Christmas stocking\": 496,\n",
      "    \"Crock Pot\": 521,\n",
      "    \"Dandie Dinmont, Dandie Dinmont terrier\": 194,\n",
      "    \"Doberman, Doberman pinscher\": 236,\n",
      "    \"Dungeness crab, Cancer magister\": 118,\n",
      "    \"Dutch oven\": 544,\n",
      "    \"Egyptian cat\": 285,\n",
      "    \"English foxhound\": 167,\n",
      "    \"English setter\": 212,\n",
      "    \"English springer, English springer spaniel\": 217,\n",
      "    \"EntleBucher\": 241,\n",
      "    \"Eskimo dog, husky\": 248,\n",
      "    \"European fire salamander, Salamandra salamandra\": 25,\n",
      "    \"European gallinule, Porphyrio porphyrio\": 136,\n",
      "    \"French bulldog\": 245,\n",
      "    \"French horn, horn\": 566,\n",
      "    \"French loaf\": 930,\n",
      "    \"German shepherd, German shepherd dog, German police dog, alsatian\": 235,\n",
      "    \"German short-haired pointer\": 210,\n",
      "    \"Gila monster, Heloderma suspectum\": 45,\n",
      "    \"Gordon setter\": 214,\n",
      "    \"Granny Smith\": 948,\n",
      "    \"Great Dane\": 246,\n",
      "    \"Great Pyrenees\": 257,\n",
      "    \"Greater Swiss Mountain dog\": 238,\n",
      "    \"Ibizan hound, Ibizan Podenco\": 173,\n",
      "    \"Indian cobra, Naja naja\": 63,\n",
      "    \"Indian elephant, Elephas maximus\": 385,\n",
      "    \"Irish setter, red setter\": 213,\n",
      "    \"Irish terrier\": 184,\n",
      "    \"Irish water spaniel\": 221,\n",
      "    \"Irish wolfhound\": 170,\n",
      "    \"Italian greyhound\": 171,\n",
      "    \"Japanese spaniel\": 152,\n",
      "    \"Kerry blue terrier\": 183,\n",
      "    \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis\": 48,\n",
      "    \"Labrador retriever\": 208,\n",
      "    \"Lakeland terrier\": 189,\n",
      "    \"Leonberg\": 255,\n",
      "    \"Lhasa, Lhasa apso\": 204,\n",
      "    \"Loafer\": 630,\n",
      "    \"Madagascar cat, ring-tailed lemur, Lemur catta\": 383,\n",
      "    \"Maltese dog, Maltese terrier, Maltese\": 153,\n",
      "    \"Mexican hairless\": 268,\n",
      "    \"Model T\": 661,\n",
      "    \"Newfoundland, Newfoundland dog\": 256,\n",
      "    \"Norfolk terrier\": 185,\n",
      "    \"Norwegian elkhound, elkhound\": 174,\n",
      "    \"Norwich terrier\": 186,\n",
      "    \"Old English sheepdog, bobtail\": 229,\n",
      "    \"Pekinese, Pekingese, Peke\": 154,\n",
      "    \"Pembroke, Pembroke Welsh corgi\": 263,\n",
      "    \"Persian cat\": 283,\n",
      "    \"Petri dish\": 712,\n",
      "    \"Polaroid camera, Polaroid Land camera\": 732,\n",
      "    \"Pomeranian\": 259,\n",
      "    \"Rhodesian ridgeback\": 159,\n",
      "    \"Rottweiler\": 234,\n",
      "    \"Saint Bernard, St Bernard\": 247,\n",
      "    \"Saluki, gazelle hound\": 176,\n",
      "    \"Samoyed, Samoyede\": 258,\n",
      "    \"Scotch terrier, Scottish terrier, Scottie\": 199,\n",
      "    \"Scottish deerhound, deerhound\": 177,\n",
      "    \"Sealyham terrier, Sealyham\": 190,\n",
      "    \"Shetland sheepdog, Shetland sheep dog, Shetland\": 230,\n",
      "    \"Shih-Tzu\": 155,\n",
      "    \"Siamese cat, Siamese\": 284,\n",
      "    \"Siberian husky\": 250,\n",
      "    \"Staffordshire bullterrier, Staffordshire bull terrier\": 179,\n",
      "    \"Sussex spaniel\": 220,\n",
      "    \"Tibetan mastiff\": 244,\n",
      "    \"Tibetan terrier, chrysanthemum dog\": 200,\n",
      "    \"Walker hound, Walker foxhound\": 166,\n",
      "    \"Weimaraner\": 178,\n",
      "    \"Welsh springer spaniel\": 218,\n",
      "    \"West Highland white terrier\": 203,\n",
      "    \"Windsor tie\": 906,\n",
      "    \"Yorkshire terrier\": 187,\n",
      "    \"abacus\": 398,\n",
      "    \"abaya\": 399,\n",
      "    \"academic gown, academic robe, judge's robe\": 400,\n",
      "    \"accordion, piano accordion, squeeze box\": 401,\n",
      "    \"acorn\": 988,\n",
      "    \"acorn squash\": 941,\n",
      "    \"acoustic guitar\": 402,\n",
      "    \"admiral\": 321,\n",
      "    \"affenpinscher, monkey pinscher, monkey dog\": 252,\n",
      "    \"agama\": 42,\n",
      "    \"agaric\": 992,\n",
      "    \"aircraft carrier, carrier, flattop, attack aircraft carrier\": 403,\n",
      "    \"airliner\": 404,\n",
      "    \"airship, dirigible\": 405,\n",
      "    \"albatross, mollymawk\": 146,\n",
      "    \"alligator lizard\": 44,\n",
      "    \"alp\": 970,\n",
      "    \"altar\": 406,\n",
      "    \"ambulance\": 407,\n",
      "    \"amphibian, amphibious vehicle\": 408,\n",
      "    \"analog clock\": 409,\n",
      "    \"anemone fish\": 393,\n",
      "    \"ant, emmet, pismire\": 310,\n",
      "    \"apiary, bee house\": 410,\n",
      "    \"apron\": 411,\n",
      "    \"armadillo\": 363,\n",
      "    \"artichoke, globe artichoke\": 944,\n",
      "    \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\": 412,\n",
      "    \"assault rifle, assault gun\": 413,\n",
      "    \"axolotl, mud puppy, Ambystoma mexicanum\": 29,\n",
      "    \"baboon\": 372,\n",
      "    \"backpack, back pack, knapsack, packsack, rucksack, haversack\": 414,\n",
      "    \"badger\": 362,\n",
      "    \"bagel, beigel\": 931,\n",
      "    \"bakery, bakeshop, bakehouse\": 415,\n",
      "    \"balance beam, beam\": 416,\n",
      "    \"bald eagle, American eagle, Haliaeetus leucocephalus\": 22,\n",
      "    \"balloon\": 417,\n",
      "    \"ballplayer, baseball player\": 981,\n",
      "    \"ballpoint, ballpoint pen, ballpen, Biro\": 418,\n",
      "    \"banana\": 954,\n",
      "    \"banded gecko\": 38,\n",
      "    \"banjo\": 420,\n",
      "    \"bannister, banister, balustrade, balusters, handrail\": 421,\n",
      "    \"barbell\": 422,\n",
      "    \"barber chair\": 423,\n",
      "    \"barbershop\": 424,\n",
      "    \"barn\": 425,\n",
      "    \"barn spider, Araneus cavaticus\": 73,\n",
      "    \"barometer\": 426,\n",
      "    \"barracouta, snoek\": 389,\n",
      "    \"barrel, cask\": 427,\n",
      "    \"barrow, garden cart, lawn cart, wheelbarrow\": 428,\n",
      "    \"baseball\": 429,\n",
      "    \"basenji\": 253,\n",
      "    \"basketball\": 430,\n",
      "    \"basset, basset hound\": 161,\n",
      "    \"bassinet\": 431,\n",
      "    \"bassoon\": 432,\n",
      "    \"bath towel\": 434,\n",
      "    \"bathing cap, swimming cap\": 433,\n",
      "    \"bathtub, bathing tub, bath, tub\": 435,\n",
      "    \"beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\": 436,\n",
      "    \"beacon, lighthouse, beacon light, pharos\": 437,\n",
      "    \"beagle\": 162,\n",
      "    \"beaker\": 438,\n",
      "    \"bearskin, busby, shako\": 439,\n",
      "    \"beaver\": 337,\n",
      "    \"bee\": 309,\n",
      "    \"bee eater\": 92,\n",
      "    \"beer bottle\": 440,\n",
      "    \"beer glass\": 441,\n",
      "    \"bell cote, bell cot\": 442,\n",
      "    \"bell pepper\": 945,\n",
      "    \"bib\": 443,\n",
      "    \"bicycle-built-for-two, tandem bicycle, tandem\": 444,\n",
      "    \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\": 349,\n",
      "    \"bikini, two-piece\": 445,\n",
      "    \"binder, ring-binder\": 446,\n",
      "    \"binoculars, field glasses, opera glasses\": 447,\n",
      "    \"birdhouse\": 448,\n",
      "    \"bison\": 347,\n",
      "    \"bittern\": 133,\n",
      "    \"black and gold garden spider, Argiope aurantia\": 72,\n",
      "    \"black grouse\": 80,\n",
      "    \"black stork, Ciconia nigra\": 128,\n",
      "    \"black swan, Cygnus atratus\": 100,\n",
      "    \"black widow, Latrodectus mactans\": 75,\n",
      "    \"black-and-tan coonhound\": 165,\n",
      "    \"black-footed ferret, ferret, Mustela nigripes\": 359,\n",
      "    \"bloodhound, sleuthhound\": 163,\n",
      "    \"bluetick\": 164,\n",
      "    \"boa constrictor, Constrictor constrictor\": 61,\n",
      "    \"boathouse\": 449,\n",
      "    \"bobsled, bobsleigh, bob\": 450,\n",
      "    \"bolete\": 997,\n",
      "    \"bolo tie, bolo, bola tie, bola\": 451,\n",
      "    \"bonnet, poke bonnet\": 452,\n",
      "    \"book jacket, dust cover, dust jacket, dust wrapper\": 921,\n",
      "    \"bookcase\": 453,\n",
      "    \"bookshop, bookstore, bookstall\": 454,\n",
      "    \"borzoi, Russian wolfhound\": 169,\n",
      "    \"bottlecap\": 455,\n",
      "    \"bow\": 456,\n",
      "    \"bow tie, bow-tie, bowtie\": 457,\n",
      "    \"box turtle, box tortoise\": 37,\n",
      "    \"boxer\": 242,\n",
      "    \"brain coral\": 109,\n",
      "    \"brambling, Fringilla montifringilla\": 10,\n",
      "    \"brass, memorial tablet, plaque\": 458,\n",
      "    \"brassiere, bra, bandeau\": 459,\n",
      "    \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\": 460,\n",
      "    \"breastplate, aegis, egis\": 461,\n",
      "    \"briard\": 226,\n",
      "    \"broccoli\": 937,\n",
      "    \"broom\": 462,\n",
      "    \"brown bear, bruin, Ursus arctos\": 294,\n",
      "    \"bubble\": 971,\n",
      "    \"bucket, pail\": 463,\n",
      "    \"buckeye, horse chestnut, conker\": 990,\n",
      "    \"buckle\": 464,\n",
      "    \"bulbul\": 16,\n",
      "    \"bull mastiff\": 243,\n",
      "    \"bullet train, bullet\": 466,\n",
      "    \"bulletproof vest\": 465,\n",
      "    \"bullfrog, Rana catesbeiana\": 30,\n",
      "    \"burrito\": 965,\n",
      "    \"bustard\": 138,\n",
      "    \"butcher shop, meat market\": 467,\n",
      "    \"butternut squash\": 942,\n",
      "    \"cab, hack, taxi, taxicab\": 468,\n",
      "    \"cabbage butterfly\": 324,\n",
      "    \"cairn, cairn terrier\": 192,\n",
      "    \"caldron, cauldron\": 469,\n",
      "    \"can opener, tin opener\": 473,\n",
      "    \"candle, taper, wax light\": 470,\n",
      "    \"cannon\": 471,\n",
      "    \"canoe\": 472,\n",
      "    \"capuchin, ringtail, Cebus capucinus\": 378,\n",
      "    \"car mirror\": 475,\n",
      "    \"car wheel\": 479,\n",
      "    \"carbonara\": 959,\n",
      "    \"cardigan\": 474,\n",
      "    \"cardoon\": 946,\n",
      "    \"carousel, carrousel, merry-go-round, roundabout, whirligig\": 476,\n",
      "    \"carpenter's kit, tool kit\": 477,\n",
      "    \"carton\": 478,\n",
      "    \"cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\": 480,\n",
      "    \"cassette\": 481,\n",
      "    \"cassette player\": 482,\n",
      "    \"castle\": 483,\n",
      "    \"catamaran\": 484,\n",
      "    \"cauliflower\": 938,\n",
      "    \"cello, violoncello\": 486,\n",
      "    \"cellular telephone, cellular phone, cellphone, cell, mobile phone\": 487,\n",
      "    \"centipede\": 79,\n",
      "    \"chain\": 488,\n",
      "    \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour\": 490,\n",
      "    \"chain saw, chainsaw\": 491,\n",
      "    \"chainlink fence\": 489,\n",
      "    \"chambered nautilus, pearly nautilus, nautilus\": 117,\n",
      "    \"cheeseburger\": 933,\n",
      "    \"cheetah, chetah, Acinonyx jubatus\": 293,\n",
      "    \"chest\": 492,\n",
      "    \"chickadee\": 19,\n",
      "    \"chiffonier, commode\": 493,\n",
      "    \"chime, bell, gong\": 494,\n",
      "    \"chimpanzee, chimp, Pan troglodytes\": 367,\n",
      "    \"china cabinet, china closet\": 495,\n",
      "    \"chiton, coat-of-mail shell, sea cradle, polyplacophore\": 116,\n",
      "    \"chocolate sauce, chocolate syrup\": 960,\n",
      "    \"chow, chow chow\": 260,\n",
      "    \"church, church building\": 497,\n",
      "    \"cicada, cicala\": 316,\n",
      "    \"cinema, movie theater, movie theatre, movie house, picture palace\": 498,\n",
      "    \"cleaver, meat cleaver, chopper\": 499,\n",
      "    \"cliff dwelling\": 500,\n",
      "    \"cliff, drop, drop-off\": 972,\n",
      "    \"cloak\": 501,\n",
      "    \"clog, geta, patten, sabot\": 502,\n",
      "    \"clumber, clumber spaniel\": 216,\n",
      "    \"cock\": 7,\n",
      "    \"cocker spaniel, English cocker spaniel, cocker\": 219,\n",
      "    \"cockroach, roach\": 314,\n",
      "    \"cocktail shaker\": 503,\n",
      "    \"coffee mug\": 504,\n",
      "    \"coffeepot\": 505,\n",
      "    \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\": 391,\n",
      "    \"coil, spiral, volute, whorl, helix\": 506,\n",
      "    \"collie\": 231,\n",
      "    \"colobus, colobus monkey\": 375,\n",
      "    \"combination lock\": 507,\n",
      "    \"comic book\": 917,\n",
      "    \"common iguana, iguana, Iguana iguana\": 39,\n",
      "    \"common newt, Triturus vulgaris\": 26,\n",
      "    \"computer keyboard, keypad\": 508,\n",
      "    \"conch\": 112,\n",
      "    \"confectionery, confectionary, candy store\": 509,\n",
      "    \"consomme\": 925,\n",
      "    \"container ship, containership, container vessel\": 510,\n",
      "    \"convertible\": 511,\n",
      "    \"coral fungus\": 991,\n",
      "    \"coral reef\": 973,\n",
      "    \"corkscrew, bottle screw\": 512,\n",
      "    \"corn\": 987,\n",
      "    \"cornet, horn, trumpet, trump\": 513,\n",
      "    \"coucal\": 91,\n",
      "    \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\": 286,\n",
      "    \"cowboy boot\": 514,\n",
      "    \"cowboy hat, ten-gallon hat\": 515,\n",
      "    \"coyote, prairie wolf, brush wolf, Canis latrans\": 272,\n",
      "    \"cradle\": 516,\n",
      "    \"crane\": 517,\n",
      "    \"crash helmet\": 518,\n",
      "    \"crate\": 519,\n",
      "    \"crayfish, crawfish, crawdad, crawdaddy\": 124,\n",
      "    \"crib, cot\": 520,\n",
      "    \"cricket\": 312,\n",
      "    \"croquet ball\": 522,\n",
      "    \"crossword puzzle, crossword\": 918,\n",
      "    \"crutch\": 523,\n",
      "    \"cucumber, cuke\": 943,\n",
      "    \"cuirass\": 524,\n",
      "    \"cup\": 968,\n",
      "    \"curly-coated retriever\": 206,\n",
      "    \"custard apple\": 956,\n",
      "    \"daisy\": 985,\n",
      "    \"dalmatian, coach dog, carriage dog\": 251,\n",
      "    \"dam, dike, dyke\": 525,\n",
      "    \"damselfly\": 320,\n",
      "    \"desk\": 526,\n",
      "    \"desktop computer\": 527,\n",
      "    \"dhole, Cuon alpinus\": 274,\n",
      "    \"dial telephone, dial phone\": 528,\n",
      "    \"diamondback, diamondback rattlesnake, Crotalus adamanteus\": 67,\n",
      "    \"diaper, nappy, napkin\": 529,\n",
      "    \"digital clock\": 530,\n",
      "    \"digital watch\": 531,\n",
      "    \"dingo, warrigal, warragal, Canis dingo\": 273,\n",
      "    \"dining table, board\": 532,\n",
      "    \"dishrag, dishcloth\": 533,\n",
      "    \"dishwasher, dish washer, dishwashing machine\": 534,\n",
      "    \"disk brake, disc brake\": 535,\n",
      "    \"dock, dockage, docking facility\": 536,\n",
      "    \"dogsled, dog sled, dog sleigh\": 537,\n",
      "    \"dome\": 538,\n",
      "    \"doormat, welcome mat\": 539,\n",
      "    \"dough\": 961,\n",
      "    \"dowitcher\": 142,\n",
      "    \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\": 319,\n",
      "    \"drake\": 97,\n",
      "    \"drilling platform, offshore rig\": 540,\n",
      "    \"drum, membranophone, tympan\": 541,\n",
      "    \"drumstick\": 542,\n",
      "    \"dugong, Dugong dugon\": 149,\n",
      "    \"dumbbell\": 543,\n",
      "    \"dung beetle\": 305,\n",
      "    \"ear, spike, capitulum\": 998,\n",
      "    \"earthstar\": 995,\n",
      "    \"echidna, spiny anteater, anteater\": 102,\n",
      "    \"eel\": 390,\n",
      "    \"eft\": 27,\n",
      "    \"eggnog\": 969,\n",
      "    \"electric fan, blower\": 545,\n",
      "    \"electric guitar\": 546,\n",
      "    \"electric locomotive\": 547,\n",
      "    \"electric ray, crampfish, numbfish, torpedo\": 5,\n",
      "    \"entertainment center\": 548,\n",
      "    \"envelope\": 549,\n",
      "    \"espresso\": 967,\n",
      "    \"espresso maker\": 550,\n",
      "    \"face powder\": 551,\n",
      "    \"feather boa, boa\": 552,\n",
      "    \"fiddler crab\": 120,\n",
      "    \"fig\": 952,\n",
      "    \"file, file cabinet, filing cabinet\": 553,\n",
      "    \"fire engine, fire truck\": 555,\n",
      "    \"fire screen, fireguard\": 556,\n",
      "    \"fireboat\": 554,\n",
      "    \"flagpole, flagstaff\": 557,\n",
      "    \"flamingo\": 130,\n",
      "    \"flat-coated retriever\": 205,\n",
      "    \"flatworm, platyhelminth\": 110,\n",
      "    \"flute, transverse flute\": 558,\n",
      "    \"fly\": 308,\n",
      "    \"folding chair\": 559,\n",
      "    \"football helmet\": 560,\n",
      "    \"forklift\": 561,\n",
      "    \"fountain\": 562,\n",
      "    \"fountain pen\": 563,\n",
      "    \"four-poster\": 564,\n",
      "    \"fox squirrel, eastern fox squirrel, Sciurus niger\": 335,\n",
      "    \"freight car\": 565,\n",
      "    \"frilled lizard, Chlamydosaurus kingi\": 43,\n",
      "    \"frying pan, frypan, skillet\": 567,\n",
      "    \"fur coat\": 568,\n",
      "    \"gar, garfish, garpike, billfish, Lepisosteus osseus\": 395,\n",
      "    \"garbage truck, dustcart\": 569,\n",
      "    \"garden spider, Aranea diademata\": 74,\n",
      "    \"garter snake, grass snake\": 57,\n",
      "    \"gas pump, gasoline pump, petrol pump, island dispenser\": 571,\n",
      "    \"gasmask, respirator, gas helmet\": 570,\n",
      "    \"gazelle\": 353,\n",
      "    \"geyser\": 974,\n",
      "    \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\": 388,\n",
      "    \"giant schnauzer\": 197,\n",
      "    \"gibbon, Hylobates lar\": 368,\n",
      "    \"go-kart\": 573,\n",
      "    \"goblet\": 572,\n",
      "    \"golden retriever\": 207,\n",
      "    \"goldfinch, Carduelis carduelis\": 11,\n",
      "    \"goldfish, Carassius auratus\": 1,\n",
      "    \"golf ball\": 574,\n",
      "    \"golfcart, golf cart\": 575,\n",
      "    \"gondola\": 576,\n",
      "    \"gong, tam-tam\": 577,\n",
      "    \"goose\": 99,\n",
      "    \"gorilla, Gorilla gorilla\": 366,\n",
      "    \"gown\": 578,\n",
      "    \"grand piano, grand\": 579,\n",
      "    \"grasshopper, hopper\": 311,\n",
      "    \"great grey owl, great gray owl, Strix nebulosa\": 24,\n",
      "    \"great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\": 2,\n",
      "    \"green lizard, Lacerta viridis\": 46,\n",
      "    \"green mamba\": 64,\n",
      "    \"green snake, grass snake\": 55,\n",
      "    \"greenhouse, nursery, glasshouse\": 580,\n",
      "    \"grey fox, gray fox, Urocyon cinereoargenteus\": 280,\n",
      "    \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\": 147,\n",
      "    \"grille, radiator grille\": 581,\n",
      "    \"grocery store, grocery, food market, market\": 582,\n",
      "    \"groenendael\": 224,\n",
      "    \"groom, bridegroom\": 982,\n",
      "    \"ground beetle, carabid beetle\": 302,\n",
      "    \"guacamole\": 924,\n",
      "    \"guenon, guenon monkey\": 370,\n",
      "    \"guillotine\": 583,\n",
      "    \"guinea pig, Cavia cobaya\": 338,\n",
      "    \"gyromitra\": 993,\n",
      "    \"hair slide\": 584,\n",
      "    \"hair spray\": 585,\n",
      "    \"half track\": 586,\n",
      "    \"hammer\": 587,\n",
      "    \"hammerhead, hammerhead shark\": 4,\n",
      "    \"hamper\": 588,\n",
      "    \"hamster\": 333,\n",
      "    \"hand blower, blow dryer, blow drier, hair dryer, hair drier\": 589,\n",
      "    \"hand-held computer, hand-held microcomputer\": 590,\n",
      "    \"handkerchief, hankie, hanky, hankey\": 591,\n",
      "    \"hard disc, hard disk, fixed disk\": 592,\n",
      "    \"hare\": 331,\n",
      "    \"harmonica, mouth organ, harp, mouth harp\": 593,\n",
      "    \"harp\": 594,\n",
      "    \"hartebeest\": 351,\n",
      "    \"harvester, reaper\": 595,\n",
      "    \"harvestman, daddy longlegs, Phalangium opilio\": 70,\n",
      "    \"hatchet\": 596,\n",
      "    \"hay\": 958,\n",
      "    \"head cabbage\": 936,\n",
      "    \"hen\": 8,\n",
      "    \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\": 996,\n",
      "    \"hermit crab\": 125,\n",
      "    \"hip, rose hip, rosehip\": 989,\n",
      "    \"hippopotamus, hippo, river horse, Hippopotamus amphibius\": 344,\n",
      "    \"hog, pig, grunter, squealer, Sus scrofa\": 341,\n",
      "    \"hognose snake, puff adder, sand viper\": 54,\n",
      "    \"holster\": 597,\n",
      "    \"home theater, home theatre\": 598,\n",
      "    \"honeycomb\": 599,\n",
      "    \"hook, claw\": 600,\n",
      "    \"hoopskirt, crinoline\": 601,\n",
      "    \"horizontal bar, high bar\": 602,\n",
      "    \"hornbill\": 93,\n",
      "    \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\": 66,\n",
      "    \"horse cart, horse-cart\": 603,\n",
      "    \"hot pot, hotpot\": 926,\n",
      "    \"hotdog, hot dog, red hot\": 934,\n",
      "    \"hourglass\": 604,\n",
      "    \"house finch, linnet, Carpodacus mexicanus\": 12,\n",
      "    \"howler monkey, howler\": 379,\n",
      "    \"hummingbird\": 94,\n",
      "    \"hyena, hyaena\": 276,\n",
      "    \"iPod\": 605,\n",
      "    \"ibex, Capra ibex\": 350,\n",
      "    \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\": 296,\n",
      "    \"ice cream, icecream\": 928,\n",
      "    \"ice lolly, lolly, lollipop, popsicle\": 929,\n",
      "    \"impala, Aepyceros melampus\": 352,\n",
      "    \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\": 14,\n",
      "    \"indri, indris, Indri indri, Indri brevicaudatus\": 384,\n",
      "    \"iron, smoothing iron\": 606,\n",
      "    \"isopod\": 126,\n",
      "    \"jacamar\": 95,\n",
      "    \"jack-o'-lantern\": 607,\n",
      "    \"jackfruit, jak, jack\": 955,\n",
      "    \"jaguar, panther, Panthera onca, Felis onca\": 290,\n",
      "    \"jay\": 17,\n",
      "    \"jean, blue jean, denim\": 608,\n",
      "    \"jeep, landrover\": 609,\n",
      "    \"jellyfish\": 107,\n",
      "    \"jersey, T-shirt, tee shirt\": 610,\n",
      "    \"jigsaw puzzle\": 611,\n",
      "    \"jinrikisha, ricksha, rickshaw\": 612,\n",
      "    \"joystick\": 613,\n",
      "    \"junco, snowbird\": 13,\n",
      "    \"keeshond\": 261,\n",
      "    \"kelpie\": 227,\n",
      "    \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\": 148,\n",
      "    \"kimono\": 614,\n",
      "    \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica\": 121,\n",
      "    \"king penguin, Aptenodytes patagonica\": 145,\n",
      "    \"king snake, kingsnake\": 56,\n",
      "    \"kit fox, Vulpes macrotis\": 278,\n",
      "    \"kite\": 21,\n",
      "    \"knee pad\": 615,\n",
      "    \"knot\": 616,\n",
      "    \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\": 105,\n",
      "    \"komondor\": 228,\n",
      "    \"kuvasz\": 222,\n",
      "    \"lab coat, laboratory coat\": 617,\n",
      "    \"lacewing, lacewing fly\": 318,\n",
      "    \"ladle\": 618,\n",
      "    \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\": 301,\n",
      "    \"lakeside, lakeshore\": 975,\n",
      "    \"lampshade, lamp shade\": 619,\n",
      "    \"langur\": 374,\n",
      "    \"laptop, laptop computer\": 620,\n",
      "    \"lawn mower, mower\": 621,\n",
      "    \"leaf beetle, chrysomelid\": 304,\n",
      "    \"leafhopper\": 317,\n",
      "    \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\": 34,\n",
      "    \"lemon\": 951,\n",
      "    \"lens cap, lens cover\": 622,\n",
      "    \"leopard, Panthera pardus\": 288,\n",
      "    \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\": 387,\n",
      "    \"letter opener, paper knife, paperknife\": 623,\n",
      "    \"library\": 624,\n",
      "    \"lifeboat\": 625,\n",
      "    \"lighter, light, igniter, ignitor\": 626,\n",
      "    \"limousine, limo\": 627,\n",
      "    \"limpkin, Aramus pictus\": 135,\n",
      "    \"liner, ocean liner\": 628,\n",
      "    \"lion, king of beasts, Panthera leo\": 291,\n",
      "    \"lionfish\": 396,\n",
      "    \"lipstick, lip rouge\": 629,\n",
      "    \"little blue heron, Egretta caerulea\": 131,\n",
      "    \"llama\": 355,\n",
      "    \"loggerhead, loggerhead turtle, Caretta caretta\": 33,\n",
      "    \"long-horned beetle, longicorn, longicorn beetle\": 303,\n",
      "    \"lorikeet\": 90,\n",
      "    \"lotion\": 631,\n",
      "    \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\": 632,\n",
      "    \"loupe, jeweler's loupe\": 633,\n",
      "    \"lumbermill, sawmill\": 634,\n",
      "    \"lycaenid, lycaenid butterfly\": 326,\n",
      "    \"lynx, catamount\": 287,\n",
      "    \"macaque\": 373,\n",
      "    \"macaw\": 88,\n",
      "    \"magnetic compass\": 635,\n",
      "    \"magpie\": 18,\n",
      "    \"mailbag, postbag\": 636,\n",
      "    \"mailbox, letter box\": 637,\n",
      "    \"maillot\": 638,\n",
      "    \"maillot, tank suit\": 639,\n",
      "    \"malamute, malemute, Alaskan malamute\": 249,\n",
      "    \"malinois\": 225,\n",
      "    \"manhole cover\": 640,\n",
      "    \"mantis, mantid\": 315,\n",
      "    \"maraca\": 641,\n",
      "    \"marimba, xylophone\": 642,\n",
      "    \"marmoset\": 377,\n",
      "    \"marmot\": 336,\n",
      "    \"mashed potato\": 935,\n",
      "    \"mask\": 643,\n",
      "    \"matchstick\": 644,\n",
      "    \"maypole\": 645,\n",
      "    \"maze, labyrinth\": 646,\n",
      "    \"measuring cup\": 647,\n",
      "    \"meat loaf, meatloaf\": 962,\n",
      "    \"medicine chest, medicine cabinet\": 648,\n",
      "    \"meerkat, mierkat\": 299,\n",
      "    \"megalith, megalithic structure\": 649,\n",
      "    \"menu\": 922,\n",
      "    \"microphone, mike\": 650,\n",
      "    \"microwave, microwave oven\": 651,\n",
      "    \"military uniform\": 652,\n",
      "    \"milk can\": 653,\n",
      "    \"miniature pinscher\": 237,\n",
      "    \"miniature poodle\": 266,\n",
      "    \"miniature schnauzer\": 196,\n",
      "    \"minibus\": 654,\n",
      "    \"miniskirt, mini\": 655,\n",
      "    \"minivan\": 656,\n",
      "    \"mink\": 357,\n",
      "    \"missile\": 657,\n",
      "    \"mitten\": 658,\n",
      "    \"mixing bowl\": 659,\n",
      "    \"mobile home, manufactured home\": 660,\n",
      "    \"modem\": 662,\n",
      "    \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\": 323,\n",
      "    \"monastery\": 663,\n",
      "    \"mongoose\": 298,\n",
      "    \"monitor\": 664,\n",
      "    \"moped\": 665,\n",
      "    \"mortar\": 666,\n",
      "    \"mortarboard\": 667,\n",
      "    \"mosque\": 668,\n",
      "    \"mosquito net\": 669,\n",
      "    \"motor scooter, scooter\": 670,\n",
      "    \"mountain bike, all-terrain bike, off-roader\": 671,\n",
      "    \"mountain tent\": 672,\n",
      "    \"mouse, computer mouse\": 673,\n",
      "    \"mousetrap\": 674,\n",
      "    \"moving van\": 675,\n",
      "    \"mud turtle\": 35,\n",
      "    \"mushroom\": 947,\n",
      "    \"muzzle\": 676,\n",
      "    \"nail\": 677,\n",
      "    \"neck brace\": 678,\n",
      "    \"necklace\": 679,\n",
      "    \"nematode, nematode worm, roundworm\": 111,\n",
      "    \"night snake, Hypsiglena torquata\": 60,\n",
      "    \"nipple\": 680,\n",
      "    \"notebook, notebook computer\": 681,\n",
      "    \"obelisk\": 682,\n",
      "    \"oboe, hautboy, hautbois\": 683,\n",
      "    \"ocarina, sweet potato\": 684,\n",
      "    \"odometer, hodometer, mileometer, milometer\": 685,\n",
      "    \"oil filter\": 686,\n",
      "    \"orange\": 950,\n",
      "    \"orangutan, orang, orangutang, Pongo pygmaeus\": 365,\n",
      "    \"organ, pipe organ\": 687,\n",
      "    \"oscilloscope, scope, cathode-ray oscilloscope, CRO\": 688,\n",
      "    \"ostrich, Struthio camelus\": 9,\n",
      "    \"otter\": 360,\n",
      "    \"otterhound, otter hound\": 175,\n",
      "    \"overskirt\": 689,\n",
      "    \"ox\": 345,\n",
      "    \"oxcart\": 690,\n",
      "    \"oxygen mask\": 691,\n",
      "    \"oystercatcher, oyster catcher\": 143,\n",
      "    \"packet\": 692,\n",
      "    \"paddle, boat paddle\": 693,\n",
      "    \"paddlewheel, paddle wheel\": 694,\n",
      "    \"padlock\": 695,\n",
      "    \"paintbrush\": 696,\n",
      "    \"pajama, pyjama, pj's, jammies\": 697,\n",
      "    \"palace\": 698,\n",
      "    \"panpipe, pandean pipe, syrinx\": 699,\n",
      "    \"paper towel\": 700,\n",
      "    \"papillon\": 157,\n",
      "    \"parachute, chute\": 701,\n",
      "    \"parallel bars, bars\": 702,\n",
      "    \"park bench\": 703,\n",
      "    \"parking meter\": 704,\n",
      "    \"partridge\": 86,\n",
      "    \"passenger car, coach, carriage\": 705,\n",
      "    \"patas, hussar monkey, Erythrocebus patas\": 371,\n",
      "    \"patio, terrace\": 706,\n",
      "    \"pay-phone, pay-station\": 707,\n",
      "    \"peacock\": 84,\n",
      "    \"pedestal, plinth, footstall\": 708,\n",
      "    \"pelican\": 144,\n",
      "    \"pencil box, pencil case\": 709,\n",
      "    \"pencil sharpener\": 710,\n",
      "    \"perfume, essence\": 711,\n",
      "    \"photocopier\": 713,\n",
      "    \"pick, plectrum, plectron\": 714,\n",
      "    \"pickelhaube\": 715,\n",
      "    \"picket fence, paling\": 716,\n",
      "    \"pickup, pickup truck\": 717,\n",
      "    \"pier\": 718,\n",
      "    \"piggy bank, penny bank\": 719,\n",
      "    \"pill bottle\": 720,\n",
      "    \"pillow\": 721,\n",
      "    \"pineapple, ananas\": 953,\n",
      "    \"ping-pong ball\": 722,\n",
      "    \"pinwheel\": 723,\n",
      "    \"pirate, pirate ship\": 724,\n",
      "    \"pitcher, ewer\": 725,\n",
      "    \"pizza, pizza pie\": 963,\n",
      "    \"plane, carpenter's plane, woodworking plane\": 726,\n",
      "    \"planetarium\": 727,\n",
      "    \"plastic bag\": 728,\n",
      "    \"plate\": 923,\n",
      "    \"plate rack\": 729,\n",
      "    \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\": 103,\n",
      "    \"plow, plough\": 730,\n",
      "    \"plunger, plumber's helper\": 731,\n",
      "    \"pole\": 733,\n",
      "    \"polecat, fitch, foulmart, foumart, Mustela putorius\": 358,\n",
      "    \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\": 734,\n",
      "    \"pomegranate\": 957,\n",
      "    \"poncho\": 735,\n",
      "    \"pool table, billiard table, snooker table\": 736,\n",
      "    \"pop bottle, soda bottle\": 737,\n",
      "    \"porcupine, hedgehog\": 334,\n",
      "    \"pot, flowerpot\": 738,\n",
      "    \"potpie\": 964,\n",
      "    \"potter's wheel\": 739,\n",
      "    \"power drill\": 740,\n",
      "    \"prairie chicken, prairie grouse, prairie fowl\": 83,\n",
      "    \"prayer rug, prayer mat\": 741,\n",
      "    \"pretzel\": 932,\n",
      "    \"printer\": 742,\n",
      "    \"prison, prison house\": 743,\n",
      "    \"proboscis monkey, Nasalis larvatus\": 376,\n",
      "    \"projectile, missile\": 744,\n",
      "    \"projector\": 745,\n",
      "    \"promontory, headland, head, foreland\": 976,\n",
      "    \"ptarmigan\": 81,\n",
      "    \"puck, hockey puck\": 746,\n",
      "    \"puffer, pufferfish, blowfish, globefish\": 397,\n",
      "    \"pug, pug-dog\": 254,\n",
      "    \"punching bag, punch bag, punching ball, punchball\": 747,\n",
      "    \"purse\": 748,\n",
      "    \"quail\": 85,\n",
      "    \"quill, quill pen\": 749,\n",
      "    \"quilt, comforter, comfort, puff\": 750,\n",
      "    \"racer, race car, racing car\": 751,\n",
      "    \"racket, racquet\": 752,\n",
      "    \"radiator\": 753,\n",
      "    \"radio telescope, radio reflector\": 755,\n",
      "    \"radio, wireless\": 754,\n",
      "    \"rain barrel\": 756,\n",
      "    \"ram, tup\": 348,\n",
      "    \"rapeseed\": 984,\n",
      "    \"recreational vehicle, RV, R.V.\": 757,\n",
      "    \"red fox, Vulpes vulpes\": 277,\n",
      "    \"red wine\": 966,\n",
      "    \"red wolf, maned wolf, Canis rufus, Canis niger\": 271,\n",
      "    \"red-backed sandpiper, dunlin, Erolia alpina\": 140,\n",
      "    \"red-breasted merganser, Mergus serrator\": 98,\n",
      "    \"redbone\": 168,\n",
      "    \"redshank, Tringa totanus\": 141,\n",
      "    \"reel\": 758,\n",
      "    \"reflex camera\": 759,\n",
      "    \"refrigerator, icebox\": 760,\n",
      "    \"remote control, remote\": 761,\n",
      "    \"restaurant, eating house, eating place, eatery\": 762,\n",
      "    \"revolver, six-gun, six-shooter\": 763,\n",
      "    \"rhinoceros beetle\": 306,\n",
      "    \"rifle\": 764,\n",
      "    \"ringlet, ringlet butterfly\": 322,\n",
      "    \"ringneck snake, ring-necked snake, ring snake\": 53,\n",
      "    \"robin, American robin, Turdus migratorius\": 15,\n",
      "    \"rock beauty, Holocanthus tricolor\": 392,\n",
      "    \"rock crab, Cancer irroratus\": 119,\n",
      "    \"rock python, rock snake, Python sebae\": 62,\n",
      "    \"rocking chair, rocker\": 765,\n",
      "    \"rotisserie\": 766,\n",
      "    \"rubber eraser, rubber, pencil eraser\": 767,\n",
      "    \"ruddy turnstone, Arenaria interpres\": 139,\n",
      "    \"ruffed grouse, partridge, Bonasa umbellus\": 82,\n",
      "    \"rugby ball\": 768,\n",
      "    \"rule, ruler\": 769,\n",
      "    \"running shoe\": 770,\n",
      "    \"safe\": 771,\n",
      "    \"safety pin\": 772,\n",
      "    \"saltshaker, salt shaker\": 773,\n",
      "    \"sandal\": 774,\n",
      "    \"sandbar, sand bar\": 977,\n",
      "    \"sarong\": 775,\n",
      "    \"sax, saxophone\": 776,\n",
      "    \"scabbard\": 777,\n",
      "    \"scale, weighing machine\": 778,\n",
      "    \"schipperke\": 223,\n",
      "    \"school bus\": 779,\n",
      "    \"schooner\": 780,\n",
      "    \"scoreboard\": 781,\n",
      "    \"scorpion\": 71,\n",
      "    \"screen, CRT screen\": 782,\n",
      "    \"screw\": 783,\n",
      "    \"screwdriver\": 784,\n",
      "    \"scuba diver\": 983,\n",
      "    \"sea anemone, anemone\": 108,\n",
      "    \"sea cucumber, holothurian\": 329,\n",
      "    \"sea lion\": 150,\n",
      "    \"sea slug, nudibranch\": 115,\n",
      "    \"sea snake\": 65,\n",
      "    \"sea urchin\": 328,\n",
      "    \"seashore, coast, seacoast, sea-coast\": 978,\n",
      "    \"seat belt, seatbelt\": 785,\n",
      "    \"sewing machine\": 786,\n",
      "    \"shield, buckler\": 787,\n",
      "    \"shoe shop, shoe-shop, shoe store\": 788,\n",
      "    \"shoji\": 789,\n",
      "    \"shopping basket\": 790,\n",
      "    \"shopping cart\": 791,\n",
      "    \"shovel\": 792,\n",
      "    \"shower cap\": 793,\n",
      "    \"shower curtain\": 794,\n",
      "    \"siamang, Hylobates syndactylus, Symphalangus syndactylus\": 369,\n",
      "    \"sidewinder, horned rattlesnake, Crotalus cerastes\": 68,\n",
      "    \"silky terrier, Sydney silky\": 201,\n",
      "    \"ski\": 795,\n",
      "    \"ski mask\": 796,\n",
      "    \"skunk, polecat, wood pussy\": 361,\n",
      "    \"sleeping bag\": 797,\n",
      "    \"slide rule, slipstick\": 798,\n",
      "    \"sliding door\": 799,\n",
      "    \"slot, one-armed bandit\": 800,\n",
      "    \"sloth bear, Melursus ursinus, Ursus ursinus\": 297,\n",
      "    \"slug\": 114,\n",
      "    \"snail\": 113,\n",
      "    \"snorkel\": 801,\n",
      "    \"snow leopard, ounce, Panthera uncia\": 289,\n",
      "    \"snowmobile\": 802,\n",
      "    \"snowplow, snowplough\": 803,\n",
      "    \"soap dispenser\": 804,\n",
      "    \"soccer ball\": 805,\n",
      "    \"sock\": 806,\n",
      "    \"soft-coated wheaten terrier\": 202,\n",
      "    \"solar dish, solar collector, solar furnace\": 807,\n",
      "    \"sombrero\": 808,\n",
      "    \"sorrel\": 339,\n",
      "    \"soup bowl\": 809,\n",
      "    \"space bar\": 810,\n",
      "    \"space heater\": 811,\n",
      "    \"space shuttle\": 812,\n",
      "    \"spaghetti squash\": 940,\n",
      "    \"spatula\": 813,\n",
      "    \"speedboat\": 814,\n",
      "    \"spider monkey, Ateles geoffroyi\": 381,\n",
      "    \"spider web, spider's web\": 815,\n",
      "    \"spindle\": 816,\n",
      "    \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\": 123,\n",
      "    \"spoonbill\": 129,\n",
      "    \"sports car, sport car\": 817,\n",
      "    \"spotlight, spot\": 818,\n",
      "    \"spotted salamander, Ambystoma maculatum\": 28,\n",
      "    \"squirrel monkey, Saimiri sciureus\": 382,\n",
      "    \"stage\": 819,\n",
      "    \"standard poodle\": 267,\n",
      "    \"standard schnauzer\": 198,\n",
      "    \"starfish, sea star\": 327,\n",
      "    \"steam locomotive\": 820,\n",
      "    \"steel arch bridge\": 821,\n",
      "    \"steel drum\": 822,\n",
      "    \"stethoscope\": 823,\n",
      "    \"stingray\": 6,\n",
      "    \"stinkhorn, carrion fungus\": 994,\n",
      "    \"stole\": 824,\n",
      "    \"stone wall\": 825,\n",
      "    \"stopwatch, stop watch\": 826,\n",
      "    \"stove\": 827,\n",
      "    \"strainer\": 828,\n",
      "    \"strawberry\": 949,\n",
      "    \"street sign\": 919,\n",
      "    \"streetcar, tram, tramcar, trolley, trolley car\": 829,\n",
      "    \"stretcher\": 830,\n",
      "    \"studio couch, day bed\": 831,\n",
      "    \"stupa, tope\": 832,\n",
      "    \"sturgeon\": 394,\n",
      "    \"submarine, pigboat, sub, U-boat\": 833,\n",
      "    \"suit, suit of clothes\": 834,\n",
      "    \"sulphur butterfly, sulfur butterfly\": 325,\n",
      "    \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\": 89,\n",
      "    \"sundial\": 835,\n",
      "    \"sunglass\": 836,\n",
      "    \"sunglasses, dark glasses, shades\": 837,\n",
      "    \"sunscreen, sunblock, sun blocker\": 838,\n",
      "    \"suspension bridge\": 839,\n",
      "    \"swab, swob, mop\": 840,\n",
      "    \"sweatshirt\": 841,\n",
      "    \"swimming trunks, bathing trunks\": 842,\n",
      "    \"swing\": 843,\n",
      "    \"switch, electric switch, electrical switch\": 844,\n",
      "    \"syringe\": 845,\n",
      "    \"tabby, tabby cat\": 281,\n",
      "    \"table lamp\": 846,\n",
      "    \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\": 32,\n",
      "    \"tank, army tank, armored combat vehicle, armoured combat vehicle\": 847,\n",
      "    \"tape player\": 848,\n",
      "    \"tarantula\": 76,\n",
      "    \"teapot\": 849,\n",
      "    \"teddy, teddy bear\": 850,\n",
      "    \"television, television system\": 851,\n",
      "    \"tench, Tinca tinca\": 0,\n",
      "    \"tennis ball\": 852,\n",
      "    \"terrapin\": 36,\n",
      "    \"thatch, thatched roof\": 853,\n",
      "    \"theater curtain, theatre curtain\": 854,\n",
      "    \"thimble\": 855,\n",
      "    \"three-toed sloth, ai, Bradypus tridactylus\": 364,\n",
      "    \"thresher, thrasher, threshing machine\": 856,\n",
      "    \"throne\": 857,\n",
      "    \"thunder snake, worm snake, Carphophis amoenus\": 52,\n",
      "    \"tick\": 78,\n",
      "    \"tiger beetle\": 300,\n",
      "    \"tiger cat\": 282,\n",
      "    \"tiger shark, Galeocerdo cuvieri\": 3,\n",
      "    \"tiger, Panthera tigris\": 292,\n",
      "    \"tile roof\": 858,\n",
      "    \"timber wolf, grey wolf, gray wolf, Canis lupus\": 269,\n",
      "    \"titi, titi monkey\": 380,\n",
      "    \"toaster\": 859,\n",
      "    \"tobacco shop, tobacconist shop, tobacconist\": 860,\n",
      "    \"toilet seat\": 861,\n",
      "    \"toilet tissue, toilet paper, bathroom tissue\": 999,\n",
      "    \"torch\": 862,\n",
      "    \"totem pole\": 863,\n",
      "    \"toucan\": 96,\n",
      "    \"tow truck, tow car, wrecker\": 864,\n",
      "    \"toy poodle\": 265,\n",
      "    \"toy terrier\": 158,\n",
      "    \"toyshop\": 865,\n",
      "    \"tractor\": 866,\n",
      "    \"traffic light, traffic signal, stoplight\": 920,\n",
      "    \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\": 867,\n",
      "    \"tray\": 868,\n",
      "    \"tree frog, tree-frog\": 31,\n",
      "    \"trench coat\": 869,\n",
      "    \"triceratops\": 51,\n",
      "    \"tricycle, trike, velocipede\": 870,\n",
      "    \"trifle\": 927,\n",
      "    \"trilobite\": 69,\n",
      "    \"trimaran\": 871,\n",
      "    \"tripod\": 872,\n",
      "    \"triumphal arch\": 873,\n",
      "    \"trolleybus, trolley coach, trackless trolley\": 874,\n",
      "    \"trombone\": 875,\n",
      "    \"tub, vat\": 876,\n",
      "    \"turnstile\": 877,\n",
      "    \"tusker\": 101,\n",
      "    \"typewriter keyboard\": 878,\n",
      "    \"umbrella\": 879,\n",
      "    \"unicycle, monocycle\": 880,\n",
      "    \"upright, upright piano\": 881,\n",
      "    \"vacuum, vacuum cleaner\": 882,\n",
      "    \"valley, vale\": 979,\n",
      "    \"vase\": 883,\n",
      "    \"vault\": 884,\n",
      "    \"velvet\": 885,\n",
      "    \"vending machine\": 886,\n",
      "    \"vestment\": 887,\n",
      "    \"viaduct\": 888,\n",
      "    \"vine snake\": 59,\n",
      "    \"violin, fiddle\": 889,\n",
      "    \"vizsla, Hungarian pointer\": 211,\n",
      "    \"volcano\": 980,\n",
      "    \"volleyball\": 890,\n",
      "    \"vulture\": 23,\n",
      "    \"waffle iron\": 891,\n",
      "    \"walking stick, walkingstick, stick insect\": 313,\n",
      "    \"wall clock\": 892,\n",
      "    \"wallaby, brush kangaroo\": 104,\n",
      "    \"wallet, billfold, notecase, pocketbook\": 893,\n",
      "    \"wardrobe, closet, press\": 894,\n",
      "    \"warplane, military plane\": 895,\n",
      "    \"warthog\": 343,\n",
      "    \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\": 896,\n",
      "    \"washer, automatic washer, washing machine\": 897,\n",
      "    \"water bottle\": 898,\n",
      "    \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\": 346,\n",
      "    \"water jug\": 899,\n",
      "    \"water ouzel, dipper\": 20,\n",
      "    \"water snake\": 58,\n",
      "    \"water tower\": 900,\n",
      "    \"weasel\": 356,\n",
      "    \"web site, website, internet site, site\": 916,\n",
      "    \"weevil\": 307,\n",
      "    \"whippet\": 172,\n",
      "    \"whiptail, whiptail lizard\": 41,\n",
      "    \"whiskey jug\": 901,\n",
      "    \"whistle\": 902,\n",
      "    \"white stork, Ciconia ciconia\": 127,\n",
      "    \"white wolf, Arctic wolf, Canis lupus tundrarum\": 270,\n",
      "    \"wig\": 903,\n",
      "    \"wild boar, boar, Sus scrofa\": 342,\n",
      "    \"window screen\": 904,\n",
      "    \"window shade\": 905,\n",
      "    \"wine bottle\": 907,\n",
      "    \"wing\": 908,\n",
      "    \"wire-haired fox terrier\": 188,\n",
      "    \"wok\": 909,\n",
      "    \"wolf spider, hunting spider\": 77,\n",
      "    \"wombat\": 106,\n",
      "    \"wood rabbit, cottontail, cottontail rabbit\": 330,\n",
      "    \"wooden spoon\": 910,\n",
      "    \"wool, woolen, woollen\": 911,\n",
      "    \"worm fence, snake fence, snake-rail fence, Virginia fence\": 912,\n",
      "    \"wreck\": 913,\n",
      "    \"yawl\": 914,\n",
      "    \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\": 986,\n",
      "    \"yurt\": 915,\n",
      "    \"zebra\": 340,\n",
      "    \"zucchini, courgette\": 939\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|image_processing_utils.py:533] 2023-03-24 15:08:21,587 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "[INFO|image_processing_utils.py:353] 2023-03-24 15:08:21,588 >> Image processor ViTImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO|trainer.py:543] 2023-03-24 15:08:21,636 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-03-24 15:08:21,641 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-24 15:08:21,642 >>   Num examples = 80000\n",
      "[INFO|trainer.py:1760] 2023-03-24 15:08:21,642 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-24 15:08:21,643 >>   Instantaneous batch size per device = 64\n",
      "[INFO|trainer.py:1762] 2023-03-24 15:08:21,643 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1763] 2023-03-24 15:08:21,644 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-24 15:08:21,644 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-24 15:08:21,646 >>   Number of trainable parameters = 85952456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 09:24, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.439100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.408500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.437400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.453500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.446700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.428300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.446100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.411800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.416900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.435700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.434900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.383500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.411800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.436600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.474800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.419900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.455200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.374500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>5.453800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.462400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>5.397400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.444900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>5.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.437300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.413400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>5.421300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.440400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.427300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.426700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>5.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>5.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>5.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>5.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>5.390100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>5.411500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>5.388700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>5.398700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.461200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>5.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>5.416100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>5.455700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>5.399200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.420200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>5.385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.411900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>5.425100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>5.449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.389100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>5.412400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>5.447400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>5.394200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.406600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>5.404500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>5.425500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>5.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>5.398300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>5.438800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>5.433300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>5.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>5.400200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>5.418700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>5.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>5.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>5.428000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>5.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>5.407100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>5.411700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>5.375600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>5.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>5.438300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>5.405600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>5.427700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>5.431100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>5.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>5.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.419100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-24 15:17:46,306 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-24 15:17:46,309 >> Saving model checkpoint to /tmp/tmpqtgpb1b0\n",
      "[INFO|configuration_utils.py:457] 2023-03-24 15:17:46,312 >> Configuration saved in /tmp/tmpqtgpb1b0/config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-24 15:17:46,558 >> Model weights saved in /tmp/tmpqtgpb1b0/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:203] 2023-03-24 15:17:46,559 >> Image processor saved in /tmp/tmpqtgpb1b0/preprocessor_config.json\n",
      "[INFO|modelcard.py:449] 2023-03-24 15:17:46,621 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Image Classification', 'type': 'image-classification'}, 'dataset': {'name': 'Maysee/tiny-imagenet', 'type': 'imagefolder', 'config': 'default', 'split': 'train', 'args': 'default'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =          0.8\n",
      "  total_flos               = 4627079235GF\n",
      "  train_loss               =       5.4236\n",
      "  train_runtime            =   0:09:24.66\n",
      "  train_samples_per_second =      113.342\n",
      "  train_steps_per_second   =        1.771\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_image_classification.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path google/vit-base-patch16-224\n",
    "    --dataset_name Maysee/tiny-imagenet\n",
    "    --do_train\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 64\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --metric_for_best_model accuracy\n",
    "    --max_steps 1000\n",
    "    --train_val_split 0.2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --ignore_mismatched_sizes True\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_image_classification.main()\n",
    "    result = get_results(tmp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "7a6856c7-3c94-4d27-823b-16e9c981d5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'pymp*': No such file or directory\n",
      "rm: cannot remove './tmp*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "933a269d-2d96-4e5c-99d9-b91d08622b1f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-24 15:17:47,413 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-24 15:17:47,414 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/24/2023 15:17:47 - WARNING - run_image_classification - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/24/2023 15:17:47 - INFO - run_image_classification - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=True,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp3l29cbbu/runs/Mar24_15-17-47_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=greedy,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=accuracy,\n",
      "min_lr=1e-05,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp3l29cbbu,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=64,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp3l29cbbu,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/24/2023 15:17:47 - INFO - datasets.builder - Using custom data configuration Maysee--tiny-imagenet-b0676a0e6b48ef45\n",
      "03/24/2023 15:17:47 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/24/2023 15:17:47 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\n",
      "03/24/2023 15:17:47 - WARNING - datasets.builder - Found cached dataset parquet (/root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "03/24/2023 15:17:47 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e040e33a12f948cd9b06297038a816bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/24/2023 15:17:47 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b0fb943218e6befa.arrow\n",
      "03/24/2023 15:17:47 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-fc5ce1ae43a8f6a5.arrow\n",
      "03/24/2023 15:17:47 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-18842866901c8da8.arrow and /root/.cache/huggingface/datasets/Maysee___parquet/Maysee--tiny-imagenet-b0676a0e6b48ef45/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-6389ebf601dcdb17.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-24 15:17:47,844 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/2ddc9d4e473d7ba52128f0df4723e478fa14fb80/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 15:17:47,846 >> Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"finetuning_task\": \"image-classification\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"n01443537\",\n",
      "    \"1\": \"n01629819\",\n",
      "    \"10\": \"n01784675\",\n",
      "    \"100\": \"n03447447\",\n",
      "    \"101\": \"n03544143\",\n",
      "    \"102\": \"n03584254\",\n",
      "    \"103\": \"n03599486\",\n",
      "    \"104\": \"n03617480\",\n",
      "    \"105\": \"n03637318\",\n",
      "    \"106\": \"n03649909\",\n",
      "    \"107\": \"n03662601\",\n",
      "    \"108\": \"n03670208\",\n",
      "    \"109\": \"n03706229\",\n",
      "    \"11\": \"n01882714\",\n",
      "    \"110\": \"n03733131\",\n",
      "    \"111\": \"n03763968\",\n",
      "    \"112\": \"n03770439\",\n",
      "    \"113\": \"n03796401\",\n",
      "    \"114\": \"n03814639\",\n",
      "    \"115\": \"n03837869\",\n",
      "    \"116\": \"n03838899\",\n",
      "    \"117\": \"n03854065\",\n",
      "    \"118\": \"n03891332\",\n",
      "    \"119\": \"n03902125\",\n",
      "    \"12\": \"n01910747\",\n",
      "    \"120\": \"n03930313\",\n",
      "    \"121\": \"n03937543\",\n",
      "    \"122\": \"n03970156\",\n",
      "    \"123\": \"n03977966\",\n",
      "    \"124\": \"n03980874\",\n",
      "    \"125\": \"n03983396\",\n",
      "    \"126\": \"n03992509\",\n",
      "    \"127\": \"n04008634\",\n",
      "    \"128\": \"n04023962\",\n",
      "    \"129\": \"n04070727\",\n",
      "    \"13\": \"n01917289\",\n",
      "    \"130\": \"n04074963\",\n",
      "    \"131\": \"n04099969\",\n",
      "    \"132\": \"n04118538\",\n",
      "    \"133\": \"n04133789\",\n",
      "    \"134\": \"n04146614\",\n",
      "    \"135\": \"n04149813\",\n",
      "    \"136\": \"n04179913\",\n",
      "    \"137\": \"n04251144\",\n",
      "    \"138\": \"n04254777\",\n",
      "    \"139\": \"n04259630\",\n",
      "    \"14\": \"n01944390\",\n",
      "    \"140\": \"n04265275\",\n",
      "    \"141\": \"n04275548\",\n",
      "    \"142\": \"n04285008\",\n",
      "    \"143\": \"n04311004\",\n",
      "    \"144\": \"n04328186\",\n",
      "    \"145\": \"n04356056\",\n",
      "    \"146\": \"n04366367\",\n",
      "    \"147\": \"n04371430\",\n",
      "    \"148\": \"n04376876\",\n",
      "    \"149\": \"n04398044\",\n",
      "    \"15\": \"n01950731\",\n",
      "    \"150\": \"n04399382\",\n",
      "    \"151\": \"n04417672\",\n",
      "    \"152\": \"n04456115\",\n",
      "    \"153\": \"n04465666\",\n",
      "    \"154\": \"n04486054\",\n",
      "    \"155\": \"n04487081\",\n",
      "    \"156\": \"n04501370\",\n",
      "    \"157\": \"n04507155\",\n",
      "    \"158\": \"n04532106\",\n",
      "    \"159\": \"n04532670\",\n",
      "    \"16\": \"n01983481\",\n",
      "    \"160\": \"n04540053\",\n",
      "    \"161\": \"n04560804\",\n",
      "    \"162\": \"n04562935\",\n",
      "    \"163\": \"n04596742\",\n",
      "    \"164\": \"n04598010\",\n",
      "    \"165\": \"n06596364\",\n",
      "    \"166\": \"n07056680\",\n",
      "    \"167\": \"n07583066\",\n",
      "    \"168\": \"n07614500\",\n",
      "    \"169\": \"n07615774\",\n",
      "    \"17\": \"n01984695\",\n",
      "    \"170\": \"n07646821\",\n",
      "    \"171\": \"n07647870\",\n",
      "    \"172\": \"n07657664\",\n",
      "    \"173\": \"n07695742\",\n",
      "    \"174\": \"n07711569\",\n",
      "    \"175\": \"n07715103\",\n",
      "    \"176\": \"n07720875\",\n",
      "    \"177\": \"n07749582\",\n",
      "    \"178\": \"n07753592\",\n",
      "    \"179\": \"n07768694\",\n",
      "    \"18\": \"n02002724\",\n",
      "    \"180\": \"n07871810\",\n",
      "    \"181\": \"n07873807\",\n",
      "    \"182\": \"n07875152\",\n",
      "    \"183\": \"n07920052\",\n",
      "    \"184\": \"n07975909\",\n",
      "    \"185\": \"n08496334\",\n",
      "    \"186\": \"n08620881\",\n",
      "    \"187\": \"n08742578\",\n",
      "    \"188\": \"n09193705\",\n",
      "    \"189\": \"n09246464\",\n",
      "    \"19\": \"n02056570\",\n",
      "    \"190\": \"n09256479\",\n",
      "    \"191\": \"n09332890\",\n",
      "    \"192\": \"n09428293\",\n",
      "    \"193\": \"n12267677\",\n",
      "    \"194\": \"n12520864\",\n",
      "    \"195\": \"n13001041\",\n",
      "    \"196\": \"n13652335\",\n",
      "    \"197\": \"n13652994\",\n",
      "    \"198\": \"n13719102\",\n",
      "    \"199\": \"n14991210\",\n",
      "    \"2\": \"n01641577\",\n",
      "    \"20\": \"n02058221\",\n",
      "    \"21\": \"n02074367\",\n",
      "    \"22\": \"n02094433\",\n",
      "    \"23\": \"n02099601\",\n",
      "    \"24\": \"n02099712\",\n",
      "    \"25\": \"n02106662\",\n",
      "    \"26\": \"n02113799\",\n",
      "    \"27\": \"n02123045\",\n",
      "    \"28\": \"n02123394\",\n",
      "    \"29\": \"n02124075\",\n",
      "    \"3\": \"n01644900\",\n",
      "    \"30\": \"n02125311\",\n",
      "    \"31\": \"n02129165\",\n",
      "    \"32\": \"n02132136\",\n",
      "    \"33\": \"n02165456\",\n",
      "    \"34\": \"n02226429\",\n",
      "    \"35\": \"n02231487\",\n",
      "    \"36\": \"n02233338\",\n",
      "    \"37\": \"n02236044\",\n",
      "    \"38\": \"n02268443\",\n",
      "    \"39\": \"n02279972\",\n",
      "    \"4\": \"n01698640\",\n",
      "    \"40\": \"n02281406\",\n",
      "    \"41\": \"n02321529\",\n",
      "    \"42\": \"n02364673\",\n",
      "    \"43\": \"n02395406\",\n",
      "    \"44\": \"n02403003\",\n",
      "    \"45\": \"n02410509\",\n",
      "    \"46\": \"n02415577\",\n",
      "    \"47\": \"n02423022\",\n",
      "    \"48\": \"n02437312\",\n",
      "    \"49\": \"n02480495\",\n",
      "    \"5\": \"n01742172\",\n",
      "    \"50\": \"n02481823\",\n",
      "    \"51\": \"n02486410\",\n",
      "    \"52\": \"n02504458\",\n",
      "    \"53\": \"n02509815\",\n",
      "    \"54\": \"n02666347\",\n",
      "    \"55\": \"n02669723\",\n",
      "    \"56\": \"n02699494\",\n",
      "    \"57\": \"n02769748\",\n",
      "    \"58\": \"n02788148\",\n",
      "    \"59\": \"n02791270\",\n",
      "    \"6\": \"n01768244\",\n",
      "    \"60\": \"n02793495\",\n",
      "    \"61\": \"n02795169\",\n",
      "    \"62\": \"n02802426\",\n",
      "    \"63\": \"n02808440\",\n",
      "    \"64\": \"n02814533\",\n",
      "    \"65\": \"n02814860\",\n",
      "    \"66\": \"n02815834\",\n",
      "    \"67\": \"n02823428\",\n",
      "    \"68\": \"n02837789\",\n",
      "    \"69\": \"n02841315\",\n",
      "    \"7\": \"n01770393\",\n",
      "    \"70\": \"n02843684\",\n",
      "    \"71\": \"n02883205\",\n",
      "    \"72\": \"n02892201\",\n",
      "    \"73\": \"n02909870\",\n",
      "    \"74\": \"n02917067\",\n",
      "    \"75\": \"n02927161\",\n",
      "    \"76\": \"n02948072\",\n",
      "    \"77\": \"n02950826\",\n",
      "    \"78\": \"n02963159\",\n",
      "    \"79\": \"n02977058\",\n",
      "    \"8\": \"n01774384\",\n",
      "    \"80\": \"n02988304\",\n",
      "    \"81\": \"n03014705\",\n",
      "    \"82\": \"n03026506\",\n",
      "    \"83\": \"n03042490\",\n",
      "    \"84\": \"n03085013\",\n",
      "    \"85\": \"n03089624\",\n",
      "    \"86\": \"n03100240\",\n",
      "    \"87\": \"n03126707\",\n",
      "    \"88\": \"n03160309\",\n",
      "    \"89\": \"n03179701\",\n",
      "    \"9\": \"n01774750\",\n",
      "    \"90\": \"n03201208\",\n",
      "    \"91\": \"n03255030\",\n",
      "    \"92\": \"n03355925\",\n",
      "    \"93\": \"n03373237\",\n",
      "    \"94\": \"n03388043\",\n",
      "    \"95\": \"n03393912\",\n",
      "    \"96\": \"n03400231\",\n",
      "    \"97\": \"n03404251\",\n",
      "    \"98\": \"n03424325\",\n",
      "    \"99\": \"n03444034\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"n01443537\": \"0\",\n",
      "    \"n01629819\": \"1\",\n",
      "    \"n01641577\": \"2\",\n",
      "    \"n01644900\": \"3\",\n",
      "    \"n01698640\": \"4\",\n",
      "    \"n01742172\": \"5\",\n",
      "    \"n01768244\": \"6\",\n",
      "    \"n01770393\": \"7\",\n",
      "    \"n01774384\": \"8\",\n",
      "    \"n01774750\": \"9\",\n",
      "    \"n01784675\": \"10\",\n",
      "    \"n01882714\": \"11\",\n",
      "    \"n01910747\": \"12\",\n",
      "    \"n01917289\": \"13\",\n",
      "    \"n01944390\": \"14\",\n",
      "    \"n01950731\": \"15\",\n",
      "    \"n01983481\": \"16\",\n",
      "    \"n01984695\": \"17\",\n",
      "    \"n02002724\": \"18\",\n",
      "    \"n02056570\": \"19\",\n",
      "    \"n02058221\": \"20\",\n",
      "    \"n02074367\": \"21\",\n",
      "    \"n02094433\": \"22\",\n",
      "    \"n02099601\": \"23\",\n",
      "    \"n02099712\": \"24\",\n",
      "    \"n02106662\": \"25\",\n",
      "    \"n02113799\": \"26\",\n",
      "    \"n02123045\": \"27\",\n",
      "    \"n02123394\": \"28\",\n",
      "    \"n02124075\": \"29\",\n",
      "    \"n02125311\": \"30\",\n",
      "    \"n02129165\": \"31\",\n",
      "    \"n02132136\": \"32\",\n",
      "    \"n02165456\": \"33\",\n",
      "    \"n02226429\": \"34\",\n",
      "    \"n02231487\": \"35\",\n",
      "    \"n02233338\": \"36\",\n",
      "    \"n02236044\": \"37\",\n",
      "    \"n02268443\": \"38\",\n",
      "    \"n02279972\": \"39\",\n",
      "    \"n02281406\": \"40\",\n",
      "    \"n02321529\": \"41\",\n",
      "    \"n02364673\": \"42\",\n",
      "    \"n02395406\": \"43\",\n",
      "    \"n02403003\": \"44\",\n",
      "    \"n02410509\": \"45\",\n",
      "    \"n02415577\": \"46\",\n",
      "    \"n02423022\": \"47\",\n",
      "    \"n02437312\": \"48\",\n",
      "    \"n02480495\": \"49\",\n",
      "    \"n02481823\": \"50\",\n",
      "    \"n02486410\": \"51\",\n",
      "    \"n02504458\": \"52\",\n",
      "    \"n02509815\": \"53\",\n",
      "    \"n02666347\": \"54\",\n",
      "    \"n02669723\": \"55\",\n",
      "    \"n02699494\": \"56\",\n",
      "    \"n02769748\": \"57\",\n",
      "    \"n02788148\": \"58\",\n",
      "    \"n02791270\": \"59\",\n",
      "    \"n02793495\": \"60\",\n",
      "    \"n02795169\": \"61\",\n",
      "    \"n02802426\": \"62\",\n",
      "    \"n02808440\": \"63\",\n",
      "    \"n02814533\": \"64\",\n",
      "    \"n02814860\": \"65\",\n",
      "    \"n02815834\": \"66\",\n",
      "    \"n02823428\": \"67\",\n",
      "    \"n02837789\": \"68\",\n",
      "    \"n02841315\": \"69\",\n",
      "    \"n02843684\": \"70\",\n",
      "    \"n02883205\": \"71\",\n",
      "    \"n02892201\": \"72\",\n",
      "    \"n02909870\": \"73\",\n",
      "    \"n02917067\": \"74\",\n",
      "    \"n02927161\": \"75\",\n",
      "    \"n02948072\": \"76\",\n",
      "    \"n02950826\": \"77\",\n",
      "    \"n02963159\": \"78\",\n",
      "    \"n02977058\": \"79\",\n",
      "    \"n02988304\": \"80\",\n",
      "    \"n03014705\": \"81\",\n",
      "    \"n03026506\": \"82\",\n",
      "    \"n03042490\": \"83\",\n",
      "    \"n03085013\": \"84\",\n",
      "    \"n03089624\": \"85\",\n",
      "    \"n03100240\": \"86\",\n",
      "    \"n03126707\": \"87\",\n",
      "    \"n03160309\": \"88\",\n",
      "    \"n03179701\": \"89\",\n",
      "    \"n03201208\": \"90\",\n",
      "    \"n03255030\": \"91\",\n",
      "    \"n03355925\": \"92\",\n",
      "    \"n03373237\": \"93\",\n",
      "    \"n03388043\": \"94\",\n",
      "    \"n03393912\": \"95\",\n",
      "    \"n03400231\": \"96\",\n",
      "    \"n03404251\": \"97\",\n",
      "    \"n03424325\": \"98\",\n",
      "    \"n03444034\": \"99\",\n",
      "    \"n03447447\": \"100\",\n",
      "    \"n03544143\": \"101\",\n",
      "    \"n03584254\": \"102\",\n",
      "    \"n03599486\": \"103\",\n",
      "    \"n03617480\": \"104\",\n",
      "    \"n03637318\": \"105\",\n",
      "    \"n03649909\": \"106\",\n",
      "    \"n03662601\": \"107\",\n",
      "    \"n03670208\": \"108\",\n",
      "    \"n03706229\": \"109\",\n",
      "    \"n03733131\": \"110\",\n",
      "    \"n03763968\": \"111\",\n",
      "    \"n03770439\": \"112\",\n",
      "    \"n03796401\": \"113\",\n",
      "    \"n03814639\": \"114\",\n",
      "    \"n03837869\": \"115\",\n",
      "    \"n03838899\": \"116\",\n",
      "    \"n03854065\": \"117\",\n",
      "    \"n03891332\": \"118\",\n",
      "    \"n03902125\": \"119\",\n",
      "    \"n03930313\": \"120\",\n",
      "    \"n03937543\": \"121\",\n",
      "    \"n03970156\": \"122\",\n",
      "    \"n03977966\": \"123\",\n",
      "    \"n03980874\": \"124\",\n",
      "    \"n03983396\": \"125\",\n",
      "    \"n03992509\": \"126\",\n",
      "    \"n04008634\": \"127\",\n",
      "    \"n04023962\": \"128\",\n",
      "    \"n04070727\": \"129\",\n",
      "    \"n04074963\": \"130\",\n",
      "    \"n04099969\": \"131\",\n",
      "    \"n04118538\": \"132\",\n",
      "    \"n04133789\": \"133\",\n",
      "    \"n04146614\": \"134\",\n",
      "    \"n04149813\": \"135\",\n",
      "    \"n04179913\": \"136\",\n",
      "    \"n04251144\": \"137\",\n",
      "    \"n04254777\": \"138\",\n",
      "    \"n04259630\": \"139\",\n",
      "    \"n04265275\": \"140\",\n",
      "    \"n04275548\": \"141\",\n",
      "    \"n04285008\": \"142\",\n",
      "    \"n04311004\": \"143\",\n",
      "    \"n04328186\": \"144\",\n",
      "    \"n04356056\": \"145\",\n",
      "    \"n04366367\": \"146\",\n",
      "    \"n04371430\": \"147\",\n",
      "    \"n04376876\": \"148\",\n",
      "    \"n04398044\": \"149\",\n",
      "    \"n04399382\": \"150\",\n",
      "    \"n04417672\": \"151\",\n",
      "    \"n04456115\": \"152\",\n",
      "    \"n04465666\": \"153\",\n",
      "    \"n04486054\": \"154\",\n",
      "    \"n04487081\": \"155\",\n",
      "    \"n04501370\": \"156\",\n",
      "    \"n04507155\": \"157\",\n",
      "    \"n04532106\": \"158\",\n",
      "    \"n04532670\": \"159\",\n",
      "    \"n04540053\": \"160\",\n",
      "    \"n04560804\": \"161\",\n",
      "    \"n04562935\": \"162\",\n",
      "    \"n04596742\": \"163\",\n",
      "    \"n04598010\": \"164\",\n",
      "    \"n06596364\": \"165\",\n",
      "    \"n07056680\": \"166\",\n",
      "    \"n07583066\": \"167\",\n",
      "    \"n07614500\": \"168\",\n",
      "    \"n07615774\": \"169\",\n",
      "    \"n07646821\": \"170\",\n",
      "    \"n07647870\": \"171\",\n",
      "    \"n07657664\": \"172\",\n",
      "    \"n07695742\": \"173\",\n",
      "    \"n07711569\": \"174\",\n",
      "    \"n07715103\": \"175\",\n",
      "    \"n07720875\": \"176\",\n",
      "    \"n07749582\": \"177\",\n",
      "    \"n07753592\": \"178\",\n",
      "    \"n07768694\": \"179\",\n",
      "    \"n07871810\": \"180\",\n",
      "    \"n07873807\": \"181\",\n",
      "    \"n07875152\": \"182\",\n",
      "    \"n07920052\": \"183\",\n",
      "    \"n07975909\": \"184\",\n",
      "    \"n08496334\": \"185\",\n",
      "    \"n08620881\": \"186\",\n",
      "    \"n08742578\": \"187\",\n",
      "    \"n09193705\": \"188\",\n",
      "    \"n09246464\": \"189\",\n",
      "    \"n09256479\": \"190\",\n",
      "    \"n09332890\": \"191\",\n",
      "    \"n09428293\": \"192\",\n",
      "    \"n12267677\": \"193\",\n",
      "    \"n12520864\": \"194\",\n",
      "    \"n13001041\": \"195\",\n",
      "    \"n13652335\": \"196\",\n",
      "    \"n13652994\": \"197\",\n",
      "    \"n13719102\": \"198\",\n",
      "    \"n14991210\": \"199\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-24 15:17:47,863 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/2ddc9d4e473d7ba52128f0df4723e478fa14fb80/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:3019] 2023-03-24 15:17:48,649 >> All model checkpoint weights were used when initializing ViTForImageClassification.\n",
      "\n",
      "[WARNING|modeling_utils.py:3041] 2023-03-24 15:17:48,650 >> Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([200, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([200]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-03-24 15:17:48,682 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/2ddc9d4e473d7ba52128f0df4723e478fa14fb80/preprocessor_config.json\n",
      "[INFO|configuration_utils.py:668] 2023-03-24 15:17:48,714 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--vit-base-patch16-224/snapshots/2ddc9d4e473d7ba52128f0df4723e478fa14fb80/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-24 15:17:48,722 >> Model config ViTConfig {\n",
      "  \"_name_or_path\": \"google/vit-base-patch16-224\",\n",
      "  \"architectures\": [\n",
      "    \"ViTForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"tench, Tinca tinca\",\n",
      "    \"1\": \"goldfish, Carassius auratus\",\n",
      "    \"2\": \"great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\",\n",
      "    \"3\": \"tiger shark, Galeocerdo cuvieri\",\n",
      "    \"4\": \"hammerhead, hammerhead shark\",\n",
      "    \"5\": \"electric ray, crampfish, numbfish, torpedo\",\n",
      "    \"6\": \"stingray\",\n",
      "    \"7\": \"cock\",\n",
      "    \"8\": \"hen\",\n",
      "    \"9\": \"ostrich, Struthio camelus\",\n",
      "    \"10\": \"brambling, Fringilla montifringilla\",\n",
      "    \"11\": \"goldfinch, Carduelis carduelis\",\n",
      "    \"12\": \"house finch, linnet, Carpodacus mexicanus\",\n",
      "    \"13\": \"junco, snowbird\",\n",
      "    \"14\": \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\",\n",
      "    \"15\": \"robin, American robin, Turdus migratorius\",\n",
      "    \"16\": \"bulbul\",\n",
      "    \"17\": \"jay\",\n",
      "    \"18\": \"magpie\",\n",
      "    \"19\": \"chickadee\",\n",
      "    \"20\": \"water ouzel, dipper\",\n",
      "    \"21\": \"kite\",\n",
      "    \"22\": \"bald eagle, American eagle, Haliaeetus leucocephalus\",\n",
      "    \"23\": \"vulture\",\n",
      "    \"24\": \"great grey owl, great gray owl, Strix nebulosa\",\n",
      "    \"25\": \"European fire salamander, Salamandra salamandra\",\n",
      "    \"26\": \"common newt, Triturus vulgaris\",\n",
      "    \"27\": \"eft\",\n",
      "    \"28\": \"spotted salamander, Ambystoma maculatum\",\n",
      "    \"29\": \"axolotl, mud puppy, Ambystoma mexicanum\",\n",
      "    \"30\": \"bullfrog, Rana catesbeiana\",\n",
      "    \"31\": \"tree frog, tree-frog\",\n",
      "    \"32\": \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\",\n",
      "    \"33\": \"loggerhead, loggerhead turtle, Caretta caretta\",\n",
      "    \"34\": \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\",\n",
      "    \"35\": \"mud turtle\",\n",
      "    \"36\": \"terrapin\",\n",
      "    \"37\": \"box turtle, box tortoise\",\n",
      "    \"38\": \"banded gecko\",\n",
      "    \"39\": \"common iguana, iguana, Iguana iguana\",\n",
      "    \"40\": \"American chameleon, anole, Anolis carolinensis\",\n",
      "    \"41\": \"whiptail, whiptail lizard\",\n",
      "    \"42\": \"agama\",\n",
      "    \"43\": \"frilled lizard, Chlamydosaurus kingi\",\n",
      "    \"44\": \"alligator lizard\",\n",
      "    \"45\": \"Gila monster, Heloderma suspectum\",\n",
      "    \"46\": \"green lizard, Lacerta viridis\",\n",
      "    \"47\": \"African chameleon, Chamaeleo chamaeleon\",\n",
      "    \"48\": \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis\",\n",
      "    \"49\": \"African crocodile, Nile crocodile, Crocodylus niloticus\",\n",
      "    \"50\": \"American alligator, Alligator mississipiensis\",\n",
      "    \"51\": \"triceratops\",\n",
      "    \"52\": \"thunder snake, worm snake, Carphophis amoenus\",\n",
      "    \"53\": \"ringneck snake, ring-necked snake, ring snake\",\n",
      "    \"54\": \"hognose snake, puff adder, sand viper\",\n",
      "    \"55\": \"green snake, grass snake\",\n",
      "    \"56\": \"king snake, kingsnake\",\n",
      "    \"57\": \"garter snake, grass snake\",\n",
      "    \"58\": \"water snake\",\n",
      "    \"59\": \"vine snake\",\n",
      "    \"60\": \"night snake, Hypsiglena torquata\",\n",
      "    \"61\": \"boa constrictor, Constrictor constrictor\",\n",
      "    \"62\": \"rock python, rock snake, Python sebae\",\n",
      "    \"63\": \"Indian cobra, Naja naja\",\n",
      "    \"64\": \"green mamba\",\n",
      "    \"65\": \"sea snake\",\n",
      "    \"66\": \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\",\n",
      "    \"67\": \"diamondback, diamondback rattlesnake, Crotalus adamanteus\",\n",
      "    \"68\": \"sidewinder, horned rattlesnake, Crotalus cerastes\",\n",
      "    \"69\": \"trilobite\",\n",
      "    \"70\": \"harvestman, daddy longlegs, Phalangium opilio\",\n",
      "    \"71\": \"scorpion\",\n",
      "    \"72\": \"black and gold garden spider, Argiope aurantia\",\n",
      "    \"73\": \"barn spider, Araneus cavaticus\",\n",
      "    \"74\": \"garden spider, Aranea diademata\",\n",
      "    \"75\": \"black widow, Latrodectus mactans\",\n",
      "    \"76\": \"tarantula\",\n",
      "    \"77\": \"wolf spider, hunting spider\",\n",
      "    \"78\": \"tick\",\n",
      "    \"79\": \"centipede\",\n",
      "    \"80\": \"black grouse\",\n",
      "    \"81\": \"ptarmigan\",\n",
      "    \"82\": \"ruffed grouse, partridge, Bonasa umbellus\",\n",
      "    \"83\": \"prairie chicken, prairie grouse, prairie fowl\",\n",
      "    \"84\": \"peacock\",\n",
      "    \"85\": \"quail\",\n",
      "    \"86\": \"partridge\",\n",
      "    \"87\": \"African grey, African gray, Psittacus erithacus\",\n",
      "    \"88\": \"macaw\",\n",
      "    \"89\": \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\",\n",
      "    \"90\": \"lorikeet\",\n",
      "    \"91\": \"coucal\",\n",
      "    \"92\": \"bee eater\",\n",
      "    \"93\": \"hornbill\",\n",
      "    \"94\": \"hummingbird\",\n",
      "    \"95\": \"jacamar\",\n",
      "    \"96\": \"toucan\",\n",
      "    \"97\": \"drake\",\n",
      "    \"98\": \"red-breasted merganser, Mergus serrator\",\n",
      "    \"99\": \"goose\",\n",
      "    \"100\": \"black swan, Cygnus atratus\",\n",
      "    \"101\": \"tusker\",\n",
      "    \"102\": \"echidna, spiny anteater, anteater\",\n",
      "    \"103\": \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\",\n",
      "    \"104\": \"wallaby, brush kangaroo\",\n",
      "    \"105\": \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\",\n",
      "    \"106\": \"wombat\",\n",
      "    \"107\": \"jellyfish\",\n",
      "    \"108\": \"sea anemone, anemone\",\n",
      "    \"109\": \"brain coral\",\n",
      "    \"110\": \"flatworm, platyhelminth\",\n",
      "    \"111\": \"nematode, nematode worm, roundworm\",\n",
      "    \"112\": \"conch\",\n",
      "    \"113\": \"snail\",\n",
      "    \"114\": \"slug\",\n",
      "    \"115\": \"sea slug, nudibranch\",\n",
      "    \"116\": \"chiton, coat-of-mail shell, sea cradle, polyplacophore\",\n",
      "    \"117\": \"chambered nautilus, pearly nautilus, nautilus\",\n",
      "    \"118\": \"Dungeness crab, Cancer magister\",\n",
      "    \"119\": \"rock crab, Cancer irroratus\",\n",
      "    \"120\": \"fiddler crab\",\n",
      "    \"121\": \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica\",\n",
      "    \"122\": \"American lobster, Northern lobster, Maine lobster, Homarus americanus\",\n",
      "    \"123\": \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\",\n",
      "    \"124\": \"crayfish, crawfish, crawdad, crawdaddy\",\n",
      "    \"125\": \"hermit crab\",\n",
      "    \"126\": \"isopod\",\n",
      "    \"127\": \"white stork, Ciconia ciconia\",\n",
      "    \"128\": \"black stork, Ciconia nigra\",\n",
      "    \"129\": \"spoonbill\",\n",
      "    \"130\": \"flamingo\",\n",
      "    \"131\": \"little blue heron, Egretta caerulea\",\n",
      "    \"132\": \"American egret, great white heron, Egretta albus\",\n",
      "    \"133\": \"bittern\",\n",
      "    \"134\": \"crane\",\n",
      "    \"135\": \"limpkin, Aramus pictus\",\n",
      "    \"136\": \"European gallinule, Porphyrio porphyrio\",\n",
      "    \"137\": \"American coot, marsh hen, mud hen, water hen, Fulica americana\",\n",
      "    \"138\": \"bustard\",\n",
      "    \"139\": \"ruddy turnstone, Arenaria interpres\",\n",
      "    \"140\": \"red-backed sandpiper, dunlin, Erolia alpina\",\n",
      "    \"141\": \"redshank, Tringa totanus\",\n",
      "    \"142\": \"dowitcher\",\n",
      "    \"143\": \"oystercatcher, oyster catcher\",\n",
      "    \"144\": \"pelican\",\n",
      "    \"145\": \"king penguin, Aptenodytes patagonica\",\n",
      "    \"146\": \"albatross, mollymawk\",\n",
      "    \"147\": \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\",\n",
      "    \"148\": \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\",\n",
      "    \"149\": \"dugong, Dugong dugon\",\n",
      "    \"150\": \"sea lion\",\n",
      "    \"151\": \"Chihuahua\",\n",
      "    \"152\": \"Japanese spaniel\",\n",
      "    \"153\": \"Maltese dog, Maltese terrier, Maltese\",\n",
      "    \"154\": \"Pekinese, Pekingese, Peke\",\n",
      "    \"155\": \"Shih-Tzu\",\n",
      "    \"156\": \"Blenheim spaniel\",\n",
      "    \"157\": \"papillon\",\n",
      "    \"158\": \"toy terrier\",\n",
      "    \"159\": \"Rhodesian ridgeback\",\n",
      "    \"160\": \"Afghan hound, Afghan\",\n",
      "    \"161\": \"basset, basset hound\",\n",
      "    \"162\": \"beagle\",\n",
      "    \"163\": \"bloodhound, sleuthhound\",\n",
      "    \"164\": \"bluetick\",\n",
      "    \"165\": \"black-and-tan coonhound\",\n",
      "    \"166\": \"Walker hound, Walker foxhound\",\n",
      "    \"167\": \"English foxhound\",\n",
      "    \"168\": \"redbone\",\n",
      "    \"169\": \"borzoi, Russian wolfhound\",\n",
      "    \"170\": \"Irish wolfhound\",\n",
      "    \"171\": \"Italian greyhound\",\n",
      "    \"172\": \"whippet\",\n",
      "    \"173\": \"Ibizan hound, Ibizan Podenco\",\n",
      "    \"174\": \"Norwegian elkhound, elkhound\",\n",
      "    \"175\": \"otterhound, otter hound\",\n",
      "    \"176\": \"Saluki, gazelle hound\",\n",
      "    \"177\": \"Scottish deerhound, deerhound\",\n",
      "    \"178\": \"Weimaraner\",\n",
      "    \"179\": \"Staffordshire bullterrier, Staffordshire bull terrier\",\n",
      "    \"180\": \"American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\",\n",
      "    \"181\": \"Bedlington terrier\",\n",
      "    \"182\": \"Border terrier\",\n",
      "    \"183\": \"Kerry blue terrier\",\n",
      "    \"184\": \"Irish terrier\",\n",
      "    \"185\": \"Norfolk terrier\",\n",
      "    \"186\": \"Norwich terrier\",\n",
      "    \"187\": \"Yorkshire terrier\",\n",
      "    \"188\": \"wire-haired fox terrier\",\n",
      "    \"189\": \"Lakeland terrier\",\n",
      "    \"190\": \"Sealyham terrier, Sealyham\",\n",
      "    \"191\": \"Airedale, Airedale terrier\",\n",
      "    \"192\": \"cairn, cairn terrier\",\n",
      "    \"193\": \"Australian terrier\",\n",
      "    \"194\": \"Dandie Dinmont, Dandie Dinmont terrier\",\n",
      "    \"195\": \"Boston bull, Boston terrier\",\n",
      "    \"196\": \"miniature schnauzer\",\n",
      "    \"197\": \"giant schnauzer\",\n",
      "    \"198\": \"standard schnauzer\",\n",
      "    \"199\": \"Scotch terrier, Scottish terrier, Scottie\",\n",
      "    \"200\": \"Tibetan terrier, chrysanthemum dog\",\n",
      "    \"201\": \"silky terrier, Sydney silky\",\n",
      "    \"202\": \"soft-coated wheaten terrier\",\n",
      "    \"203\": \"West Highland white terrier\",\n",
      "    \"204\": \"Lhasa, Lhasa apso\",\n",
      "    \"205\": \"flat-coated retriever\",\n",
      "    \"206\": \"curly-coated retriever\",\n",
      "    \"207\": \"golden retriever\",\n",
      "    \"208\": \"Labrador retriever\",\n",
      "    \"209\": \"Chesapeake Bay retriever\",\n",
      "    \"210\": \"German short-haired pointer\",\n",
      "    \"211\": \"vizsla, Hungarian pointer\",\n",
      "    \"212\": \"English setter\",\n",
      "    \"213\": \"Irish setter, red setter\",\n",
      "    \"214\": \"Gordon setter\",\n",
      "    \"215\": \"Brittany spaniel\",\n",
      "    \"216\": \"clumber, clumber spaniel\",\n",
      "    \"217\": \"English springer, English springer spaniel\",\n",
      "    \"218\": \"Welsh springer spaniel\",\n",
      "    \"219\": \"cocker spaniel, English cocker spaniel, cocker\",\n",
      "    \"220\": \"Sussex spaniel\",\n",
      "    \"221\": \"Irish water spaniel\",\n",
      "    \"222\": \"kuvasz\",\n",
      "    \"223\": \"schipperke\",\n",
      "    \"224\": \"groenendael\",\n",
      "    \"225\": \"malinois\",\n",
      "    \"226\": \"briard\",\n",
      "    \"227\": \"kelpie\",\n",
      "    \"228\": \"komondor\",\n",
      "    \"229\": \"Old English sheepdog, bobtail\",\n",
      "    \"230\": \"Shetland sheepdog, Shetland sheep dog, Shetland\",\n",
      "    \"231\": \"collie\",\n",
      "    \"232\": \"Border collie\",\n",
      "    \"233\": \"Bouvier des Flandres, Bouviers des Flandres\",\n",
      "    \"234\": \"Rottweiler\",\n",
      "    \"235\": \"German shepherd, German shepherd dog, German police dog, alsatian\",\n",
      "    \"236\": \"Doberman, Doberman pinscher\",\n",
      "    \"237\": \"miniature pinscher\",\n",
      "    \"238\": \"Greater Swiss Mountain dog\",\n",
      "    \"239\": \"Bernese mountain dog\",\n",
      "    \"240\": \"Appenzeller\",\n",
      "    \"241\": \"EntleBucher\",\n",
      "    \"242\": \"boxer\",\n",
      "    \"243\": \"bull mastiff\",\n",
      "    \"244\": \"Tibetan mastiff\",\n",
      "    \"245\": \"French bulldog\",\n",
      "    \"246\": \"Great Dane\",\n",
      "    \"247\": \"Saint Bernard, St Bernard\",\n",
      "    \"248\": \"Eskimo dog, husky\",\n",
      "    \"249\": \"malamute, malemute, Alaskan malamute\",\n",
      "    \"250\": \"Siberian husky\",\n",
      "    \"251\": \"dalmatian, coach dog, carriage dog\",\n",
      "    \"252\": \"affenpinscher, monkey pinscher, monkey dog\",\n",
      "    \"253\": \"basenji\",\n",
      "    \"254\": \"pug, pug-dog\",\n",
      "    \"255\": \"Leonberg\",\n",
      "    \"256\": \"Newfoundland, Newfoundland dog\",\n",
      "    \"257\": \"Great Pyrenees\",\n",
      "    \"258\": \"Samoyed, Samoyede\",\n",
      "    \"259\": \"Pomeranian\",\n",
      "    \"260\": \"chow, chow chow\",\n",
      "    \"261\": \"keeshond\",\n",
      "    \"262\": \"Brabancon griffon\",\n",
      "    \"263\": \"Pembroke, Pembroke Welsh corgi\",\n",
      "    \"264\": \"Cardigan, Cardigan Welsh corgi\",\n",
      "    \"265\": \"toy poodle\",\n",
      "    \"266\": \"miniature poodle\",\n",
      "    \"267\": \"standard poodle\",\n",
      "    \"268\": \"Mexican hairless\",\n",
      "    \"269\": \"timber wolf, grey wolf, gray wolf, Canis lupus\",\n",
      "    \"270\": \"white wolf, Arctic wolf, Canis lupus tundrarum\",\n",
      "    \"271\": \"red wolf, maned wolf, Canis rufus, Canis niger\",\n",
      "    \"272\": \"coyote, prairie wolf, brush wolf, Canis latrans\",\n",
      "    \"273\": \"dingo, warrigal, warragal, Canis dingo\",\n",
      "    \"274\": \"dhole, Cuon alpinus\",\n",
      "    \"275\": \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\",\n",
      "    \"276\": \"hyena, hyaena\",\n",
      "    \"277\": \"red fox, Vulpes vulpes\",\n",
      "    \"278\": \"kit fox, Vulpes macrotis\",\n",
      "    \"279\": \"Arctic fox, white fox, Alopex lagopus\",\n",
      "    \"280\": \"grey fox, gray fox, Urocyon cinereoargenteus\",\n",
      "    \"281\": \"tabby, tabby cat\",\n",
      "    \"282\": \"tiger cat\",\n",
      "    \"283\": \"Persian cat\",\n",
      "    \"284\": \"Siamese cat, Siamese\",\n",
      "    \"285\": \"Egyptian cat\",\n",
      "    \"286\": \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\",\n",
      "    \"287\": \"lynx, catamount\",\n",
      "    \"288\": \"leopard, Panthera pardus\",\n",
      "    \"289\": \"snow leopard, ounce, Panthera uncia\",\n",
      "    \"290\": \"jaguar, panther, Panthera onca, Felis onca\",\n",
      "    \"291\": \"lion, king of beasts, Panthera leo\",\n",
      "    \"292\": \"tiger, Panthera tigris\",\n",
      "    \"293\": \"cheetah, chetah, Acinonyx jubatus\",\n",
      "    \"294\": \"brown bear, bruin, Ursus arctos\",\n",
      "    \"295\": \"American black bear, black bear, Ursus americanus, Euarctos americanus\",\n",
      "    \"296\": \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\",\n",
      "    \"297\": \"sloth bear, Melursus ursinus, Ursus ursinus\",\n",
      "    \"298\": \"mongoose\",\n",
      "    \"299\": \"meerkat, mierkat\",\n",
      "    \"300\": \"tiger beetle\",\n",
      "    \"301\": \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\",\n",
      "    \"302\": \"ground beetle, carabid beetle\",\n",
      "    \"303\": \"long-horned beetle, longicorn, longicorn beetle\",\n",
      "    \"304\": \"leaf beetle, chrysomelid\",\n",
      "    \"305\": \"dung beetle\",\n",
      "    \"306\": \"rhinoceros beetle\",\n",
      "    \"307\": \"weevil\",\n",
      "    \"308\": \"fly\",\n",
      "    \"309\": \"bee\",\n",
      "    \"310\": \"ant, emmet, pismire\",\n",
      "    \"311\": \"grasshopper, hopper\",\n",
      "    \"312\": \"cricket\",\n",
      "    \"313\": \"walking stick, walkingstick, stick insect\",\n",
      "    \"314\": \"cockroach, roach\",\n",
      "    \"315\": \"mantis, mantid\",\n",
      "    \"316\": \"cicada, cicala\",\n",
      "    \"317\": \"leafhopper\",\n",
      "    \"318\": \"lacewing, lacewing fly\",\n",
      "    \"319\": \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\",\n",
      "    \"320\": \"damselfly\",\n",
      "    \"321\": \"admiral\",\n",
      "    \"322\": \"ringlet, ringlet butterfly\",\n",
      "    \"323\": \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\",\n",
      "    \"324\": \"cabbage butterfly\",\n",
      "    \"325\": \"sulphur butterfly, sulfur butterfly\",\n",
      "    \"326\": \"lycaenid, lycaenid butterfly\",\n",
      "    \"327\": \"starfish, sea star\",\n",
      "    \"328\": \"sea urchin\",\n",
      "    \"329\": \"sea cucumber, holothurian\",\n",
      "    \"330\": \"wood rabbit, cottontail, cottontail rabbit\",\n",
      "    \"331\": \"hare\",\n",
      "    \"332\": \"Angora, Angora rabbit\",\n",
      "    \"333\": \"hamster\",\n",
      "    \"334\": \"porcupine, hedgehog\",\n",
      "    \"335\": \"fox squirrel, eastern fox squirrel, Sciurus niger\",\n",
      "    \"336\": \"marmot\",\n",
      "    \"337\": \"beaver\",\n",
      "    \"338\": \"guinea pig, Cavia cobaya\",\n",
      "    \"339\": \"sorrel\",\n",
      "    \"340\": \"zebra\",\n",
      "    \"341\": \"hog, pig, grunter, squealer, Sus scrofa\",\n",
      "    \"342\": \"wild boar, boar, Sus scrofa\",\n",
      "    \"343\": \"warthog\",\n",
      "    \"344\": \"hippopotamus, hippo, river horse, Hippopotamus amphibius\",\n",
      "    \"345\": \"ox\",\n",
      "    \"346\": \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\",\n",
      "    \"347\": \"bison\",\n",
      "    \"348\": \"ram, tup\",\n",
      "    \"349\": \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\",\n",
      "    \"350\": \"ibex, Capra ibex\",\n",
      "    \"351\": \"hartebeest\",\n",
      "    \"352\": \"impala, Aepyceros melampus\",\n",
      "    \"353\": \"gazelle\",\n",
      "    \"354\": \"Arabian camel, dromedary, Camelus dromedarius\",\n",
      "    \"355\": \"llama\",\n",
      "    \"356\": \"weasel\",\n",
      "    \"357\": \"mink\",\n",
      "    \"358\": \"polecat, fitch, foulmart, foumart, Mustela putorius\",\n",
      "    \"359\": \"black-footed ferret, ferret, Mustela nigripes\",\n",
      "    \"360\": \"otter\",\n",
      "    \"361\": \"skunk, polecat, wood pussy\",\n",
      "    \"362\": \"badger\",\n",
      "    \"363\": \"armadillo\",\n",
      "    \"364\": \"three-toed sloth, ai, Bradypus tridactylus\",\n",
      "    \"365\": \"orangutan, orang, orangutang, Pongo pygmaeus\",\n",
      "    \"366\": \"gorilla, Gorilla gorilla\",\n",
      "    \"367\": \"chimpanzee, chimp, Pan troglodytes\",\n",
      "    \"368\": \"gibbon, Hylobates lar\",\n",
      "    \"369\": \"siamang, Hylobates syndactylus, Symphalangus syndactylus\",\n",
      "    \"370\": \"guenon, guenon monkey\",\n",
      "    \"371\": \"patas, hussar monkey, Erythrocebus patas\",\n",
      "    \"372\": \"baboon\",\n",
      "    \"373\": \"macaque\",\n",
      "    \"374\": \"langur\",\n",
      "    \"375\": \"colobus, colobus monkey\",\n",
      "    \"376\": \"proboscis monkey, Nasalis larvatus\",\n",
      "    \"377\": \"marmoset\",\n",
      "    \"378\": \"capuchin, ringtail, Cebus capucinus\",\n",
      "    \"379\": \"howler monkey, howler\",\n",
      "    \"380\": \"titi, titi monkey\",\n",
      "    \"381\": \"spider monkey, Ateles geoffroyi\",\n",
      "    \"382\": \"squirrel monkey, Saimiri sciureus\",\n",
      "    \"383\": \"Madagascar cat, ring-tailed lemur, Lemur catta\",\n",
      "    \"384\": \"indri, indris, Indri indri, Indri brevicaudatus\",\n",
      "    \"385\": \"Indian elephant, Elephas maximus\",\n",
      "    \"386\": \"African elephant, Loxodonta africana\",\n",
      "    \"387\": \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\",\n",
      "    \"388\": \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\",\n",
      "    \"389\": \"barracouta, snoek\",\n",
      "    \"390\": \"eel\",\n",
      "    \"391\": \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\",\n",
      "    \"392\": \"rock beauty, Holocanthus tricolor\",\n",
      "    \"393\": \"anemone fish\",\n",
      "    \"394\": \"sturgeon\",\n",
      "    \"395\": \"gar, garfish, garpike, billfish, Lepisosteus osseus\",\n",
      "    \"396\": \"lionfish\",\n",
      "    \"397\": \"puffer, pufferfish, blowfish, globefish\",\n",
      "    \"398\": \"abacus\",\n",
      "    \"399\": \"abaya\",\n",
      "    \"400\": \"academic gown, academic robe, judge's robe\",\n",
      "    \"401\": \"accordion, piano accordion, squeeze box\",\n",
      "    \"402\": \"acoustic guitar\",\n",
      "    \"403\": \"aircraft carrier, carrier, flattop, attack aircraft carrier\",\n",
      "    \"404\": \"airliner\",\n",
      "    \"405\": \"airship, dirigible\",\n",
      "    \"406\": \"altar\",\n",
      "    \"407\": \"ambulance\",\n",
      "    \"408\": \"amphibian, amphibious vehicle\",\n",
      "    \"409\": \"analog clock\",\n",
      "    \"410\": \"apiary, bee house\",\n",
      "    \"411\": \"apron\",\n",
      "    \"412\": \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\",\n",
      "    \"413\": \"assault rifle, assault gun\",\n",
      "    \"414\": \"backpack, back pack, knapsack, packsack, rucksack, haversack\",\n",
      "    \"415\": \"bakery, bakeshop, bakehouse\",\n",
      "    \"416\": \"balance beam, beam\",\n",
      "    \"417\": \"balloon\",\n",
      "    \"418\": \"ballpoint, ballpoint pen, ballpen, Biro\",\n",
      "    \"419\": \"Band Aid\",\n",
      "    \"420\": \"banjo\",\n",
      "    \"421\": \"bannister, banister, balustrade, balusters, handrail\",\n",
      "    \"422\": \"barbell\",\n",
      "    \"423\": \"barber chair\",\n",
      "    \"424\": \"barbershop\",\n",
      "    \"425\": \"barn\",\n",
      "    \"426\": \"barometer\",\n",
      "    \"427\": \"barrel, cask\",\n",
      "    \"428\": \"barrow, garden cart, lawn cart, wheelbarrow\",\n",
      "    \"429\": \"baseball\",\n",
      "    \"430\": \"basketball\",\n",
      "    \"431\": \"bassinet\",\n",
      "    \"432\": \"bassoon\",\n",
      "    \"433\": \"bathing cap, swimming cap\",\n",
      "    \"434\": \"bath towel\",\n",
      "    \"435\": \"bathtub, bathing tub, bath, tub\",\n",
      "    \"436\": \"beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\",\n",
      "    \"437\": \"beacon, lighthouse, beacon light, pharos\",\n",
      "    \"438\": \"beaker\",\n",
      "    \"439\": \"bearskin, busby, shako\",\n",
      "    \"440\": \"beer bottle\",\n",
      "    \"441\": \"beer glass\",\n",
      "    \"442\": \"bell cote, bell cot\",\n",
      "    \"443\": \"bib\",\n",
      "    \"444\": \"bicycle-built-for-two, tandem bicycle, tandem\",\n",
      "    \"445\": \"bikini, two-piece\",\n",
      "    \"446\": \"binder, ring-binder\",\n",
      "    \"447\": \"binoculars, field glasses, opera glasses\",\n",
      "    \"448\": \"birdhouse\",\n",
      "    \"449\": \"boathouse\",\n",
      "    \"450\": \"bobsled, bobsleigh, bob\",\n",
      "    \"451\": \"bolo tie, bolo, bola tie, bola\",\n",
      "    \"452\": \"bonnet, poke bonnet\",\n",
      "    \"453\": \"bookcase\",\n",
      "    \"454\": \"bookshop, bookstore, bookstall\",\n",
      "    \"455\": \"bottlecap\",\n",
      "    \"456\": \"bow\",\n",
      "    \"457\": \"bow tie, bow-tie, bowtie\",\n",
      "    \"458\": \"brass, memorial tablet, plaque\",\n",
      "    \"459\": \"brassiere, bra, bandeau\",\n",
      "    \"460\": \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\",\n",
      "    \"461\": \"breastplate, aegis, egis\",\n",
      "    \"462\": \"broom\",\n",
      "    \"463\": \"bucket, pail\",\n",
      "    \"464\": \"buckle\",\n",
      "    \"465\": \"bulletproof vest\",\n",
      "    \"466\": \"bullet train, bullet\",\n",
      "    \"467\": \"butcher shop, meat market\",\n",
      "    \"468\": \"cab, hack, taxi, taxicab\",\n",
      "    \"469\": \"caldron, cauldron\",\n",
      "    \"470\": \"candle, taper, wax light\",\n",
      "    \"471\": \"cannon\",\n",
      "    \"472\": \"canoe\",\n",
      "    \"473\": \"can opener, tin opener\",\n",
      "    \"474\": \"cardigan\",\n",
      "    \"475\": \"car mirror\",\n",
      "    \"476\": \"carousel, carrousel, merry-go-round, roundabout, whirligig\",\n",
      "    \"477\": \"carpenter's kit, tool kit\",\n",
      "    \"478\": \"carton\",\n",
      "    \"479\": \"car wheel\",\n",
      "    \"480\": \"cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\",\n",
      "    \"481\": \"cassette\",\n",
      "    \"482\": \"cassette player\",\n",
      "    \"483\": \"castle\",\n",
      "    \"484\": \"catamaran\",\n",
      "    \"485\": \"CD player\",\n",
      "    \"486\": \"cello, violoncello\",\n",
      "    \"487\": \"cellular telephone, cellular phone, cellphone, cell, mobile phone\",\n",
      "    \"488\": \"chain\",\n",
      "    \"489\": \"chainlink fence\",\n",
      "    \"490\": \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour\",\n",
      "    \"491\": \"chain saw, chainsaw\",\n",
      "    \"492\": \"chest\",\n",
      "    \"493\": \"chiffonier, commode\",\n",
      "    \"494\": \"chime, bell, gong\",\n",
      "    \"495\": \"china cabinet, china closet\",\n",
      "    \"496\": \"Christmas stocking\",\n",
      "    \"497\": \"church, church building\",\n",
      "    \"498\": \"cinema, movie theater, movie theatre, movie house, picture palace\",\n",
      "    \"499\": \"cleaver, meat cleaver, chopper\",\n",
      "    \"500\": \"cliff dwelling\",\n",
      "    \"501\": \"cloak\",\n",
      "    \"502\": \"clog, geta, patten, sabot\",\n",
      "    \"503\": \"cocktail shaker\",\n",
      "    \"504\": \"coffee mug\",\n",
      "    \"505\": \"coffeepot\",\n",
      "    \"506\": \"coil, spiral, volute, whorl, helix\",\n",
      "    \"507\": \"combination lock\",\n",
      "    \"508\": \"computer keyboard, keypad\",\n",
      "    \"509\": \"confectionery, confectionary, candy store\",\n",
      "    \"510\": \"container ship, containership, container vessel\",\n",
      "    \"511\": \"convertible\",\n",
      "    \"512\": \"corkscrew, bottle screw\",\n",
      "    \"513\": \"cornet, horn, trumpet, trump\",\n",
      "    \"514\": \"cowboy boot\",\n",
      "    \"515\": \"cowboy hat, ten-gallon hat\",\n",
      "    \"516\": \"cradle\",\n",
      "    \"517\": \"crane\",\n",
      "    \"518\": \"crash helmet\",\n",
      "    \"519\": \"crate\",\n",
      "    \"520\": \"crib, cot\",\n",
      "    \"521\": \"Crock Pot\",\n",
      "    \"522\": \"croquet ball\",\n",
      "    \"523\": \"crutch\",\n",
      "    \"524\": \"cuirass\",\n",
      "    \"525\": \"dam, dike, dyke\",\n",
      "    \"526\": \"desk\",\n",
      "    \"527\": \"desktop computer\",\n",
      "    \"528\": \"dial telephone, dial phone\",\n",
      "    \"529\": \"diaper, nappy, napkin\",\n",
      "    \"530\": \"digital clock\",\n",
      "    \"531\": \"digital watch\",\n",
      "    \"532\": \"dining table, board\",\n",
      "    \"533\": \"dishrag, dishcloth\",\n",
      "    \"534\": \"dishwasher, dish washer, dishwashing machine\",\n",
      "    \"535\": \"disk brake, disc brake\",\n",
      "    \"536\": \"dock, dockage, docking facility\",\n",
      "    \"537\": \"dogsled, dog sled, dog sleigh\",\n",
      "    \"538\": \"dome\",\n",
      "    \"539\": \"doormat, welcome mat\",\n",
      "    \"540\": \"drilling platform, offshore rig\",\n",
      "    \"541\": \"drum, membranophone, tympan\",\n",
      "    \"542\": \"drumstick\",\n",
      "    \"543\": \"dumbbell\",\n",
      "    \"544\": \"Dutch oven\",\n",
      "    \"545\": \"electric fan, blower\",\n",
      "    \"546\": \"electric guitar\",\n",
      "    \"547\": \"electric locomotive\",\n",
      "    \"548\": \"entertainment center\",\n",
      "    \"549\": \"envelope\",\n",
      "    \"550\": \"espresso maker\",\n",
      "    \"551\": \"face powder\",\n",
      "    \"552\": \"feather boa, boa\",\n",
      "    \"553\": \"file, file cabinet, filing cabinet\",\n",
      "    \"554\": \"fireboat\",\n",
      "    \"555\": \"fire engine, fire truck\",\n",
      "    \"556\": \"fire screen, fireguard\",\n",
      "    \"557\": \"flagpole, flagstaff\",\n",
      "    \"558\": \"flute, transverse flute\",\n",
      "    \"559\": \"folding chair\",\n",
      "    \"560\": \"football helmet\",\n",
      "    \"561\": \"forklift\",\n",
      "    \"562\": \"fountain\",\n",
      "    \"563\": \"fountain pen\",\n",
      "    \"564\": \"four-poster\",\n",
      "    \"565\": \"freight car\",\n",
      "    \"566\": \"French horn, horn\",\n",
      "    \"567\": \"frying pan, frypan, skillet\",\n",
      "    \"568\": \"fur coat\",\n",
      "    \"569\": \"garbage truck, dustcart\",\n",
      "    \"570\": \"gasmask, respirator, gas helmet\",\n",
      "    \"571\": \"gas pump, gasoline pump, petrol pump, island dispenser\",\n",
      "    \"572\": \"goblet\",\n",
      "    \"573\": \"go-kart\",\n",
      "    \"574\": \"golf ball\",\n",
      "    \"575\": \"golfcart, golf cart\",\n",
      "    \"576\": \"gondola\",\n",
      "    \"577\": \"gong, tam-tam\",\n",
      "    \"578\": \"gown\",\n",
      "    \"579\": \"grand piano, grand\",\n",
      "    \"580\": \"greenhouse, nursery, glasshouse\",\n",
      "    \"581\": \"grille, radiator grille\",\n",
      "    \"582\": \"grocery store, grocery, food market, market\",\n",
      "    \"583\": \"guillotine\",\n",
      "    \"584\": \"hair slide\",\n",
      "    \"585\": \"hair spray\",\n",
      "    \"586\": \"half track\",\n",
      "    \"587\": \"hammer\",\n",
      "    \"588\": \"hamper\",\n",
      "    \"589\": \"hand blower, blow dryer, blow drier, hair dryer, hair drier\",\n",
      "    \"590\": \"hand-held computer, hand-held microcomputer\",\n",
      "    \"591\": \"handkerchief, hankie, hanky, hankey\",\n",
      "    \"592\": \"hard disc, hard disk, fixed disk\",\n",
      "    \"593\": \"harmonica, mouth organ, harp, mouth harp\",\n",
      "    \"594\": \"harp\",\n",
      "    \"595\": \"harvester, reaper\",\n",
      "    \"596\": \"hatchet\",\n",
      "    \"597\": \"holster\",\n",
      "    \"598\": \"home theater, home theatre\",\n",
      "    \"599\": \"honeycomb\",\n",
      "    \"600\": \"hook, claw\",\n",
      "    \"601\": \"hoopskirt, crinoline\",\n",
      "    \"602\": \"horizontal bar, high bar\",\n",
      "    \"603\": \"horse cart, horse-cart\",\n",
      "    \"604\": \"hourglass\",\n",
      "    \"605\": \"iPod\",\n",
      "    \"606\": \"iron, smoothing iron\",\n",
      "    \"607\": \"jack-o'-lantern\",\n",
      "    \"608\": \"jean, blue jean, denim\",\n",
      "    \"609\": \"jeep, landrover\",\n",
      "    \"610\": \"jersey, T-shirt, tee shirt\",\n",
      "    \"611\": \"jigsaw puzzle\",\n",
      "    \"612\": \"jinrikisha, ricksha, rickshaw\",\n",
      "    \"613\": \"joystick\",\n",
      "    \"614\": \"kimono\",\n",
      "    \"615\": \"knee pad\",\n",
      "    \"616\": \"knot\",\n",
      "    \"617\": \"lab coat, laboratory coat\",\n",
      "    \"618\": \"ladle\",\n",
      "    \"619\": \"lampshade, lamp shade\",\n",
      "    \"620\": \"laptop, laptop computer\",\n",
      "    \"621\": \"lawn mower, mower\",\n",
      "    \"622\": \"lens cap, lens cover\",\n",
      "    \"623\": \"letter opener, paper knife, paperknife\",\n",
      "    \"624\": \"library\",\n",
      "    \"625\": \"lifeboat\",\n",
      "    \"626\": \"lighter, light, igniter, ignitor\",\n",
      "    \"627\": \"limousine, limo\",\n",
      "    \"628\": \"liner, ocean liner\",\n",
      "    \"629\": \"lipstick, lip rouge\",\n",
      "    \"630\": \"Loafer\",\n",
      "    \"631\": \"lotion\",\n",
      "    \"632\": \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\",\n",
      "    \"633\": \"loupe, jeweler's loupe\",\n",
      "    \"634\": \"lumbermill, sawmill\",\n",
      "    \"635\": \"magnetic compass\",\n",
      "    \"636\": \"mailbag, postbag\",\n",
      "    \"637\": \"mailbox, letter box\",\n",
      "    \"638\": \"maillot\",\n",
      "    \"639\": \"maillot, tank suit\",\n",
      "    \"640\": \"manhole cover\",\n",
      "    \"641\": \"maraca\",\n",
      "    \"642\": \"marimba, xylophone\",\n",
      "    \"643\": \"mask\",\n",
      "    \"644\": \"matchstick\",\n",
      "    \"645\": \"maypole\",\n",
      "    \"646\": \"maze, labyrinth\",\n",
      "    \"647\": \"measuring cup\",\n",
      "    \"648\": \"medicine chest, medicine cabinet\",\n",
      "    \"649\": \"megalith, megalithic structure\",\n",
      "    \"650\": \"microphone, mike\",\n",
      "    \"651\": \"microwave, microwave oven\",\n",
      "    \"652\": \"military uniform\",\n",
      "    \"653\": \"milk can\",\n",
      "    \"654\": \"minibus\",\n",
      "    \"655\": \"miniskirt, mini\",\n",
      "    \"656\": \"minivan\",\n",
      "    \"657\": \"missile\",\n",
      "    \"658\": \"mitten\",\n",
      "    \"659\": \"mixing bowl\",\n",
      "    \"660\": \"mobile home, manufactured home\",\n",
      "    \"661\": \"Model T\",\n",
      "    \"662\": \"modem\",\n",
      "    \"663\": \"monastery\",\n",
      "    \"664\": \"monitor\",\n",
      "    \"665\": \"moped\",\n",
      "    \"666\": \"mortar\",\n",
      "    \"667\": \"mortarboard\",\n",
      "    \"668\": \"mosque\",\n",
      "    \"669\": \"mosquito net\",\n",
      "    \"670\": \"motor scooter, scooter\",\n",
      "    \"671\": \"mountain bike, all-terrain bike, off-roader\",\n",
      "    \"672\": \"mountain tent\",\n",
      "    \"673\": \"mouse, computer mouse\",\n",
      "    \"674\": \"mousetrap\",\n",
      "    \"675\": \"moving van\",\n",
      "    \"676\": \"muzzle\",\n",
      "    \"677\": \"nail\",\n",
      "    \"678\": \"neck brace\",\n",
      "    \"679\": \"necklace\",\n",
      "    \"680\": \"nipple\",\n",
      "    \"681\": \"notebook, notebook computer\",\n",
      "    \"682\": \"obelisk\",\n",
      "    \"683\": \"oboe, hautboy, hautbois\",\n",
      "    \"684\": \"ocarina, sweet potato\",\n",
      "    \"685\": \"odometer, hodometer, mileometer, milometer\",\n",
      "    \"686\": \"oil filter\",\n",
      "    \"687\": \"organ, pipe organ\",\n",
      "    \"688\": \"oscilloscope, scope, cathode-ray oscilloscope, CRO\",\n",
      "    \"689\": \"overskirt\",\n",
      "    \"690\": \"oxcart\",\n",
      "    \"691\": \"oxygen mask\",\n",
      "    \"692\": \"packet\",\n",
      "    \"693\": \"paddle, boat paddle\",\n",
      "    \"694\": \"paddlewheel, paddle wheel\",\n",
      "    \"695\": \"padlock\",\n",
      "    \"696\": \"paintbrush\",\n",
      "    \"697\": \"pajama, pyjama, pj's, jammies\",\n",
      "    \"698\": \"palace\",\n",
      "    \"699\": \"panpipe, pandean pipe, syrinx\",\n",
      "    \"700\": \"paper towel\",\n",
      "    \"701\": \"parachute, chute\",\n",
      "    \"702\": \"parallel bars, bars\",\n",
      "    \"703\": \"park bench\",\n",
      "    \"704\": \"parking meter\",\n",
      "    \"705\": \"passenger car, coach, carriage\",\n",
      "    \"706\": \"patio, terrace\",\n",
      "    \"707\": \"pay-phone, pay-station\",\n",
      "    \"708\": \"pedestal, plinth, footstall\",\n",
      "    \"709\": \"pencil box, pencil case\",\n",
      "    \"710\": \"pencil sharpener\",\n",
      "    \"711\": \"perfume, essence\",\n",
      "    \"712\": \"Petri dish\",\n",
      "    \"713\": \"photocopier\",\n",
      "    \"714\": \"pick, plectrum, plectron\",\n",
      "    \"715\": \"pickelhaube\",\n",
      "    \"716\": \"picket fence, paling\",\n",
      "    \"717\": \"pickup, pickup truck\",\n",
      "    \"718\": \"pier\",\n",
      "    \"719\": \"piggy bank, penny bank\",\n",
      "    \"720\": \"pill bottle\",\n",
      "    \"721\": \"pillow\",\n",
      "    \"722\": \"ping-pong ball\",\n",
      "    \"723\": \"pinwheel\",\n",
      "    \"724\": \"pirate, pirate ship\",\n",
      "    \"725\": \"pitcher, ewer\",\n",
      "    \"726\": \"plane, carpenter's plane, woodworking plane\",\n",
      "    \"727\": \"planetarium\",\n",
      "    \"728\": \"plastic bag\",\n",
      "    \"729\": \"plate rack\",\n",
      "    \"730\": \"plow, plough\",\n",
      "    \"731\": \"plunger, plumber's helper\",\n",
      "    \"732\": \"Polaroid camera, Polaroid Land camera\",\n",
      "    \"733\": \"pole\",\n",
      "    \"734\": \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\",\n",
      "    \"735\": \"poncho\",\n",
      "    \"736\": \"pool table, billiard table, snooker table\",\n",
      "    \"737\": \"pop bottle, soda bottle\",\n",
      "    \"738\": \"pot, flowerpot\",\n",
      "    \"739\": \"potter's wheel\",\n",
      "    \"740\": \"power drill\",\n",
      "    \"741\": \"prayer rug, prayer mat\",\n",
      "    \"742\": \"printer\",\n",
      "    \"743\": \"prison, prison house\",\n",
      "    \"744\": \"projectile, missile\",\n",
      "    \"745\": \"projector\",\n",
      "    \"746\": \"puck, hockey puck\",\n",
      "    \"747\": \"punching bag, punch bag, punching ball, punchball\",\n",
      "    \"748\": \"purse\",\n",
      "    \"749\": \"quill, quill pen\",\n",
      "    \"750\": \"quilt, comforter, comfort, puff\",\n",
      "    \"751\": \"racer, race car, racing car\",\n",
      "    \"752\": \"racket, racquet\",\n",
      "    \"753\": \"radiator\",\n",
      "    \"754\": \"radio, wireless\",\n",
      "    \"755\": \"radio telescope, radio reflector\",\n",
      "    \"756\": \"rain barrel\",\n",
      "    \"757\": \"recreational vehicle, RV, R.V.\",\n",
      "    \"758\": \"reel\",\n",
      "    \"759\": \"reflex camera\",\n",
      "    \"760\": \"refrigerator, icebox\",\n",
      "    \"761\": \"remote control, remote\",\n",
      "    \"762\": \"restaurant, eating house, eating place, eatery\",\n",
      "    \"763\": \"revolver, six-gun, six-shooter\",\n",
      "    \"764\": \"rifle\",\n",
      "    \"765\": \"rocking chair, rocker\",\n",
      "    \"766\": \"rotisserie\",\n",
      "    \"767\": \"rubber eraser, rubber, pencil eraser\",\n",
      "    \"768\": \"rugby ball\",\n",
      "    \"769\": \"rule, ruler\",\n",
      "    \"770\": \"running shoe\",\n",
      "    \"771\": \"safe\",\n",
      "    \"772\": \"safety pin\",\n",
      "    \"773\": \"saltshaker, salt shaker\",\n",
      "    \"774\": \"sandal\",\n",
      "    \"775\": \"sarong\",\n",
      "    \"776\": \"sax, saxophone\",\n",
      "    \"777\": \"scabbard\",\n",
      "    \"778\": \"scale, weighing machine\",\n",
      "    \"779\": \"school bus\",\n",
      "    \"780\": \"schooner\",\n",
      "    \"781\": \"scoreboard\",\n",
      "    \"782\": \"screen, CRT screen\",\n",
      "    \"783\": \"screw\",\n",
      "    \"784\": \"screwdriver\",\n",
      "    \"785\": \"seat belt, seatbelt\",\n",
      "    \"786\": \"sewing machine\",\n",
      "    \"787\": \"shield, buckler\",\n",
      "    \"788\": \"shoe shop, shoe-shop, shoe store\",\n",
      "    \"789\": \"shoji\",\n",
      "    \"790\": \"shopping basket\",\n",
      "    \"791\": \"shopping cart\",\n",
      "    \"792\": \"shovel\",\n",
      "    \"793\": \"shower cap\",\n",
      "    \"794\": \"shower curtain\",\n",
      "    \"795\": \"ski\",\n",
      "    \"796\": \"ski mask\",\n",
      "    \"797\": \"sleeping bag\",\n",
      "    \"798\": \"slide rule, slipstick\",\n",
      "    \"799\": \"sliding door\",\n",
      "    \"800\": \"slot, one-armed bandit\",\n",
      "    \"801\": \"snorkel\",\n",
      "    \"802\": \"snowmobile\",\n",
      "    \"803\": \"snowplow, snowplough\",\n",
      "    \"804\": \"soap dispenser\",\n",
      "    \"805\": \"soccer ball\",\n",
      "    \"806\": \"sock\",\n",
      "    \"807\": \"solar dish, solar collector, solar furnace\",\n",
      "    \"808\": \"sombrero\",\n",
      "    \"809\": \"soup bowl\",\n",
      "    \"810\": \"space bar\",\n",
      "    \"811\": \"space heater\",\n",
      "    \"812\": \"space shuttle\",\n",
      "    \"813\": \"spatula\",\n",
      "    \"814\": \"speedboat\",\n",
      "    \"815\": \"spider web, spider's web\",\n",
      "    \"816\": \"spindle\",\n",
      "    \"817\": \"sports car, sport car\",\n",
      "    \"818\": \"spotlight, spot\",\n",
      "    \"819\": \"stage\",\n",
      "    \"820\": \"steam locomotive\",\n",
      "    \"821\": \"steel arch bridge\",\n",
      "    \"822\": \"steel drum\",\n",
      "    \"823\": \"stethoscope\",\n",
      "    \"824\": \"stole\",\n",
      "    \"825\": \"stone wall\",\n",
      "    \"826\": \"stopwatch, stop watch\",\n",
      "    \"827\": \"stove\",\n",
      "    \"828\": \"strainer\",\n",
      "    \"829\": \"streetcar, tram, tramcar, trolley, trolley car\",\n",
      "    \"830\": \"stretcher\",\n",
      "    \"831\": \"studio couch, day bed\",\n",
      "    \"832\": \"stupa, tope\",\n",
      "    \"833\": \"submarine, pigboat, sub, U-boat\",\n",
      "    \"834\": \"suit, suit of clothes\",\n",
      "    \"835\": \"sundial\",\n",
      "    \"836\": \"sunglass\",\n",
      "    \"837\": \"sunglasses, dark glasses, shades\",\n",
      "    \"838\": \"sunscreen, sunblock, sun blocker\",\n",
      "    \"839\": \"suspension bridge\",\n",
      "    \"840\": \"swab, swob, mop\",\n",
      "    \"841\": \"sweatshirt\",\n",
      "    \"842\": \"swimming trunks, bathing trunks\",\n",
      "    \"843\": \"swing\",\n",
      "    \"844\": \"switch, electric switch, electrical switch\",\n",
      "    \"845\": \"syringe\",\n",
      "    \"846\": \"table lamp\",\n",
      "    \"847\": \"tank, army tank, armored combat vehicle, armoured combat vehicle\",\n",
      "    \"848\": \"tape player\",\n",
      "    \"849\": \"teapot\",\n",
      "    \"850\": \"teddy, teddy bear\",\n",
      "    \"851\": \"television, television system\",\n",
      "    \"852\": \"tennis ball\",\n",
      "    \"853\": \"thatch, thatched roof\",\n",
      "    \"854\": \"theater curtain, theatre curtain\",\n",
      "    \"855\": \"thimble\",\n",
      "    \"856\": \"thresher, thrasher, threshing machine\",\n",
      "    \"857\": \"throne\",\n",
      "    \"858\": \"tile roof\",\n",
      "    \"859\": \"toaster\",\n",
      "    \"860\": \"tobacco shop, tobacconist shop, tobacconist\",\n",
      "    \"861\": \"toilet seat\",\n",
      "    \"862\": \"torch\",\n",
      "    \"863\": \"totem pole\",\n",
      "    \"864\": \"tow truck, tow car, wrecker\",\n",
      "    \"865\": \"toyshop\",\n",
      "    \"866\": \"tractor\",\n",
      "    \"867\": \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\",\n",
      "    \"868\": \"tray\",\n",
      "    \"869\": \"trench coat\",\n",
      "    \"870\": \"tricycle, trike, velocipede\",\n",
      "    \"871\": \"trimaran\",\n",
      "    \"872\": \"tripod\",\n",
      "    \"873\": \"triumphal arch\",\n",
      "    \"874\": \"trolleybus, trolley coach, trackless trolley\",\n",
      "    \"875\": \"trombone\",\n",
      "    \"876\": \"tub, vat\",\n",
      "    \"877\": \"turnstile\",\n",
      "    \"878\": \"typewriter keyboard\",\n",
      "    \"879\": \"umbrella\",\n",
      "    \"880\": \"unicycle, monocycle\",\n",
      "    \"881\": \"upright, upright piano\",\n",
      "    \"882\": \"vacuum, vacuum cleaner\",\n",
      "    \"883\": \"vase\",\n",
      "    \"884\": \"vault\",\n",
      "    \"885\": \"velvet\",\n",
      "    \"886\": \"vending machine\",\n",
      "    \"887\": \"vestment\",\n",
      "    \"888\": \"viaduct\",\n",
      "    \"889\": \"violin, fiddle\",\n",
      "    \"890\": \"volleyball\",\n",
      "    \"891\": \"waffle iron\",\n",
      "    \"892\": \"wall clock\",\n",
      "    \"893\": \"wallet, billfold, notecase, pocketbook\",\n",
      "    \"894\": \"wardrobe, closet, press\",\n",
      "    \"895\": \"warplane, military plane\",\n",
      "    \"896\": \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\",\n",
      "    \"897\": \"washer, automatic washer, washing machine\",\n",
      "    \"898\": \"water bottle\",\n",
      "    \"899\": \"water jug\",\n",
      "    \"900\": \"water tower\",\n",
      "    \"901\": \"whiskey jug\",\n",
      "    \"902\": \"whistle\",\n",
      "    \"903\": \"wig\",\n",
      "    \"904\": \"window screen\",\n",
      "    \"905\": \"window shade\",\n",
      "    \"906\": \"Windsor tie\",\n",
      "    \"907\": \"wine bottle\",\n",
      "    \"908\": \"wing\",\n",
      "    \"909\": \"wok\",\n",
      "    \"910\": \"wooden spoon\",\n",
      "    \"911\": \"wool, woolen, woollen\",\n",
      "    \"912\": \"worm fence, snake fence, snake-rail fence, Virginia fence\",\n",
      "    \"913\": \"wreck\",\n",
      "    \"914\": \"yawl\",\n",
      "    \"915\": \"yurt\",\n",
      "    \"916\": \"web site, website, internet site, site\",\n",
      "    \"917\": \"comic book\",\n",
      "    \"918\": \"crossword puzzle, crossword\",\n",
      "    \"919\": \"street sign\",\n",
      "    \"920\": \"traffic light, traffic signal, stoplight\",\n",
      "    \"921\": \"book jacket, dust cover, dust jacket, dust wrapper\",\n",
      "    \"922\": \"menu\",\n",
      "    \"923\": \"plate\",\n",
      "    \"924\": \"guacamole\",\n",
      "    \"925\": \"consomme\",\n",
      "    \"926\": \"hot pot, hotpot\",\n",
      "    \"927\": \"trifle\",\n",
      "    \"928\": \"ice cream, icecream\",\n",
      "    \"929\": \"ice lolly, lolly, lollipop, popsicle\",\n",
      "    \"930\": \"French loaf\",\n",
      "    \"931\": \"bagel, beigel\",\n",
      "    \"932\": \"pretzel\",\n",
      "    \"933\": \"cheeseburger\",\n",
      "    \"934\": \"hotdog, hot dog, red hot\",\n",
      "    \"935\": \"mashed potato\",\n",
      "    \"936\": \"head cabbage\",\n",
      "    \"937\": \"broccoli\",\n",
      "    \"938\": \"cauliflower\",\n",
      "    \"939\": \"zucchini, courgette\",\n",
      "    \"940\": \"spaghetti squash\",\n",
      "    \"941\": \"acorn squash\",\n",
      "    \"942\": \"butternut squash\",\n",
      "    \"943\": \"cucumber, cuke\",\n",
      "    \"944\": \"artichoke, globe artichoke\",\n",
      "    \"945\": \"bell pepper\",\n",
      "    \"946\": \"cardoon\",\n",
      "    \"947\": \"mushroom\",\n",
      "    \"948\": \"Granny Smith\",\n",
      "    \"949\": \"strawberry\",\n",
      "    \"950\": \"orange\",\n",
      "    \"951\": \"lemon\",\n",
      "    \"952\": \"fig\",\n",
      "    \"953\": \"pineapple, ananas\",\n",
      "    \"954\": \"banana\",\n",
      "    \"955\": \"jackfruit, jak, jack\",\n",
      "    \"956\": \"custard apple\",\n",
      "    \"957\": \"pomegranate\",\n",
      "    \"958\": \"hay\",\n",
      "    \"959\": \"carbonara\",\n",
      "    \"960\": \"chocolate sauce, chocolate syrup\",\n",
      "    \"961\": \"dough\",\n",
      "    \"962\": \"meat loaf, meatloaf\",\n",
      "    \"963\": \"pizza, pizza pie\",\n",
      "    \"964\": \"potpie\",\n",
      "    \"965\": \"burrito\",\n",
      "    \"966\": \"red wine\",\n",
      "    \"967\": \"espresso\",\n",
      "    \"968\": \"cup\",\n",
      "    \"969\": \"eggnog\",\n",
      "    \"970\": \"alp\",\n",
      "    \"971\": \"bubble\",\n",
      "    \"972\": \"cliff, drop, drop-off\",\n",
      "    \"973\": \"coral reef\",\n",
      "    \"974\": \"geyser\",\n",
      "    \"975\": \"lakeside, lakeshore\",\n",
      "    \"976\": \"promontory, headland, head, foreland\",\n",
      "    \"977\": \"sandbar, sand bar\",\n",
      "    \"978\": \"seashore, coast, seacoast, sea-coast\",\n",
      "    \"979\": \"valley, vale\",\n",
      "    \"980\": \"volcano\",\n",
      "    \"981\": \"ballplayer, baseball player\",\n",
      "    \"982\": \"groom, bridegroom\",\n",
      "    \"983\": \"scuba diver\",\n",
      "    \"984\": \"rapeseed\",\n",
      "    \"985\": \"daisy\",\n",
      "    \"986\": \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\",\n",
      "    \"987\": \"corn\",\n",
      "    \"988\": \"acorn\",\n",
      "    \"989\": \"hip, rose hip, rosehip\",\n",
      "    \"990\": \"buckeye, horse chestnut, conker\",\n",
      "    \"991\": \"coral fungus\",\n",
      "    \"992\": \"agaric\",\n",
      "    \"993\": \"gyromitra\",\n",
      "    \"994\": \"stinkhorn, carrion fungus\",\n",
      "    \"995\": \"earthstar\",\n",
      "    \"996\": \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\",\n",
      "    \"997\": \"bolete\",\n",
      "    \"998\": \"ear, spike, capitulum\",\n",
      "    \"999\": \"toilet tissue, toilet paper, bathroom tissue\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Afghan hound, Afghan\": 160,\n",
      "    \"African chameleon, Chamaeleo chamaeleon\": 47,\n",
      "    \"African crocodile, Nile crocodile, Crocodylus niloticus\": 49,\n",
      "    \"African elephant, Loxodonta africana\": 386,\n",
      "    \"African grey, African gray, Psittacus erithacus\": 87,\n",
      "    \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\": 275,\n",
      "    \"Airedale, Airedale terrier\": 191,\n",
      "    \"American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier\": 180,\n",
      "    \"American alligator, Alligator mississipiensis\": 50,\n",
      "    \"American black bear, black bear, Ursus americanus, Euarctos americanus\": 295,\n",
      "    \"American chameleon, anole, Anolis carolinensis\": 40,\n",
      "    \"American coot, marsh hen, mud hen, water hen, Fulica americana\": 137,\n",
      "    \"American egret, great white heron, Egretta albus\": 132,\n",
      "    \"American lobster, Northern lobster, Maine lobster, Homarus americanus\": 122,\n",
      "    \"Angora, Angora rabbit\": 332,\n",
      "    \"Appenzeller\": 240,\n",
      "    \"Arabian camel, dromedary, Camelus dromedarius\": 354,\n",
      "    \"Arctic fox, white fox, Alopex lagopus\": 279,\n",
      "    \"Australian terrier\": 193,\n",
      "    \"Band Aid\": 419,\n",
      "    \"Bedlington terrier\": 181,\n",
      "    \"Bernese mountain dog\": 239,\n",
      "    \"Blenheim spaniel\": 156,\n",
      "    \"Border collie\": 232,\n",
      "    \"Border terrier\": 182,\n",
      "    \"Boston bull, Boston terrier\": 195,\n",
      "    \"Bouvier des Flandres, Bouviers des Flandres\": 233,\n",
      "    \"Brabancon griffon\": 262,\n",
      "    \"Brittany spaniel\": 215,\n",
      "    \"CD player\": 485,\n",
      "    \"Cardigan, Cardigan Welsh corgi\": 264,\n",
      "    \"Chesapeake Bay retriever\": 209,\n",
      "    \"Chihuahua\": 151,\n",
      "    \"Christmas stocking\": 496,\n",
      "    \"Crock Pot\": 521,\n",
      "    \"Dandie Dinmont, Dandie Dinmont terrier\": 194,\n",
      "    \"Doberman, Doberman pinscher\": 236,\n",
      "    \"Dungeness crab, Cancer magister\": 118,\n",
      "    \"Dutch oven\": 544,\n",
      "    \"Egyptian cat\": 285,\n",
      "    \"English foxhound\": 167,\n",
      "    \"English setter\": 212,\n",
      "    \"English springer, English springer spaniel\": 217,\n",
      "    \"EntleBucher\": 241,\n",
      "    \"Eskimo dog, husky\": 248,\n",
      "    \"European fire salamander, Salamandra salamandra\": 25,\n",
      "    \"European gallinule, Porphyrio porphyrio\": 136,\n",
      "    \"French bulldog\": 245,\n",
      "    \"French horn, horn\": 566,\n",
      "    \"French loaf\": 930,\n",
      "    \"German shepherd, German shepherd dog, German police dog, alsatian\": 235,\n",
      "    \"German short-haired pointer\": 210,\n",
      "    \"Gila monster, Heloderma suspectum\": 45,\n",
      "    \"Gordon setter\": 214,\n",
      "    \"Granny Smith\": 948,\n",
      "    \"Great Dane\": 246,\n",
      "    \"Great Pyrenees\": 257,\n",
      "    \"Greater Swiss Mountain dog\": 238,\n",
      "    \"Ibizan hound, Ibizan Podenco\": 173,\n",
      "    \"Indian cobra, Naja naja\": 63,\n",
      "    \"Indian elephant, Elephas maximus\": 385,\n",
      "    \"Irish setter, red setter\": 213,\n",
      "    \"Irish terrier\": 184,\n",
      "    \"Irish water spaniel\": 221,\n",
      "    \"Irish wolfhound\": 170,\n",
      "    \"Italian greyhound\": 171,\n",
      "    \"Japanese spaniel\": 152,\n",
      "    \"Kerry blue terrier\": 183,\n",
      "    \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis\": 48,\n",
      "    \"Labrador retriever\": 208,\n",
      "    \"Lakeland terrier\": 189,\n",
      "    \"Leonberg\": 255,\n",
      "    \"Lhasa, Lhasa apso\": 204,\n",
      "    \"Loafer\": 630,\n",
      "    \"Madagascar cat, ring-tailed lemur, Lemur catta\": 383,\n",
      "    \"Maltese dog, Maltese terrier, Maltese\": 153,\n",
      "    \"Mexican hairless\": 268,\n",
      "    \"Model T\": 661,\n",
      "    \"Newfoundland, Newfoundland dog\": 256,\n",
      "    \"Norfolk terrier\": 185,\n",
      "    \"Norwegian elkhound, elkhound\": 174,\n",
      "    \"Norwich terrier\": 186,\n",
      "    \"Old English sheepdog, bobtail\": 229,\n",
      "    \"Pekinese, Pekingese, Peke\": 154,\n",
      "    \"Pembroke, Pembroke Welsh corgi\": 263,\n",
      "    \"Persian cat\": 283,\n",
      "    \"Petri dish\": 712,\n",
      "    \"Polaroid camera, Polaroid Land camera\": 732,\n",
      "    \"Pomeranian\": 259,\n",
      "    \"Rhodesian ridgeback\": 159,\n",
      "    \"Rottweiler\": 234,\n",
      "    \"Saint Bernard, St Bernard\": 247,\n",
      "    \"Saluki, gazelle hound\": 176,\n",
      "    \"Samoyed, Samoyede\": 258,\n",
      "    \"Scotch terrier, Scottish terrier, Scottie\": 199,\n",
      "    \"Scottish deerhound, deerhound\": 177,\n",
      "    \"Sealyham terrier, Sealyham\": 190,\n",
      "    \"Shetland sheepdog, Shetland sheep dog, Shetland\": 230,\n",
      "    \"Shih-Tzu\": 155,\n",
      "    \"Siamese cat, Siamese\": 284,\n",
      "    \"Siberian husky\": 250,\n",
      "    \"Staffordshire bullterrier, Staffordshire bull terrier\": 179,\n",
      "    \"Sussex spaniel\": 220,\n",
      "    \"Tibetan mastiff\": 244,\n",
      "    \"Tibetan terrier, chrysanthemum dog\": 200,\n",
      "    \"Walker hound, Walker foxhound\": 166,\n",
      "    \"Weimaraner\": 178,\n",
      "    \"Welsh springer spaniel\": 218,\n",
      "    \"West Highland white terrier\": 203,\n",
      "    \"Windsor tie\": 906,\n",
      "    \"Yorkshire terrier\": 187,\n",
      "    \"abacus\": 398,\n",
      "    \"abaya\": 399,\n",
      "    \"academic gown, academic robe, judge's robe\": 400,\n",
      "    \"accordion, piano accordion, squeeze box\": 401,\n",
      "    \"acorn\": 988,\n",
      "    \"acorn squash\": 941,\n",
      "    \"acoustic guitar\": 402,\n",
      "    \"admiral\": 321,\n",
      "    \"affenpinscher, monkey pinscher, monkey dog\": 252,\n",
      "    \"agama\": 42,\n",
      "    \"agaric\": 992,\n",
      "    \"aircraft carrier, carrier, flattop, attack aircraft carrier\": 403,\n",
      "    \"airliner\": 404,\n",
      "    \"airship, dirigible\": 405,\n",
      "    \"albatross, mollymawk\": 146,\n",
      "    \"alligator lizard\": 44,\n",
      "    \"alp\": 970,\n",
      "    \"altar\": 406,\n",
      "    \"ambulance\": 407,\n",
      "    \"amphibian, amphibious vehicle\": 408,\n",
      "    \"analog clock\": 409,\n",
      "    \"anemone fish\": 393,\n",
      "    \"ant, emmet, pismire\": 310,\n",
      "    \"apiary, bee house\": 410,\n",
      "    \"apron\": 411,\n",
      "    \"armadillo\": 363,\n",
      "    \"artichoke, globe artichoke\": 944,\n",
      "    \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin\": 412,\n",
      "    \"assault rifle, assault gun\": 413,\n",
      "    \"axolotl, mud puppy, Ambystoma mexicanum\": 29,\n",
      "    \"baboon\": 372,\n",
      "    \"backpack, back pack, knapsack, packsack, rucksack, haversack\": 414,\n",
      "    \"badger\": 362,\n",
      "    \"bagel, beigel\": 931,\n",
      "    \"bakery, bakeshop, bakehouse\": 415,\n",
      "    \"balance beam, beam\": 416,\n",
      "    \"bald eagle, American eagle, Haliaeetus leucocephalus\": 22,\n",
      "    \"balloon\": 417,\n",
      "    \"ballplayer, baseball player\": 981,\n",
      "    \"ballpoint, ballpoint pen, ballpen, Biro\": 418,\n",
      "    \"banana\": 954,\n",
      "    \"banded gecko\": 38,\n",
      "    \"banjo\": 420,\n",
      "    \"bannister, banister, balustrade, balusters, handrail\": 421,\n",
      "    \"barbell\": 422,\n",
      "    \"barber chair\": 423,\n",
      "    \"barbershop\": 424,\n",
      "    \"barn\": 425,\n",
      "    \"barn spider, Araneus cavaticus\": 73,\n",
      "    \"barometer\": 426,\n",
      "    \"barracouta, snoek\": 389,\n",
      "    \"barrel, cask\": 427,\n",
      "    \"barrow, garden cart, lawn cart, wheelbarrow\": 428,\n",
      "    \"baseball\": 429,\n",
      "    \"basenji\": 253,\n",
      "    \"basketball\": 430,\n",
      "    \"basset, basset hound\": 161,\n",
      "    \"bassinet\": 431,\n",
      "    \"bassoon\": 432,\n",
      "    \"bath towel\": 434,\n",
      "    \"bathing cap, swimming cap\": 433,\n",
      "    \"bathtub, bathing tub, bath, tub\": 435,\n",
      "    \"beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\": 436,\n",
      "    \"beacon, lighthouse, beacon light, pharos\": 437,\n",
      "    \"beagle\": 162,\n",
      "    \"beaker\": 438,\n",
      "    \"bearskin, busby, shako\": 439,\n",
      "    \"beaver\": 337,\n",
      "    \"bee\": 309,\n",
      "    \"bee eater\": 92,\n",
      "    \"beer bottle\": 440,\n",
      "    \"beer glass\": 441,\n",
      "    \"bell cote, bell cot\": 442,\n",
      "    \"bell pepper\": 945,\n",
      "    \"bib\": 443,\n",
      "    \"bicycle-built-for-two, tandem bicycle, tandem\": 444,\n",
      "    \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\": 349,\n",
      "    \"bikini, two-piece\": 445,\n",
      "    \"binder, ring-binder\": 446,\n",
      "    \"binoculars, field glasses, opera glasses\": 447,\n",
      "    \"birdhouse\": 448,\n",
      "    \"bison\": 347,\n",
      "    \"bittern\": 133,\n",
      "    \"black and gold garden spider, Argiope aurantia\": 72,\n",
      "    \"black grouse\": 80,\n",
      "    \"black stork, Ciconia nigra\": 128,\n",
      "    \"black swan, Cygnus atratus\": 100,\n",
      "    \"black widow, Latrodectus mactans\": 75,\n",
      "    \"black-and-tan coonhound\": 165,\n",
      "    \"black-footed ferret, ferret, Mustela nigripes\": 359,\n",
      "    \"bloodhound, sleuthhound\": 163,\n",
      "    \"bluetick\": 164,\n",
      "    \"boa constrictor, Constrictor constrictor\": 61,\n",
      "    \"boathouse\": 449,\n",
      "    \"bobsled, bobsleigh, bob\": 450,\n",
      "    \"bolete\": 997,\n",
      "    \"bolo tie, bolo, bola tie, bola\": 451,\n",
      "    \"bonnet, poke bonnet\": 452,\n",
      "    \"book jacket, dust cover, dust jacket, dust wrapper\": 921,\n",
      "    \"bookcase\": 453,\n",
      "    \"bookshop, bookstore, bookstall\": 454,\n",
      "    \"borzoi, Russian wolfhound\": 169,\n",
      "    \"bottlecap\": 455,\n",
      "    \"bow\": 456,\n",
      "    \"bow tie, bow-tie, bowtie\": 457,\n",
      "    \"box turtle, box tortoise\": 37,\n",
      "    \"boxer\": 242,\n",
      "    \"brain coral\": 109,\n",
      "    \"brambling, Fringilla montifringilla\": 10,\n",
      "    \"brass, memorial tablet, plaque\": 458,\n",
      "    \"brassiere, bra, bandeau\": 459,\n",
      "    \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\": 460,\n",
      "    \"breastplate, aegis, egis\": 461,\n",
      "    \"briard\": 226,\n",
      "    \"broccoli\": 937,\n",
      "    \"broom\": 462,\n",
      "    \"brown bear, bruin, Ursus arctos\": 294,\n",
      "    \"bubble\": 971,\n",
      "    \"bucket, pail\": 463,\n",
      "    \"buckeye, horse chestnut, conker\": 990,\n",
      "    \"buckle\": 464,\n",
      "    \"bulbul\": 16,\n",
      "    \"bull mastiff\": 243,\n",
      "    \"bullet train, bullet\": 466,\n",
      "    \"bulletproof vest\": 465,\n",
      "    \"bullfrog, Rana catesbeiana\": 30,\n",
      "    \"burrito\": 965,\n",
      "    \"bustard\": 138,\n",
      "    \"butcher shop, meat market\": 467,\n",
      "    \"butternut squash\": 942,\n",
      "    \"cab, hack, taxi, taxicab\": 468,\n",
      "    \"cabbage butterfly\": 324,\n",
      "    \"cairn, cairn terrier\": 192,\n",
      "    \"caldron, cauldron\": 469,\n",
      "    \"can opener, tin opener\": 473,\n",
      "    \"candle, taper, wax light\": 470,\n",
      "    \"cannon\": 471,\n",
      "    \"canoe\": 472,\n",
      "    \"capuchin, ringtail, Cebus capucinus\": 378,\n",
      "    \"car mirror\": 475,\n",
      "    \"car wheel\": 479,\n",
      "    \"carbonara\": 959,\n",
      "    \"cardigan\": 474,\n",
      "    \"cardoon\": 946,\n",
      "    \"carousel, carrousel, merry-go-round, roundabout, whirligig\": 476,\n",
      "    \"carpenter's kit, tool kit\": 477,\n",
      "    \"carton\": 478,\n",
      "    \"cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\": 480,\n",
      "    \"cassette\": 481,\n",
      "    \"cassette player\": 482,\n",
      "    \"castle\": 483,\n",
      "    \"catamaran\": 484,\n",
      "    \"cauliflower\": 938,\n",
      "    \"cello, violoncello\": 486,\n",
      "    \"cellular telephone, cellular phone, cellphone, cell, mobile phone\": 487,\n",
      "    \"centipede\": 79,\n",
      "    \"chain\": 488,\n",
      "    \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour\": 490,\n",
      "    \"chain saw, chainsaw\": 491,\n",
      "    \"chainlink fence\": 489,\n",
      "    \"chambered nautilus, pearly nautilus, nautilus\": 117,\n",
      "    \"cheeseburger\": 933,\n",
      "    \"cheetah, chetah, Acinonyx jubatus\": 293,\n",
      "    \"chest\": 492,\n",
      "    \"chickadee\": 19,\n",
      "    \"chiffonier, commode\": 493,\n",
      "    \"chime, bell, gong\": 494,\n",
      "    \"chimpanzee, chimp, Pan troglodytes\": 367,\n",
      "    \"china cabinet, china closet\": 495,\n",
      "    \"chiton, coat-of-mail shell, sea cradle, polyplacophore\": 116,\n",
      "    \"chocolate sauce, chocolate syrup\": 960,\n",
      "    \"chow, chow chow\": 260,\n",
      "    \"church, church building\": 497,\n",
      "    \"cicada, cicala\": 316,\n",
      "    \"cinema, movie theater, movie theatre, movie house, picture palace\": 498,\n",
      "    \"cleaver, meat cleaver, chopper\": 499,\n",
      "    \"cliff dwelling\": 500,\n",
      "    \"cliff, drop, drop-off\": 972,\n",
      "    \"cloak\": 501,\n",
      "    \"clog, geta, patten, sabot\": 502,\n",
      "    \"clumber, clumber spaniel\": 216,\n",
      "    \"cock\": 7,\n",
      "    \"cocker spaniel, English cocker spaniel, cocker\": 219,\n",
      "    \"cockroach, roach\": 314,\n",
      "    \"cocktail shaker\": 503,\n",
      "    \"coffee mug\": 504,\n",
      "    \"coffeepot\": 505,\n",
      "    \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\": 391,\n",
      "    \"coil, spiral, volute, whorl, helix\": 506,\n",
      "    \"collie\": 231,\n",
      "    \"colobus, colobus monkey\": 375,\n",
      "    \"combination lock\": 507,\n",
      "    \"comic book\": 917,\n",
      "    \"common iguana, iguana, Iguana iguana\": 39,\n",
      "    \"common newt, Triturus vulgaris\": 26,\n",
      "    \"computer keyboard, keypad\": 508,\n",
      "    \"conch\": 112,\n",
      "    \"confectionery, confectionary, candy store\": 509,\n",
      "    \"consomme\": 925,\n",
      "    \"container ship, containership, container vessel\": 510,\n",
      "    \"convertible\": 511,\n",
      "    \"coral fungus\": 991,\n",
      "    \"coral reef\": 973,\n",
      "    \"corkscrew, bottle screw\": 512,\n",
      "    \"corn\": 987,\n",
      "    \"cornet, horn, trumpet, trump\": 513,\n",
      "    \"coucal\": 91,\n",
      "    \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\": 286,\n",
      "    \"cowboy boot\": 514,\n",
      "    \"cowboy hat, ten-gallon hat\": 515,\n",
      "    \"coyote, prairie wolf, brush wolf, Canis latrans\": 272,\n",
      "    \"cradle\": 516,\n",
      "    \"crane\": 517,\n",
      "    \"crash helmet\": 518,\n",
      "    \"crate\": 519,\n",
      "    \"crayfish, crawfish, crawdad, crawdaddy\": 124,\n",
      "    \"crib, cot\": 520,\n",
      "    \"cricket\": 312,\n",
      "    \"croquet ball\": 522,\n",
      "    \"crossword puzzle, crossword\": 918,\n",
      "    \"crutch\": 523,\n",
      "    \"cucumber, cuke\": 943,\n",
      "    \"cuirass\": 524,\n",
      "    \"cup\": 968,\n",
      "    \"curly-coated retriever\": 206,\n",
      "    \"custard apple\": 956,\n",
      "    \"daisy\": 985,\n",
      "    \"dalmatian, coach dog, carriage dog\": 251,\n",
      "    \"dam, dike, dyke\": 525,\n",
      "    \"damselfly\": 320,\n",
      "    \"desk\": 526,\n",
      "    \"desktop computer\": 527,\n",
      "    \"dhole, Cuon alpinus\": 274,\n",
      "    \"dial telephone, dial phone\": 528,\n",
      "    \"diamondback, diamondback rattlesnake, Crotalus adamanteus\": 67,\n",
      "    \"diaper, nappy, napkin\": 529,\n",
      "    \"digital clock\": 530,\n",
      "    \"digital watch\": 531,\n",
      "    \"dingo, warrigal, warragal, Canis dingo\": 273,\n",
      "    \"dining table, board\": 532,\n",
      "    \"dishrag, dishcloth\": 533,\n",
      "    \"dishwasher, dish washer, dishwashing machine\": 534,\n",
      "    \"disk brake, disc brake\": 535,\n",
      "    \"dock, dockage, docking facility\": 536,\n",
      "    \"dogsled, dog sled, dog sleigh\": 537,\n",
      "    \"dome\": 538,\n",
      "    \"doormat, welcome mat\": 539,\n",
      "    \"dough\": 961,\n",
      "    \"dowitcher\": 142,\n",
      "    \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\": 319,\n",
      "    \"drake\": 97,\n",
      "    \"drilling platform, offshore rig\": 540,\n",
      "    \"drum, membranophone, tympan\": 541,\n",
      "    \"drumstick\": 542,\n",
      "    \"dugong, Dugong dugon\": 149,\n",
      "    \"dumbbell\": 543,\n",
      "    \"dung beetle\": 305,\n",
      "    \"ear, spike, capitulum\": 998,\n",
      "    \"earthstar\": 995,\n",
      "    \"echidna, spiny anteater, anteater\": 102,\n",
      "    \"eel\": 390,\n",
      "    \"eft\": 27,\n",
      "    \"eggnog\": 969,\n",
      "    \"electric fan, blower\": 545,\n",
      "    \"electric guitar\": 546,\n",
      "    \"electric locomotive\": 547,\n",
      "    \"electric ray, crampfish, numbfish, torpedo\": 5,\n",
      "    \"entertainment center\": 548,\n",
      "    \"envelope\": 549,\n",
      "    \"espresso\": 967,\n",
      "    \"espresso maker\": 550,\n",
      "    \"face powder\": 551,\n",
      "    \"feather boa, boa\": 552,\n",
      "    \"fiddler crab\": 120,\n",
      "    \"fig\": 952,\n",
      "    \"file, file cabinet, filing cabinet\": 553,\n",
      "    \"fire engine, fire truck\": 555,\n",
      "    \"fire screen, fireguard\": 556,\n",
      "    \"fireboat\": 554,\n",
      "    \"flagpole, flagstaff\": 557,\n",
      "    \"flamingo\": 130,\n",
      "    \"flat-coated retriever\": 205,\n",
      "    \"flatworm, platyhelminth\": 110,\n",
      "    \"flute, transverse flute\": 558,\n",
      "    \"fly\": 308,\n",
      "    \"folding chair\": 559,\n",
      "    \"football helmet\": 560,\n",
      "    \"forklift\": 561,\n",
      "    \"fountain\": 562,\n",
      "    \"fountain pen\": 563,\n",
      "    \"four-poster\": 564,\n",
      "    \"fox squirrel, eastern fox squirrel, Sciurus niger\": 335,\n",
      "    \"freight car\": 565,\n",
      "    \"frilled lizard, Chlamydosaurus kingi\": 43,\n",
      "    \"frying pan, frypan, skillet\": 567,\n",
      "    \"fur coat\": 568,\n",
      "    \"gar, garfish, garpike, billfish, Lepisosteus osseus\": 395,\n",
      "    \"garbage truck, dustcart\": 569,\n",
      "    \"garden spider, Aranea diademata\": 74,\n",
      "    \"garter snake, grass snake\": 57,\n",
      "    \"gas pump, gasoline pump, petrol pump, island dispenser\": 571,\n",
      "    \"gasmask, respirator, gas helmet\": 570,\n",
      "    \"gazelle\": 353,\n",
      "    \"geyser\": 974,\n",
      "    \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\": 388,\n",
      "    \"giant schnauzer\": 197,\n",
      "    \"gibbon, Hylobates lar\": 368,\n",
      "    \"go-kart\": 573,\n",
      "    \"goblet\": 572,\n",
      "    \"golden retriever\": 207,\n",
      "    \"goldfinch, Carduelis carduelis\": 11,\n",
      "    \"goldfish, Carassius auratus\": 1,\n",
      "    \"golf ball\": 574,\n",
      "    \"golfcart, golf cart\": 575,\n",
      "    \"gondola\": 576,\n",
      "    \"gong, tam-tam\": 577,\n",
      "    \"goose\": 99,\n",
      "    \"gorilla, Gorilla gorilla\": 366,\n",
      "    \"gown\": 578,\n",
      "    \"grand piano, grand\": 579,\n",
      "    \"grasshopper, hopper\": 311,\n",
      "    \"great grey owl, great gray owl, Strix nebulosa\": 24,\n",
      "    \"great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias\": 2,\n",
      "    \"green lizard, Lacerta viridis\": 46,\n",
      "    \"green mamba\": 64,\n",
      "    \"green snake, grass snake\": 55,\n",
      "    \"greenhouse, nursery, glasshouse\": 580,\n",
      "    \"grey fox, gray fox, Urocyon cinereoargenteus\": 280,\n",
      "    \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus\": 147,\n",
      "    \"grille, radiator grille\": 581,\n",
      "    \"grocery store, grocery, food market, market\": 582,\n",
      "    \"groenendael\": 224,\n",
      "    \"groom, bridegroom\": 982,\n",
      "    \"ground beetle, carabid beetle\": 302,\n",
      "    \"guacamole\": 924,\n",
      "    \"guenon, guenon monkey\": 370,\n",
      "    \"guillotine\": 583,\n",
      "    \"guinea pig, Cavia cobaya\": 338,\n",
      "    \"gyromitra\": 993,\n",
      "    \"hair slide\": 584,\n",
      "    \"hair spray\": 585,\n",
      "    \"half track\": 586,\n",
      "    \"hammer\": 587,\n",
      "    \"hammerhead, hammerhead shark\": 4,\n",
      "    \"hamper\": 588,\n",
      "    \"hamster\": 333,\n",
      "    \"hand blower, blow dryer, blow drier, hair dryer, hair drier\": 589,\n",
      "    \"hand-held computer, hand-held microcomputer\": 590,\n",
      "    \"handkerchief, hankie, hanky, hankey\": 591,\n",
      "    \"hard disc, hard disk, fixed disk\": 592,\n",
      "    \"hare\": 331,\n",
      "    \"harmonica, mouth organ, harp, mouth harp\": 593,\n",
      "    \"harp\": 594,\n",
      "    \"hartebeest\": 351,\n",
      "    \"harvester, reaper\": 595,\n",
      "    \"harvestman, daddy longlegs, Phalangium opilio\": 70,\n",
      "    \"hatchet\": 596,\n",
      "    \"hay\": 958,\n",
      "    \"head cabbage\": 936,\n",
      "    \"hen\": 8,\n",
      "    \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\": 996,\n",
      "    \"hermit crab\": 125,\n",
      "    \"hip, rose hip, rosehip\": 989,\n",
      "    \"hippopotamus, hippo, river horse, Hippopotamus amphibius\": 344,\n",
      "    \"hog, pig, grunter, squealer, Sus scrofa\": 341,\n",
      "    \"hognose snake, puff adder, sand viper\": 54,\n",
      "    \"holster\": 597,\n",
      "    \"home theater, home theatre\": 598,\n",
      "    \"honeycomb\": 599,\n",
      "    \"hook, claw\": 600,\n",
      "    \"hoopskirt, crinoline\": 601,\n",
      "    \"horizontal bar, high bar\": 602,\n",
      "    \"hornbill\": 93,\n",
      "    \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\": 66,\n",
      "    \"horse cart, horse-cart\": 603,\n",
      "    \"hot pot, hotpot\": 926,\n",
      "    \"hotdog, hot dog, red hot\": 934,\n",
      "    \"hourglass\": 604,\n",
      "    \"house finch, linnet, Carpodacus mexicanus\": 12,\n",
      "    \"howler monkey, howler\": 379,\n",
      "    \"hummingbird\": 94,\n",
      "    \"hyena, hyaena\": 276,\n",
      "    \"iPod\": 605,\n",
      "    \"ibex, Capra ibex\": 350,\n",
      "    \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\": 296,\n",
      "    \"ice cream, icecream\": 928,\n",
      "    \"ice lolly, lolly, lollipop, popsicle\": 929,\n",
      "    \"impala, Aepyceros melampus\": 352,\n",
      "    \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\": 14,\n",
      "    \"indri, indris, Indri indri, Indri brevicaudatus\": 384,\n",
      "    \"iron, smoothing iron\": 606,\n",
      "    \"isopod\": 126,\n",
      "    \"jacamar\": 95,\n",
      "    \"jack-o'-lantern\": 607,\n",
      "    \"jackfruit, jak, jack\": 955,\n",
      "    \"jaguar, panther, Panthera onca, Felis onca\": 290,\n",
      "    \"jay\": 17,\n",
      "    \"jean, blue jean, denim\": 608,\n",
      "    \"jeep, landrover\": 609,\n",
      "    \"jellyfish\": 107,\n",
      "    \"jersey, T-shirt, tee shirt\": 610,\n",
      "    \"jigsaw puzzle\": 611,\n",
      "    \"jinrikisha, ricksha, rickshaw\": 612,\n",
      "    \"joystick\": 613,\n",
      "    \"junco, snowbird\": 13,\n",
      "    \"keeshond\": 261,\n",
      "    \"kelpie\": 227,\n",
      "    \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\": 148,\n",
      "    \"kimono\": 614,\n",
      "    \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica\": 121,\n",
      "    \"king penguin, Aptenodytes patagonica\": 145,\n",
      "    \"king snake, kingsnake\": 56,\n",
      "    \"kit fox, Vulpes macrotis\": 278,\n",
      "    \"kite\": 21,\n",
      "    \"knee pad\": 615,\n",
      "    \"knot\": 616,\n",
      "    \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\": 105,\n",
      "    \"komondor\": 228,\n",
      "    \"kuvasz\": 222,\n",
      "    \"lab coat, laboratory coat\": 617,\n",
      "    \"lacewing, lacewing fly\": 318,\n",
      "    \"ladle\": 618,\n",
      "    \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\": 301,\n",
      "    \"lakeside, lakeshore\": 975,\n",
      "    \"lampshade, lamp shade\": 619,\n",
      "    \"langur\": 374,\n",
      "    \"laptop, laptop computer\": 620,\n",
      "    \"lawn mower, mower\": 621,\n",
      "    \"leaf beetle, chrysomelid\": 304,\n",
      "    \"leafhopper\": 317,\n",
      "    \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\": 34,\n",
      "    \"lemon\": 951,\n",
      "    \"lens cap, lens cover\": 622,\n",
      "    \"leopard, Panthera pardus\": 288,\n",
      "    \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\": 387,\n",
      "    \"letter opener, paper knife, paperknife\": 623,\n",
      "    \"library\": 624,\n",
      "    \"lifeboat\": 625,\n",
      "    \"lighter, light, igniter, ignitor\": 626,\n",
      "    \"limousine, limo\": 627,\n",
      "    \"limpkin, Aramus pictus\": 135,\n",
      "    \"liner, ocean liner\": 628,\n",
      "    \"lion, king of beasts, Panthera leo\": 291,\n",
      "    \"lionfish\": 396,\n",
      "    \"lipstick, lip rouge\": 629,\n",
      "    \"little blue heron, Egretta caerulea\": 131,\n",
      "    \"llama\": 355,\n",
      "    \"loggerhead, loggerhead turtle, Caretta caretta\": 33,\n",
      "    \"long-horned beetle, longicorn, longicorn beetle\": 303,\n",
      "    \"lorikeet\": 90,\n",
      "    \"lotion\": 631,\n",
      "    \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\": 632,\n",
      "    \"loupe, jeweler's loupe\": 633,\n",
      "    \"lumbermill, sawmill\": 634,\n",
      "    \"lycaenid, lycaenid butterfly\": 326,\n",
      "    \"lynx, catamount\": 287,\n",
      "    \"macaque\": 373,\n",
      "    \"macaw\": 88,\n",
      "    \"magnetic compass\": 635,\n",
      "    \"magpie\": 18,\n",
      "    \"mailbag, postbag\": 636,\n",
      "    \"mailbox, letter box\": 637,\n",
      "    \"maillot\": 638,\n",
      "    \"maillot, tank suit\": 639,\n",
      "    \"malamute, malemute, Alaskan malamute\": 249,\n",
      "    \"malinois\": 225,\n",
      "    \"manhole cover\": 640,\n",
      "    \"mantis, mantid\": 315,\n",
      "    \"maraca\": 641,\n",
      "    \"marimba, xylophone\": 642,\n",
      "    \"marmoset\": 377,\n",
      "    \"marmot\": 336,\n",
      "    \"mashed potato\": 935,\n",
      "    \"mask\": 643,\n",
      "    \"matchstick\": 644,\n",
      "    \"maypole\": 645,\n",
      "    \"maze, labyrinth\": 646,\n",
      "    \"measuring cup\": 647,\n",
      "    \"meat loaf, meatloaf\": 962,\n",
      "    \"medicine chest, medicine cabinet\": 648,\n",
      "    \"meerkat, mierkat\": 299,\n",
      "    \"megalith, megalithic structure\": 649,\n",
      "    \"menu\": 922,\n",
      "    \"microphone, mike\": 650,\n",
      "    \"microwave, microwave oven\": 651,\n",
      "    \"military uniform\": 652,\n",
      "    \"milk can\": 653,\n",
      "    \"miniature pinscher\": 237,\n",
      "    \"miniature poodle\": 266,\n",
      "    \"miniature schnauzer\": 196,\n",
      "    \"minibus\": 654,\n",
      "    \"miniskirt, mini\": 655,\n",
      "    \"minivan\": 656,\n",
      "    \"mink\": 357,\n",
      "    \"missile\": 657,\n",
      "    \"mitten\": 658,\n",
      "    \"mixing bowl\": 659,\n",
      "    \"mobile home, manufactured home\": 660,\n",
      "    \"modem\": 662,\n",
      "    \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\": 323,\n",
      "    \"monastery\": 663,\n",
      "    \"mongoose\": 298,\n",
      "    \"monitor\": 664,\n",
      "    \"moped\": 665,\n",
      "    \"mortar\": 666,\n",
      "    \"mortarboard\": 667,\n",
      "    \"mosque\": 668,\n",
      "    \"mosquito net\": 669,\n",
      "    \"motor scooter, scooter\": 670,\n",
      "    \"mountain bike, all-terrain bike, off-roader\": 671,\n",
      "    \"mountain tent\": 672,\n",
      "    \"mouse, computer mouse\": 673,\n",
      "    \"mousetrap\": 674,\n",
      "    \"moving van\": 675,\n",
      "    \"mud turtle\": 35,\n",
      "    \"mushroom\": 947,\n",
      "    \"muzzle\": 676,\n",
      "    \"nail\": 677,\n",
      "    \"neck brace\": 678,\n",
      "    \"necklace\": 679,\n",
      "    \"nematode, nematode worm, roundworm\": 111,\n",
      "    \"night snake, Hypsiglena torquata\": 60,\n",
      "    \"nipple\": 680,\n",
      "    \"notebook, notebook computer\": 681,\n",
      "    \"obelisk\": 682,\n",
      "    \"oboe, hautboy, hautbois\": 683,\n",
      "    \"ocarina, sweet potato\": 684,\n",
      "    \"odometer, hodometer, mileometer, milometer\": 685,\n",
      "    \"oil filter\": 686,\n",
      "    \"orange\": 950,\n",
      "    \"orangutan, orang, orangutang, Pongo pygmaeus\": 365,\n",
      "    \"organ, pipe organ\": 687,\n",
      "    \"oscilloscope, scope, cathode-ray oscilloscope, CRO\": 688,\n",
      "    \"ostrich, Struthio camelus\": 9,\n",
      "    \"otter\": 360,\n",
      "    \"otterhound, otter hound\": 175,\n",
      "    \"overskirt\": 689,\n",
      "    \"ox\": 345,\n",
      "    \"oxcart\": 690,\n",
      "    \"oxygen mask\": 691,\n",
      "    \"oystercatcher, oyster catcher\": 143,\n",
      "    \"packet\": 692,\n",
      "    \"paddle, boat paddle\": 693,\n",
      "    \"paddlewheel, paddle wheel\": 694,\n",
      "    \"padlock\": 695,\n",
      "    \"paintbrush\": 696,\n",
      "    \"pajama, pyjama, pj's, jammies\": 697,\n",
      "    \"palace\": 698,\n",
      "    \"panpipe, pandean pipe, syrinx\": 699,\n",
      "    \"paper towel\": 700,\n",
      "    \"papillon\": 157,\n",
      "    \"parachute, chute\": 701,\n",
      "    \"parallel bars, bars\": 702,\n",
      "    \"park bench\": 703,\n",
      "    \"parking meter\": 704,\n",
      "    \"partridge\": 86,\n",
      "    \"passenger car, coach, carriage\": 705,\n",
      "    \"patas, hussar monkey, Erythrocebus patas\": 371,\n",
      "    \"patio, terrace\": 706,\n",
      "    \"pay-phone, pay-station\": 707,\n",
      "    \"peacock\": 84,\n",
      "    \"pedestal, plinth, footstall\": 708,\n",
      "    \"pelican\": 144,\n",
      "    \"pencil box, pencil case\": 709,\n",
      "    \"pencil sharpener\": 710,\n",
      "    \"perfume, essence\": 711,\n",
      "    \"photocopier\": 713,\n",
      "    \"pick, plectrum, plectron\": 714,\n",
      "    \"pickelhaube\": 715,\n",
      "    \"picket fence, paling\": 716,\n",
      "    \"pickup, pickup truck\": 717,\n",
      "    \"pier\": 718,\n",
      "    \"piggy bank, penny bank\": 719,\n",
      "    \"pill bottle\": 720,\n",
      "    \"pillow\": 721,\n",
      "    \"pineapple, ananas\": 953,\n",
      "    \"ping-pong ball\": 722,\n",
      "    \"pinwheel\": 723,\n",
      "    \"pirate, pirate ship\": 724,\n",
      "    \"pitcher, ewer\": 725,\n",
      "    \"pizza, pizza pie\": 963,\n",
      "    \"plane, carpenter's plane, woodworking plane\": 726,\n",
      "    \"planetarium\": 727,\n",
      "    \"plastic bag\": 728,\n",
      "    \"plate\": 923,\n",
      "    \"plate rack\": 729,\n",
      "    \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus\": 103,\n",
      "    \"plow, plough\": 730,\n",
      "    \"plunger, plumber's helper\": 731,\n",
      "    \"pole\": 733,\n",
      "    \"polecat, fitch, foulmart, foumart, Mustela putorius\": 358,\n",
      "    \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\": 734,\n",
      "    \"pomegranate\": 957,\n",
      "    \"poncho\": 735,\n",
      "    \"pool table, billiard table, snooker table\": 736,\n",
      "    \"pop bottle, soda bottle\": 737,\n",
      "    \"porcupine, hedgehog\": 334,\n",
      "    \"pot, flowerpot\": 738,\n",
      "    \"potpie\": 964,\n",
      "    \"potter's wheel\": 739,\n",
      "    \"power drill\": 740,\n",
      "    \"prairie chicken, prairie grouse, prairie fowl\": 83,\n",
      "    \"prayer rug, prayer mat\": 741,\n",
      "    \"pretzel\": 932,\n",
      "    \"printer\": 742,\n",
      "    \"prison, prison house\": 743,\n",
      "    \"proboscis monkey, Nasalis larvatus\": 376,\n",
      "    \"projectile, missile\": 744,\n",
      "    \"projector\": 745,\n",
      "    \"promontory, headland, head, foreland\": 976,\n",
      "    \"ptarmigan\": 81,\n",
      "    \"puck, hockey puck\": 746,\n",
      "    \"puffer, pufferfish, blowfish, globefish\": 397,\n",
      "    \"pug, pug-dog\": 254,\n",
      "    \"punching bag, punch bag, punching ball, punchball\": 747,\n",
      "    \"purse\": 748,\n",
      "    \"quail\": 85,\n",
      "    \"quill, quill pen\": 749,\n",
      "    \"quilt, comforter, comfort, puff\": 750,\n",
      "    \"racer, race car, racing car\": 751,\n",
      "    \"racket, racquet\": 752,\n",
      "    \"radiator\": 753,\n",
      "    \"radio telescope, radio reflector\": 755,\n",
      "    \"radio, wireless\": 754,\n",
      "    \"rain barrel\": 756,\n",
      "    \"ram, tup\": 348,\n",
      "    \"rapeseed\": 984,\n",
      "    \"recreational vehicle, RV, R.V.\": 757,\n",
      "    \"red fox, Vulpes vulpes\": 277,\n",
      "    \"red wine\": 966,\n",
      "    \"red wolf, maned wolf, Canis rufus, Canis niger\": 271,\n",
      "    \"red-backed sandpiper, dunlin, Erolia alpina\": 140,\n",
      "    \"red-breasted merganser, Mergus serrator\": 98,\n",
      "    \"redbone\": 168,\n",
      "    \"redshank, Tringa totanus\": 141,\n",
      "    \"reel\": 758,\n",
      "    \"reflex camera\": 759,\n",
      "    \"refrigerator, icebox\": 760,\n",
      "    \"remote control, remote\": 761,\n",
      "    \"restaurant, eating house, eating place, eatery\": 762,\n",
      "    \"revolver, six-gun, six-shooter\": 763,\n",
      "    \"rhinoceros beetle\": 306,\n",
      "    \"rifle\": 764,\n",
      "    \"ringlet, ringlet butterfly\": 322,\n",
      "    \"ringneck snake, ring-necked snake, ring snake\": 53,\n",
      "    \"robin, American robin, Turdus migratorius\": 15,\n",
      "    \"rock beauty, Holocanthus tricolor\": 392,\n",
      "    \"rock crab, Cancer irroratus\": 119,\n",
      "    \"rock python, rock snake, Python sebae\": 62,\n",
      "    \"rocking chair, rocker\": 765,\n",
      "    \"rotisserie\": 766,\n",
      "    \"rubber eraser, rubber, pencil eraser\": 767,\n",
      "    \"ruddy turnstone, Arenaria interpres\": 139,\n",
      "    \"ruffed grouse, partridge, Bonasa umbellus\": 82,\n",
      "    \"rugby ball\": 768,\n",
      "    \"rule, ruler\": 769,\n",
      "    \"running shoe\": 770,\n",
      "    \"safe\": 771,\n",
      "    \"safety pin\": 772,\n",
      "    \"saltshaker, salt shaker\": 773,\n",
      "    \"sandal\": 774,\n",
      "    \"sandbar, sand bar\": 977,\n",
      "    \"sarong\": 775,\n",
      "    \"sax, saxophone\": 776,\n",
      "    \"scabbard\": 777,\n",
      "    \"scale, weighing machine\": 778,\n",
      "    \"schipperke\": 223,\n",
      "    \"school bus\": 779,\n",
      "    \"schooner\": 780,\n",
      "    \"scoreboard\": 781,\n",
      "    \"scorpion\": 71,\n",
      "    \"screen, CRT screen\": 782,\n",
      "    \"screw\": 783,\n",
      "    \"screwdriver\": 784,\n",
      "    \"scuba diver\": 983,\n",
      "    \"sea anemone, anemone\": 108,\n",
      "    \"sea cucumber, holothurian\": 329,\n",
      "    \"sea lion\": 150,\n",
      "    \"sea slug, nudibranch\": 115,\n",
      "    \"sea snake\": 65,\n",
      "    \"sea urchin\": 328,\n",
      "    \"seashore, coast, seacoast, sea-coast\": 978,\n",
      "    \"seat belt, seatbelt\": 785,\n",
      "    \"sewing machine\": 786,\n",
      "    \"shield, buckler\": 787,\n",
      "    \"shoe shop, shoe-shop, shoe store\": 788,\n",
      "    \"shoji\": 789,\n",
      "    \"shopping basket\": 790,\n",
      "    \"shopping cart\": 791,\n",
      "    \"shovel\": 792,\n",
      "    \"shower cap\": 793,\n",
      "    \"shower curtain\": 794,\n",
      "    \"siamang, Hylobates syndactylus, Symphalangus syndactylus\": 369,\n",
      "    \"sidewinder, horned rattlesnake, Crotalus cerastes\": 68,\n",
      "    \"silky terrier, Sydney silky\": 201,\n",
      "    \"ski\": 795,\n",
      "    \"ski mask\": 796,\n",
      "    \"skunk, polecat, wood pussy\": 361,\n",
      "    \"sleeping bag\": 797,\n",
      "    \"slide rule, slipstick\": 798,\n",
      "    \"sliding door\": 799,\n",
      "    \"slot, one-armed bandit\": 800,\n",
      "    \"sloth bear, Melursus ursinus, Ursus ursinus\": 297,\n",
      "    \"slug\": 114,\n",
      "    \"snail\": 113,\n",
      "    \"snorkel\": 801,\n",
      "    \"snow leopard, ounce, Panthera uncia\": 289,\n",
      "    \"snowmobile\": 802,\n",
      "    \"snowplow, snowplough\": 803,\n",
      "    \"soap dispenser\": 804,\n",
      "    \"soccer ball\": 805,\n",
      "    \"sock\": 806,\n",
      "    \"soft-coated wheaten terrier\": 202,\n",
      "    \"solar dish, solar collector, solar furnace\": 807,\n",
      "    \"sombrero\": 808,\n",
      "    \"sorrel\": 339,\n",
      "    \"soup bowl\": 809,\n",
      "    \"space bar\": 810,\n",
      "    \"space heater\": 811,\n",
      "    \"space shuttle\": 812,\n",
      "    \"spaghetti squash\": 940,\n",
      "    \"spatula\": 813,\n",
      "    \"speedboat\": 814,\n",
      "    \"spider monkey, Ateles geoffroyi\": 381,\n",
      "    \"spider web, spider's web\": 815,\n",
      "    \"spindle\": 816,\n",
      "    \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\": 123,\n",
      "    \"spoonbill\": 129,\n",
      "    \"sports car, sport car\": 817,\n",
      "    \"spotlight, spot\": 818,\n",
      "    \"spotted salamander, Ambystoma maculatum\": 28,\n",
      "    \"squirrel monkey, Saimiri sciureus\": 382,\n",
      "    \"stage\": 819,\n",
      "    \"standard poodle\": 267,\n",
      "    \"standard schnauzer\": 198,\n",
      "    \"starfish, sea star\": 327,\n",
      "    \"steam locomotive\": 820,\n",
      "    \"steel arch bridge\": 821,\n",
      "    \"steel drum\": 822,\n",
      "    \"stethoscope\": 823,\n",
      "    \"stingray\": 6,\n",
      "    \"stinkhorn, carrion fungus\": 994,\n",
      "    \"stole\": 824,\n",
      "    \"stone wall\": 825,\n",
      "    \"stopwatch, stop watch\": 826,\n",
      "    \"stove\": 827,\n",
      "    \"strainer\": 828,\n",
      "    \"strawberry\": 949,\n",
      "    \"street sign\": 919,\n",
      "    \"streetcar, tram, tramcar, trolley, trolley car\": 829,\n",
      "    \"stretcher\": 830,\n",
      "    \"studio couch, day bed\": 831,\n",
      "    \"stupa, tope\": 832,\n",
      "    \"sturgeon\": 394,\n",
      "    \"submarine, pigboat, sub, U-boat\": 833,\n",
      "    \"suit, suit of clothes\": 834,\n",
      "    \"sulphur butterfly, sulfur butterfly\": 325,\n",
      "    \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\": 89,\n",
      "    \"sundial\": 835,\n",
      "    \"sunglass\": 836,\n",
      "    \"sunglasses, dark glasses, shades\": 837,\n",
      "    \"sunscreen, sunblock, sun blocker\": 838,\n",
      "    \"suspension bridge\": 839,\n",
      "    \"swab, swob, mop\": 840,\n",
      "    \"sweatshirt\": 841,\n",
      "    \"swimming trunks, bathing trunks\": 842,\n",
      "    \"swing\": 843,\n",
      "    \"switch, electric switch, electrical switch\": 844,\n",
      "    \"syringe\": 845,\n",
      "    \"tabby, tabby cat\": 281,\n",
      "    \"table lamp\": 846,\n",
      "    \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\": 32,\n",
      "    \"tank, army tank, armored combat vehicle, armoured combat vehicle\": 847,\n",
      "    \"tape player\": 848,\n",
      "    \"tarantula\": 76,\n",
      "    \"teapot\": 849,\n",
      "    \"teddy, teddy bear\": 850,\n",
      "    \"television, television system\": 851,\n",
      "    \"tench, Tinca tinca\": 0,\n",
      "    \"tennis ball\": 852,\n",
      "    \"terrapin\": 36,\n",
      "    \"thatch, thatched roof\": 853,\n",
      "    \"theater curtain, theatre curtain\": 854,\n",
      "    \"thimble\": 855,\n",
      "    \"three-toed sloth, ai, Bradypus tridactylus\": 364,\n",
      "    \"thresher, thrasher, threshing machine\": 856,\n",
      "    \"throne\": 857,\n",
      "    \"thunder snake, worm snake, Carphophis amoenus\": 52,\n",
      "    \"tick\": 78,\n",
      "    \"tiger beetle\": 300,\n",
      "    \"tiger cat\": 282,\n",
      "    \"tiger shark, Galeocerdo cuvieri\": 3,\n",
      "    \"tiger, Panthera tigris\": 292,\n",
      "    \"tile roof\": 858,\n",
      "    \"timber wolf, grey wolf, gray wolf, Canis lupus\": 269,\n",
      "    \"titi, titi monkey\": 380,\n",
      "    \"toaster\": 859,\n",
      "    \"tobacco shop, tobacconist shop, tobacconist\": 860,\n",
      "    \"toilet seat\": 861,\n",
      "    \"toilet tissue, toilet paper, bathroom tissue\": 999,\n",
      "    \"torch\": 862,\n",
      "    \"totem pole\": 863,\n",
      "    \"toucan\": 96,\n",
      "    \"tow truck, tow car, wrecker\": 864,\n",
      "    \"toy poodle\": 265,\n",
      "    \"toy terrier\": 158,\n",
      "    \"toyshop\": 865,\n",
      "    \"tractor\": 866,\n",
      "    \"traffic light, traffic signal, stoplight\": 920,\n",
      "    \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi\": 867,\n",
      "    \"tray\": 868,\n",
      "    \"tree frog, tree-frog\": 31,\n",
      "    \"trench coat\": 869,\n",
      "    \"triceratops\": 51,\n",
      "    \"tricycle, trike, velocipede\": 870,\n",
      "    \"trifle\": 927,\n",
      "    \"trilobite\": 69,\n",
      "    \"trimaran\": 871,\n",
      "    \"tripod\": 872,\n",
      "    \"triumphal arch\": 873,\n",
      "    \"trolleybus, trolley coach, trackless trolley\": 874,\n",
      "    \"trombone\": 875,\n",
      "    \"tub, vat\": 876,\n",
      "    \"turnstile\": 877,\n",
      "    \"tusker\": 101,\n",
      "    \"typewriter keyboard\": 878,\n",
      "    \"umbrella\": 879,\n",
      "    \"unicycle, monocycle\": 880,\n",
      "    \"upright, upright piano\": 881,\n",
      "    \"vacuum, vacuum cleaner\": 882,\n",
      "    \"valley, vale\": 979,\n",
      "    \"vase\": 883,\n",
      "    \"vault\": 884,\n",
      "    \"velvet\": 885,\n",
      "    \"vending machine\": 886,\n",
      "    \"vestment\": 887,\n",
      "    \"viaduct\": 888,\n",
      "    \"vine snake\": 59,\n",
      "    \"violin, fiddle\": 889,\n",
      "    \"vizsla, Hungarian pointer\": 211,\n",
      "    \"volcano\": 980,\n",
      "    \"volleyball\": 890,\n",
      "    \"vulture\": 23,\n",
      "    \"waffle iron\": 891,\n",
      "    \"walking stick, walkingstick, stick insect\": 313,\n",
      "    \"wall clock\": 892,\n",
      "    \"wallaby, brush kangaroo\": 104,\n",
      "    \"wallet, billfold, notecase, pocketbook\": 893,\n",
      "    \"wardrobe, closet, press\": 894,\n",
      "    \"warplane, military plane\": 895,\n",
      "    \"warthog\": 343,\n",
      "    \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\": 896,\n",
      "    \"washer, automatic washer, washing machine\": 897,\n",
      "    \"water bottle\": 898,\n",
      "    \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\": 346,\n",
      "    \"water jug\": 899,\n",
      "    \"water ouzel, dipper\": 20,\n",
      "    \"water snake\": 58,\n",
      "    \"water tower\": 900,\n",
      "    \"weasel\": 356,\n",
      "    \"web site, website, internet site, site\": 916,\n",
      "    \"weevil\": 307,\n",
      "    \"whippet\": 172,\n",
      "    \"whiptail, whiptail lizard\": 41,\n",
      "    \"whiskey jug\": 901,\n",
      "    \"whistle\": 902,\n",
      "    \"white stork, Ciconia ciconia\": 127,\n",
      "    \"white wolf, Arctic wolf, Canis lupus tundrarum\": 270,\n",
      "    \"wig\": 903,\n",
      "    \"wild boar, boar, Sus scrofa\": 342,\n",
      "    \"window screen\": 904,\n",
      "    \"window shade\": 905,\n",
      "    \"wine bottle\": 907,\n",
      "    \"wing\": 908,\n",
      "    \"wire-haired fox terrier\": 188,\n",
      "    \"wok\": 909,\n",
      "    \"wolf spider, hunting spider\": 77,\n",
      "    \"wombat\": 106,\n",
      "    \"wood rabbit, cottontail, cottontail rabbit\": 330,\n",
      "    \"wooden spoon\": 910,\n",
      "    \"wool, woolen, woollen\": 911,\n",
      "    \"worm fence, snake fence, snake-rail fence, Virginia fence\": 912,\n",
      "    \"wreck\": 913,\n",
      "    \"yawl\": 914,\n",
      "    \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\": 986,\n",
      "    \"yurt\": 915,\n",
      "    \"zebra\": 340,\n",
      "    \"zucchini, courgette\": 939\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": true,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|image_processing_utils.py:533] 2023-03-24 15:17:48,723 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}), got 224. Converted to {'height': 224, 'width': 224}.\n",
      "[INFO|image_processing_utils.py:353] 2023-03-24 15:17:48,724 >> Image processor ViTImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"image_processor_type\": \"ViTImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.5,\n",
      "    0.5,\n",
      "    0.5\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO|trainer.py:543] 2023-03-24 15:17:48,773 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-03-24 15:17:48,778 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-24 15:17:48,779 >>   Num examples = 80000\n",
      "[INFO|trainer.py:1760] 2023-03-24 15:17:48,779 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-24 15:17:48,780 >>   Instantaneous batch size per device = 64\n",
      "[INFO|trainer.py:1762] 2023-03-24 15:17:48,780 >>   Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "[INFO|trainer.py:1763] 2023-03-24 15:17:48,781 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-24 15:17:48,781 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-24 15:17:48,783 >>   Number of trainable parameters = 85952456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreedyLR settings: patience=10 smooth=True min_lr=1e-05 factor=0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 09:25, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.439100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.408500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.412100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.428100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.447000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.446700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.458200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.412800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.417900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.437100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.401400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.399600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.436700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.385500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.429800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.378500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.477500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.458100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.377700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>5.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.465900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>5.401100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>5.415800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.417700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>5.425700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.445200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.458700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.432500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.432300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>5.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>5.431900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>5.397400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.448900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>5.430500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>5.396400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>5.418300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>5.395700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>5.405800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.468700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>5.415100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>5.424000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>5.463700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>5.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.428700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>5.394200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.420500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>5.433800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>5.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.398100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>5.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>5.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>5.404300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>5.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>5.435800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>5.411100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>5.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>5.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>5.444600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>5.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>5.412200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>5.430800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>5.452200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>5.454700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>5.440700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>5.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>5.420200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.446300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>5.425300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>5.389500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>5.446000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>5.452100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>5.420400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>5.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>5.446000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>5.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>5.428600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.434500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-24 15:27:14,808 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-24 15:27:14,811 >> Saving model checkpoint to /tmp/tmp3l29cbbu\n",
      "[INFO|configuration_utils.py:457] 2023-03-24 15:27:14,814 >> Configuration saved in /tmp/tmp3l29cbbu/config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-24 15:27:15,061 >> Model weights saved in /tmp/tmp3l29cbbu/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:203] 2023-03-24 15:27:15,063 >> Image processor saved in /tmp/tmp3l29cbbu/preprocessor_config.json\n",
      "[INFO|modelcard.py:449] 2023-03-24 15:27:15,119 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Image Classification', 'type': 'image-classification'}, 'dataset': {'name': 'Maysee/tiny-imagenet', 'type': 'imagefolder', 'config': 'default', 'split': 'train', 'args': 'default'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =          0.8\n",
      "  total_flos               = 4627079235GF\n",
      "  train_loss               =       5.4297\n",
      "  train_runtime            =   0:09:26.02\n",
      "  train_samples_per_second =      113.069\n",
      "  train_steps_per_second   =        1.767\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_image_classification.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path google/vit-base-patch16-224\n",
    "    --dataset_name Maysee/tiny-imagenet\n",
    "    --do_train\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 64\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --metric_for_best_model accuracy\n",
    "    --max_steps 1000\n",
    "    --train_val_split 0.2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --ignore_mismatched_sizes True\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_image_classification.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "63602e64-b64d-477b-b5f9-580a93df158b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "505dbd11-fa02-46c7-afbb-4009dfcb2db9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkYAAAF0CAYAAADGh/ZXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde3wM9/4/8Ndmk2wiNkuRbKIuoUpy0FPxdWsJbUnaUr26xdJ7XYpwzq84KIdWQlPtKUKrSi8qrSZ6wVFOL6isKA1CQqsStJq6lN0oSci+f39MsqxcZDXJbHZfz8djHjtm3jvz3qVnX2fmMzMaEREQEREREbzUboCIiIjIVTAYEREREZVgMCIiIiIqwWBEREREVILBiIiIiKgEgxERERFRCQYjIiIiohIMRkREREQlGIyIiIiISjAYEZHbWrlyJTQaDXbt2lXu+tzcXGg0Gvvk5eWFhg0b4u6778amTZtquVsicgUMRkTk8caNGwez2Yxt27YhMTERP/30E+677z5s3bpV7daIqJZ5q90AEZHamjdvjm7dugEA7rjjDrRp0wZRUVFYvnw5evXqpXJ3RFSbeMSIiOganTt3BgD8/vvvDsuPHDmCIUOGIDQ0FDqdDsHBwbj77ruxZ88eNdokohrAI0ZERNfIyckBANx6660Oy++77z4UFxdj/vz5aN68OU6fPo20tDScO3dOjTaJqAYwGBGRx7PZbLh8+TKKi4tx8OBBjB49GiEhIZg0aZK95syZMzh06BBef/11DB8+3L784YcfVqNlIqohDEZE5PEmT56MyZMn2/+s1+vxzTffoGXLlvZlN910E1q3bo1XXnkFxcXF6NOnD2677TZ4eXFEApE74X/RROTxJkyYgO+//x7fffcdEhMTcenSJQwcOBBnzpyx12g0Gnz11VeIjo7G/Pnz0alTJzRp0gTjx49Hfn6+it0TUXXiESMi8ng333yzfcD1HXfcAaPRiOHDh2PmzJlYtGiRva5FixZYvnw5AODHH3/Exx9/jFmzZqGoqAhLly5VpXciql48YkREdI3Y2Fj07t0by5Ytw9GjR8utufXWWzF9+nR06NABP/zwQy13SEQ1hUeMiMjtff3118jNzS2zPCIiosL3zJs3D127dsWcOXPw9ttvY9++fXj++efx2GOPoU2bNvD19cXXX3+Nffv2YcqUKTXYPRHVJgYjInJ7Vw+svlrpZfnl6dKlCx577DG8++67mDp1KoxGI1q3bo2kpCQcP34cGo0GrVq1wquvvopx48bVVOtEVMs0IiJqN0FERETkCjjGiIiIiKgEgxERERFRCQYjIiIiohIMRkREREQlGIyIiIiISjAYEREREZXgfYycZLPZcOLECej1emg0GrXbISIioioQEeTn5yM0NLTShz8zGDnpxIkTaNasmdptEBER0Q04fvw4br755grXMxg5Sa/XA1C+2MDAQJW7ISIioqqwWq1o1qyZ/Xe8IgxGTio9fRYYGMhgREREVMdcbxgMB18TERERlWAwIiIiIirBYERERERUgsGIiIiIqASDEREREVEJBiMiIiKiEgxGRERERCVuKBglJSUhLCwMfn5+iIyMxLZt2yqtT0lJQUREBHQ6HSIiIrB27VqH9SKCWbNmITQ0FP7+/ujduzcOHDjgUHP27FmYTCYYDAYYDAaYTCacO3fOvr6goACPP/44OnToAG9vbzz44IPl9rJlyxZERkbCz88PrVq1wtKlS2/kKyAiIiI35HQw+uijjxAXF4dp06YhIyMDPXv2xL333otjx46VW282mzF48GCYTCbs3bsXJpMJgwYNQnp6ur1m/vz5WLBgARYtWoTvv/8eRqMRffv2RX5+vr1m2LBh2LNnDzZu3IiNGzdiz549MJlM9vXFxcXw9/fH+PHjcc8995TbS05ODu677z707NkTGRkZ+Ne//oXx48cjJSXF2a+BiIiI3JBGRMSZN3Tt2hWdOnXCkiVL7MvCw8Px4IMPIj4+vkz94MGDYbVa8d///te+LCYmBg0bNsTq1ashIggNDUVcXBwmT54MACgsLERwcDDmzZuH5557DtnZ2YiIiMCOHTvQtWtXAMCOHTvQvXt3HDx4EG3btnXY5+OPP45z587h008/dVg+efJkfP7558jOzrYvGzVqFPbu3Quz2Vylz2+1WmEwGGCxWKrtztciwIUL1bIpIiKiOq9ePaC6n9Ne1d9vpx4JUlRUhN27d2PKlCkOy/v164e0tLRy32M2mzFx4kSHZdHR0Xj99dcBKEdx8vLy0K9fP/t6nU6HqKgopKWl4bnnnoPZbIbBYLCHIgDo1q0bDAYD0tLSygSjipjNZof9lPayfPlyXLp0CT4+PmXeU1hYiMLCQvufrVZrlfbljAsXgPfrj0J77K/2bZdKR1f8E4kAqvlfGhERUTU7fx4ICFBn304Fo9OnT6O4uBjBwcEOy4ODg5GXl1fue/Ly8iqtL30tr+bo0aP2mqCgoDLbDgoKqnC/zvRy+fJlnD59GiEhIWXeEx8fj3//+99V3seN6oh96IGqHbW6EXdiOz7AcOzB7TW2DyIiorruhh4ie+0D2ESk0oeyVaX+ejXlbf96+61qLxVtHwCmTp2KSZMm2f9c+nTe6lSvHnD7hrkoOPtHtW63lM/i16FN24b0GetxaTKDERERubZ69dTbt1PBqHHjxtBqtWWO0pw8ebLMkZhSRqOx0nqj0QhAOZpz9RGba2t+//33Mts+depUhft1phdvb280atSo3PfodDrodLoq7+NGaDSA/729a24H508Dadvgu3k9fGdPr7n9EBER1XFOXZXm6+uLyMhIbN682WH55s2b0aNHj3Lf07179zL1mzZtsteHhYXBaDQ61BQVFWHLli32mu7du8NisWDnzp32mvT0dFgslgr360wvnTt3Lnd8kdu47z7lNT0dOHVK3V6IiIhcmTgpOTlZfHx8ZPny5ZKVlSVxcXESEBAgubm5IiJiMplkypQp9vrt27eLVquVhIQEyc7OloSEBPH29pYdO3bYaxISEsRgMEhqaqpkZmbK0KFDJSQkRKxWq70mJiZGOnbsKGazWcxms3To0EH69+/v0NuBAwckIyNDBgwYIL1795aMjAzJyMiwrz9y5IjUq1dPJk6cKFlZWbJ8+XLx8fGRTz75pMqf32KxCACxWCzOfnXquu02EUDkvffU7oSIiKjWVfX32+lgJCKyePFiadGihfj6+kqnTp1ky5Yt9nVRUVEycuRIh/o1a9ZI27ZtxcfHR9q1aycpKSkO6202m8ycOVOMRqPodDrp1auXZGZmOtScOXNGYmNjRa/Xi16vl9jYWDl79qxDTYsWLQRAmelq3377rdx+++3i6+srLVu2lCVLljj12etsMPrXv5RgNHiw2p0QERHVuqr+fjt9HyNPVxP3MaoVaWnAHXcADRoop9O8b2jcPRERUZ1U1d9vPivNU3TtCjRqBJw7p4QkIiIiKoPByFNotUBMjDK/YYO6vRAREbkoBiNPcv/9yuv69er2QURE5KIYjDxJdDTg5QXs3w9U8NBfIiIiT8Zg5Eluugkove8TjxoRERGVwWDkaXg6jYiIqEIMRp6mNBh9/TVw8aK6vRAREbkYBiNP07490KyZEoq++UbtboiIiFwKg5Gn0WiuHDVat07dXoiIiFwMg5En6t9fef3iC4A3PiciIrJjMPJEd98NBAQAv/wC/PCD2t0QERG5DAYjT+Tnp9zTCAA++0zdXoiIiFwIg5GnGjhQeWUwIiIismMw8lT336/cBXvfPiAnR+1uiIiIXAKDkadq1Ai4805l/vPP1e2FiIjIRTAYeTKeTiMiInLAYOTJSoPR1q3AH3+o2wsREZELYDDyZK1bA3/7G1BcDPz3v2p3Q0REpDoGI0/H02lERER2DEaerjQY/fe/QGGhur0QERGpjMHI03XuDISEAOfP86GyRETk8RiMPJ2XF/DAA8o8T6cREZGHYzCiK6fTPv8csNnU7YWIiEhFDEYE9OkD1K8PnDgB7NqldjdERESqYTAi5aGy992nzKekqNsLERGRihiMSPHII8prSgogom4vREREKmEwIsV99ylHjn7+WXmwLBERkQdiMCJF/fpAdLQyz9NpRETkoRiM6IqrT6cRERF5IAYjumLAAMDHB8jKAg4eVLsbIiKiWsdgRFc0aADcfbcyz6NGRETkgRiMyBFPpxERkQdjMCJHAwcqjwnJyACOHFG7GyIiolrFYESOmjQBoqKU+dRUdXshIiKqZQxGVBZPpxERkYdiMKKyHnpIed2xA/jlF3V7ISIiqkUMRlRWaCjQo4cyv3atur0QERHVIgYjKl/p6bRPPlG3DyIiolrEYETle/RR5XXbNuDECXV7ISIiqiUMRlS+5s2V02kiwJo1andDRERUKxiMqGJDhiivycnq9kFERFRLGIyoYo8+Cmg0ytVpublqd0NERFTjGIyoYiEhV272+PHH6vZCRERUCxiMqHKlp9M++kjdPoiIiGoBgxFV7pFHAK0W+OEH4Kef1O6GiIioRjEYUeUaNwbuuUeZ51EjIiJycwxGdH2DByuvvDqNiIjcHIMRXd9DDwE+PsCBA8pERETkphiM6PoaNABiYpR5nk4jIiI3xmBEVXP1zR4tFsBqVab8fHX7IiIiqkYMRlQ1AwYAfn7KlWkNGgAGgzIFBgKxsWp3R0REVC1uKBglJSUhLCwMfn5+iIyMxLZt2yqtT0lJQUREBHQ6HSIiIrB27VqH9SKCWbNmITQ0FP7+/ujduzcOXDOW5ezZszCZTDAYDDAYDDCZTDh37pxDTWZmJqKiouDv74+mTZti9uzZEBGHmtdffx1t27aFv78/mjVrhokTJ6KgoOBGvgbPotcDY8aUv271auD48drth4iIqCaIk5KTk8XHx0eWLVsmWVlZMmHCBAkICJCjR4+WW5+WliZarVbmzp0r2dnZMnfuXPH29pYdO3bYaxISEkSv10tKSopkZmbK4MGDJSQkRKxWq70mJiZG2rdvL2lpaZKWlibt27eX/v3729dbLBYJDg6WIUOGSGZmpqSkpIher5fExER7zQcffCA6nU5WrVolOTk58uWXX0pISIjExcVV+fNbLBYBIBaLxZmvzX0UFooUFFyZevUSAUTmzVO7MyIiogpV9ffb6WDUpUsXGTVqlMOydu3ayZQpU8qtHzRokMTExDgsi46OliFDhoiIiM1mE6PRKAkJCfb1BQUFYjAYZOnSpSIikpWVJQAcwpTZbBYAcvDgQRERSUpKEoPBIAUFBfaa+Ph4CQ0NFZvNJiIiY8eOlbvuusuhl0mTJsmdd95Z5c/v8cHoWsuWKcGofXuRku+ZiIjI1VT199upU2lFRUXYvXs3+vXr57C8X79+SEtLK/c9ZrO5TH10dLS9PicnB3l5eQ41Op0OUVFR9hqz2QyDwYCuXbvaa7p16waDweBQExUVBZ1O57CfEydOILfkAah33nkndu/ejZ07dwIAjhw5gg0bNuD+++935mugqz36KODrC+zfD+zbp3Y3REREf4lTwej06dMoLi5GcHCww/Lg4GDk5eWV+568vLxK60tfr1cTFBRUZttBQUEONeVt4+p9DBkyBHPmzMGdd94JHx8ftG7dGn369MGUKVMq/MyFhYWwWq0OE12lQQNlYDYAfPCBur0QERH9RTc0+Fqj0Tj8WUTKLHO2/no15W3/ejVSMvC6dPm3336Ll19+GUlJSfjhhx+QmpqKdevWYc6cORX2Hh8fbx/wbTAY0KxZswprPdbw4crrhx8CxcXq9kJERPQXOBWMGjduDK1WW+bo0MmTJ8scrSllNBorrTcajQBw3Zrff/+9zLZPnTrlUFPeNoArR45mzJgBk8mEp59+Gh06dMBDDz2EuXPnIj4+Hjabrdz+p06dCovFYp+O8+qrsu69F2jYEDhxAvj2W7W7ISIiumFOBSNfX19ERkZi8+bNDss3b96MHj16lPue7t27l6nftGmTvT4sLAxGo9GhpqioCFu2bLHXdO/eHRaLxT42CADS09NhsVgcarZu3YqioiKH/YSGhqJly5YAgAsXLsDLy/Eja7VaiDIIvdz+dTodAgMDHSa6hk4HDBqkzPN0GhER1WXOjuouvVx/+fLlkpWVJXFxcRIQECC5ubkiImIymRyuUNu+fbtotVpJSEiQ7OxsSUhIKPdyfYPBIKmpqZKZmSlDhw4t93L9jh07itlsFrPZLB06dHC4XP/cuXMSHBwsQ4cOlczMTElNTZXAwECHy/Vnzpwper1eVq9eLUeOHJFNmzZJ69atZdCgQVX+/LwqrQLbtilXp+n1In/+qXY3REREDmrscn0RkcWLF0uLFi3E19dXOnXqJFu2bLGvi4qKkpEjRzrUr1mzRtq2bSs+Pj7Srl07SUlJcVhvs9lk5syZYjQaRafTSa9evSQzM9Oh5syZMxIbGyt6vV70er3ExsbK2bNnHWr27dsnPXv2FJ1OJ0ajUWbNmmW/VF9E5NKlSzJr1ixp3bq1+Pn5SbNmzWTMmDFltlMZBqMKFBeLtGyphKPkZLW7ISIiclDV32+NSAXnkKhcVqsVBoMBFouFp9WuNX068PLLQP/+wBdfqN0NERGRXVV/v/msNKo+pc9M27gROHVK3V6IiIhuAIMRVZ/wcCAyErh8GUhOVrsbIiIipzEYUfUaMUJ5XblS1TaIiIhuBIMRVa9hwwAfH+CHH/iIECIiqnMYjKh6NW585REhK1ao2wsREZGTGIyo+j3xhPL6wQfAVTfcJCIicnUMRlT9YmIAoxE4fRpYv17tboiIiKqMwYiqn7c3YDIp8zydRkREdQiDEdWM0tNpGzYA5TwAmIiIyBUxGFHNCA8HunYFiov5YFkiIqozGIyo5pQeNVqxAuCTZ4iIqA5gMKKaM2QI4OcHHDgA7NqldjdERETXxWBENcdgAB5+WJnnIGwiIqoDGIyoZpWeTlu9Grh4Ud1eiIiIroPBiGrWXXcBLVsC584Bn3yidjdERESVYjCimuXlBTz9tDL/1lvq9kJERHQdDEZU8554AtBqge++A7Ky1O6GiIioQgxGVPNCQ688WHbZMnV7ISIiqgSDEdWOZ59VXt99FygoULcXIiKiCjAYUe3o1w9o3hw4exZISVG7GyIionIxGFHt0Go5CJuIiFwegxHVniefVK5S27oVOHhQ7W6IiIjKYDCi2tO0KdC/vzLPQdhEROSCGIyodnEQNhERuTAGI6pdMTHAzTcDZ84ol/EHBV2Z+vcHLl9Wu0MiIvJgDEZUu7RaIC5OmT97Fjh16sq0fj3wxRfq9kdERB6NwYhq36RJwOHDQGbmlWnsWGXd4sXq9kZERB5NIyKidhN1idVqhcFggMViQWBgoNrtuI+jR4FWrQCbTXlsSHi42h0REZEbqervN48YkWto0eLKY0OSktTthYiIPBaDEbmO0tNp774L5Oer2wsREXkkBiNyHXffDbRtq4Si999XuxsiIvJADEbkOry8gDFjlPnFiwEOfyMiolrGYESuZeRIICBAGYC9ZYva3RARkYdhMCLXYjAAJpMyv2iRur0QEZHHYTAi11M6CPvTT4FfflG3FyIi8igMRuR62rcHevUCiouBN99UuxsiIvIgDEbkmsaNU16XLgUuXlS3FyIi8hgMRuSaHnxQuenj6dPAqlVqd0NERB6CwYhck7f3laNGr7/OS/eJiKhWMBiR63r6aaB+feDAAWDzZrW7ISIiD8BgRK7LYACefFKZf+01dXshIiKPwGBErm38eECjATZuBLKz1e6GiIjcHIMRubbWrYGBA5X5119XtxciInJ7DEbk+iZOVF7fe0+5So2IiKiGMBiR6+vZE+jUCSgo4A0fiYioRjEYkevTaK4cNVq8GCgqUrcfIiJyWwxGVDcMGgSEhgK//QZ8+KHa3RARkZtiMKK6wdcXmDBBmZ8/H7DZ1O2HiIjcEoMR1R3PPQcEBiqX7a9bp3Y3RETkhhiMqO4wGIDRo5X5efPU7YWIiNwSgxHVLRMmKKfV0tKA775TuxsiInIzNxSMkpKSEBYWBj8/P0RGRmLbtm2V1qekpCAiIgI6nQ4RERFYu3atw3oRwaxZsxAaGgp/f3/07t0bBw4ccKg5e/YsTCYTDAYDDAYDTCYTzp0751CTmZmJqKgo+Pv7o2nTppg9ezbkmoePnjt3DmPHjkVISAj8/PwQHh6ODRs23MjXQGoICQFGjlTmedSIiIiqmdPB6KOPPkJcXBymTZuGjIwM9OzZE/feey+OHTtWbr3ZbMbgwYNhMpmwd+9emEwmDBo0COnp6faa+fPnY8GCBVi0aBG+//57GI1G9O3bF/n5+faaYcOGYc+ePdi4cSM2btyIPXv2wGQy2ddbrVb07dsXoaGh+P7777Fw4UIkJiZiwYIF9pqioiL07dsXubm5+OSTT3Do0CEsW7YMTZs2dfZrIDX985/KJfzr1gH796vdDRERuRNxUpcuXWTUqFEOy9q1aydTpkwpt37QoEESExPjsCw6OlqGDBkiIiI2m02MRqMkJCTY1xcUFIjBYJClS5eKiEhWVpYAkB07dthrzGazAJCDBw+KiEhSUpIYDAYpKCiw18THx0toaKjYbDYREVmyZIm0atVKioqKnP3YdhaLRQCIxWK54W1QNXjkERFAZMQItTshIqI6oKq/304dMSoqKsLu3bvRr18/h+X9+vVDWlpaue8xm81l6qOjo+31OTk5yMvLc6jR6XSIioqy15jNZhgMBnTt2tVe061bNxgMBoeaqKgo6HQ6h/2cOHECubm5AIDPP/8c3bt3x9ixYxEcHIz27dtj7ty5KC4uduZrIFcwebLy+uGHQAVHK4mIiJzlVDA6ffo0iouLERwc7LA8ODgYeXl55b4nLy+v0vrS1+vVBAUFldl2UFCQQ01527h6H0eOHMEnn3yC4uJibNiwAdOnT8err76Kl19+ucLPXFhYCKvV6jCRC/i//wPuugu4fBm46nQpERHRX3FDg681Go3Dn0WkzDJn669XU972r1cjJQOvS5fbbDYEBQXhrbfeQmRkJIYMGYJp06ZhyZIlFfYeHx9vH/BtMBjQrFmzCmuplpUeNXrrLeDkSXV7ISIit+BUMGrcuDG0Wm2Zo0MnT54sc7SmlNForLTeaDQCwHVrfv/99zLbPnXqlENNedsArhw5CgkJwa233gqtVmuvCQ8PR15eHooqeP7W1KlTYbFY7NPx48fLrSMV9O2rHDm6eJFHjYiIqFo4FYx8fX0RGRmJzZs3OyzfvHkzevToUe57unfvXqZ+06ZN9vqwsDAYjUaHmqKiImzZssVe0717d1gsFuzcudNek56eDovF4lCzdetWh4CzadMmhIaGomXLlgCAO+64A4cPH4btqsdJ/PjjjwgJCYGvr2+5/et0OgQGBjpM5CI0GuDFF5X5RYuAM2fU7YeIiOo+Z0d1Jycni4+PjyxfvlyysrIkLi5OAgICJDc3V0RETCaTwxVq27dvF61WKwkJCZKdnS0JCQni7e3tcIVZQkKCGAwGSU1NlczMTBk6dKiEhISI1Wq118TExEjHjh3FbDaL2WyWDh06SP/+/e3rz507J8HBwTJ06FDJzMyU1NRUCQwMlMTERHvNsWPHpH79+vL888/LoUOHZN26dRIUFCQvvfRSlT8/r0pzMTabyO23K1eoTZ+udjdEROSiqvr77XQwEhFZvHixtGjRQnx9faVTp06yZcsW+7qoqCgZOXKkQ/2aNWukbdu24uPjI+3atZOUlBSH9TabTWbOnClGo1F0Op306tVLMjMzHWrOnDkjsbGxotfrRa/XS2xsrJw9e9ahZt++fdKzZ0/R6XRiNBpl1qxZ9kv1S6WlpUnXrl1Fp9NJq1at5OWXX5bLly9X+bMzGLmglBQlGAUGilzzb4KIiEik6r/fGpFrbg1NlbJarTAYDLBYLDyt5ipsNuC225SbPc6eDcyYoXZHRETkYqr6+81npVHd5+UFTJumzL/2GsBbKhAR0Q1iMCL38NhjQNu2wNmzQFKS2t0QEVEdxWBE7kGrvXLU6NVXgT//VLcfIiKqkxiMyH0MHQq0bg2cPg0sXqx2N0REVAcxGJH78Pa+MvB6/nyONSIiIqcxGJF7iY1VxhqdOQP85z9qd0NERHUMgxG5F29v4N//VuYTE4E//lC3HyIiqlMYjMj9PPYY0KGDcirt1VfV7oaIiOoQBiNyP15eyo0eAeV02qlT6vZDRER1BoMRuaeBA4HISOWy/Xnz1O6GiIjqCAYjck8aDTBnjjK/eDFw4oS6/RARUZ3AYETuKyYG6NEDKCgAXn5Z7W6IiKgOYDAi96XRAC+9pMwvWwb8/LO6/RARkctjMCL31qcPEB0NXLoETJ+udjdEROTiGIzI/SUkKEePkpOBXbvU7oaIiFwYgxG5v7//XbkjNgBMngyIqNsPERG5LAYj8gxz5gC+vsDXXwObNqndDRERuSgGI/IMLVsCzz+vzE+eDNhsqrZDRESuicGIPMe//gUYDMDevcCHH6rdDRERuSAGI/IcjRoBU6Yo89OnK/c3IiIiugqDEXmWCROApk2Bo0eBhQvV7oaIiFwMgxF5Fn//Kzd9fOkl4ORJdfshIiKXwmBEnmfECKBTJ8BqBV58Ue1uiIjIhTAYkefx8gJef12ZX7YM2LdP3X6IiMhlMBiRZ+rZE3jsMeWy/UmTeNNHIiICwGBEnmzePECnA776CvjiC7W7ISIiF8BgRJ4rLEw5WgQA//gHUFSkbj9ERKQ6jQjPITjDarXCYDDAYrEgMDBQ7Xbor8rPB269FcjLA0aNArp2vbLO3x948EHlqBIREdVpVf39ZjByEoORG1qxAnjyyfLXjRkDLF5cu/0QEVG1q+rvt3ct9kTkmkaOBLKygAMHriy7fBnYvBlYsgR46inl8n4iInJ7DEZEXl7AK6+UXT5sGLB6NTB2LLB9u1JHRERujf9LT1SRxESgfn1gxw5g5Uq1uyEiolrAYERUkdBQYNYsZX7yZOCPP1Rth4iIah6DEVFlxo8HIiKA06eBGTPU7oaIiGoYgxFRZXx8rlyVtmQJsHu3uv0QEVGNYjAiup7evYGhQ5XHhowdqzxGhA7z+KUAACAASURBVIiI3BKDEVFVJCYCej2Qng68+aba3RARUQ1hMCKqitBQ4OWXlfkpU4Bff1W3HyIiqhEMRkRVNWYM0KULYLUqg7KJiMjtMBgRVZVWCyxbBnh7A6mpwGefqd0RERFVMwYjImd07Aj885/K/NixytEjIiJyGwxGRM568UWgdWtlnNH06Wp3Q0RE1YjBiMhZ/v7A0qXK/KJFypVqRETkFhiMiG7EPfcAJpNyb6OnngIKC9XuiIiIqgGDEdGNWrAACAoCDhwAZs9WuxsiIqoGDEZEN6pxY+UxIQAwbx6wa5e6/RAR0V/GYET0Vzz8MDBkCFBcDDz+OE+pERHVcQxGRH/VwoVAkybKKbU5c9TuhoiI/gIGI6K/6upTagkJwO7d6vZDREQ3jMGIqDo88ggweDBPqRER1XEMRkTVpfSU2v79wIwZandDREQ34IaCUVJSEsLCwuDn54fIyEhs27at0vqUlBRERERAp9MhIiICa9eudVgvIpg1axZCQ0Ph7++P3r1748CBAw41Z8+ehclkgsFggMFggMlkwrlz5xxqMjMzERUVBX9/fzRt2hSzZ8+GiJTbU3JyMjQaDR588MEb+AaIytGkifIsNQBITAS+/VbVdoiIyHlOB6OPPvoIcXFxmDZtGjIyMtCzZ0/ce++9OHbsWLn1ZrMZgwcPhslkwt69e2EymTBo0CCkX3W34Pnz52PBggVYtGgRvv/+exiNRvTt2xf5+fn2mmHDhmHPnj3YuHEjNm7ciD179sBkMtnXW61W9O3bF6Ghofj++++xcOFCJCYmYsGCBWV6Onr0KP75z3+iZ8+ezn58osoNHAg8/bRy48cRI4BrwjsREbk4cVKXLl1k1KhRDsvatWsnU6ZMKbd+0KBBEhMT47AsOjpahgwZIiIiNptNjEajJCQk2NcXFBSIwWCQpUuXiohIVlaWAJAdO3bYa8xmswCQgwcPiohIUlKSGAwGKSgosNfEx8dLaGio2Gw2+7LLly/LHXfcIW+//baMHDlSBg4c6NTnt1gsAkAsFotT7yMPkp8v0rq1CCASG6t2N0REJFX//XbqiFFRURF2796Nfv36OSzv168f0tLSyn2P2WwuUx8dHW2vz8nJQV5enkONTqdDVFSUvcZsNsNgMKBr1672mm7dusFgMDjUREVFQafTOeznxIkTyM3NtS+bPXs2mjRpgqeeesqZj05UdfXrAx98AGi1wKpVQHKy2h0REVEVORWMTp8+jeLiYgQHBzssDw4ORl5eXrnvycvLq7S+9PV6NUFBQWW2HRQU5FBT3jau3sf27duxfPlyLCsdB1IFhYWFsFqtDhPRdXXrBkybpsyPHg0cP65uP0REVCU3NPhao9E4/FlEyixztv56NeVt/3o1UjLwWqPRID8/H8OHD8eyZcvQuHHjCnu9Vnx8vH3At8FgQLNmzar8XvJw06cDXboo44xGjFAu5SciIpfmVDBq3LgxtFptmaNDJ0+eLHO0ppTRaKy03mg0AsB1a37//fcy2z516pRDTXnbAJQjRz///DNyc3MxYMAAeHt7w9vbG++99x4+//xzeHt74+effy63/6lTp8Jisdin4/x//lRVPj7KKbWAAOUKtblz1e6IiIiuw6lg5Ovri8jISGzevNlh+ebNm9GjR49y39O9e/cy9Zs2bbLXh4WFwWg0OtQUFRVhy5Yt9pru3bvDYrFg586d9pr09HRYLBaHmq1bt6KoqMhhP6GhoWjZsiXatWuHzMxM7Nmzxz498MAD6NOnD/bs2VPhkSCdTofAwECHiajK2rS5clfsWbOArVtVbYeIiK7D2VHdycnJ4uPjI8uXL5esrCyJi4uTgIAAyc3NFRERk8nkcIXa9u3bRavVSkJCgmRnZ0tCQoJ4e3s7XGGWkJAgBoNBUlNTJTMzU4YOHSohISFitVrtNTExMdKxY0cxm81iNpulQ4cO0r9/f/v6c+fOSXBwsAwdOlQyMzMlNTVVAgMDJTExscLPwqvSqNaMHKlcpda0qcipU2p3Q0Tkcar6++10MBIRWbx4sbRo0UJ8fX2lU6dOsmXLFvu6qKgoGTlypEP9mjVrpG3btuLj4yPt2rWTlJQUh/U2m01mzpwpRqNRdDqd9OrVSzIzMx1qzpw5I7GxsaLX60Wv10tsbKycPXvWoWbfvn3Ss2dP0el0YjQaZdasWQ6X6l+LwYhqTX6+SNu2Sjjq31+kkn+XRERU/ar6+60RqeDW0FQuq9UKg8EAi8XC02rknL17ga5dleeovfYaEBendkdERB6jqr/ffFYaUW257Tag9E7sL7wAXDVmjoiIXAODEVFtGj0aePhh4NIl4NFHgdOn1e6IiIiuwmBEVJs0GuCdd5Sr1Y4fB4YN4/2NiIhcCIMRUW0zGICUFMDfH9i8Gfj3v9XuiIiISjAYEamhQweg9NE0c+YA69er2w8REQEAvNVugMhjxcYCaWlAUhIwfDjw6adAgwaVvyc8HPD1rZ3+iIg8EIMRkZoWLAB27wbS04Heva9ff8stwPbtQDkPVSYior+OwYhITTodsGYNYDIBhw5VXmu1AocPK1ez/e9/PHJERFQDGIyI1NasmfKQ2evJzlZuELltGzB+PLB0aY23RkTkaTj4mqiuCA8HVq9WLvl/880rD6clIqJqw2BEVJfcfz8wd64yP348sGWLuv0QEbkZBiOiumbyZGDoUODyZeCRR4CcHLU7IiJyGwxGRHWNRgO8/TbQqRNw5gzQvz9w7pzaXRERuQUGI6K6qF494LPPgNBQICtLuVLt0iW1uyIiqvMYjIjqqptvBtatAwICgK++Uh5QK6J2V0REdRqDEVFddvvtwEcfAV5ewPLlwLx5andERFSnMRgR1XX33w+88YYyP3Uq8PHH6vZDRFSHMRgRuYOxY4G4OGV+xAhexk9EdIMYjIjcRWIi8OCDQGEhMHAgsG+f2h0REdU5DEZE7kKrBT78ELjzTsBiAWJigNxctbsiIqpTGIyI3Im/P/D550D79sBvvwHR0cCpU2p3RURUZzAYEbmbhg2BjRuB5s2BH39UbgB5/rzaXRER1QkMRkTuqGlT4MsvgZtuAnbuBB56CCgoULsrIiKXx2BE5K7atQM2bFBuAPm//wGDB/Pu2ERE18FgROTOunYFvvgC8PNTxh6NGAEUF6vdFRGRy2IwInJ3ffoAn3wCeHsDycnAc88BNpvaXRERuSQGIyJPcP/9yqX8pY8OmTiRz1UjIioHgxGRp3jsMeCdd5T5N94A/vlPhiMiomswGBF5kpEjgaVLlfkFC4B//IPhiIjoKgxGRJ7mueeuhKPXXgMmTWI4IiIqwWBE5Imeew54801l/vXXGY6IiEowGBF5qmefdQxHEybwajUi8ngMRkSe7NlngbfeUuYXLgSefpr3OSIij8ZgROTpnnkGeO895VL+FSuAoUOBoiK1uyIiUgWDEREBJhOwZg3g46O8PvwwcPGi2l0REdU6BiMiUjz8sPL4EH9/YP164L77AKtV7a6IiGoVgxERXREdDWzcCOj1wLffAr17A3l5andFRFRrGIyIyFGvXsA33wBNmgAZGUCPHsBPP6ndFRFRrWAwIqKyIiOBtDSgVSsgJ0cJR99/r3ZXREQ1jsGIiMp3yy1KOOrUCTh9GujTRznNRkTkxhiMiKhiwcHKWKN77gH+/BPo3//K40SIiNwQgxERVU6vV65SGzFCufnj6NHKw2d5I0gickMMRkR0fb6+wMqVwJw5yp8XLAAeeUQ5ikRE5EYYjIioajQaYPp04MMPAZ0O+Owz5Qq2X39VuzMiomrDYEREzhk6FPjqK6BxY+CHH4DOnQGzWe2uiIiqBYMRETnvjjuA9HSgfXvlBpC9ewPvvKN2V0REfxmDERHdmFatlCNFDz2kPHT2qaeA8eOBS5fU7oyI6IZpRETUbqIusVqtMBgMsFgsCAwMLLfGZrOhiE8ndws+Pj7QarVqt+HabDbgpZeAmTOVP/fuDSQnK5f6ExG5iKr8fgOAdy325BGKioqQk5MDm82mditUTRo0aACj0QiNRqN2K67Jywt48UWgY0fAZFLue3T77cDHHwN33ql2d0RETmEwqkYigt9++w1arRbNmjWDlxfPVNZlIoILFy7g5MmTAICQkBCVO3JxDz4I7NypXMafna0cOXrlFSAuTrmijYioDmAwqkaXL1/GhQsXEBoainr16qndDlUDf39/AMDJkycRFBTE02rXEx6uhKNnnwVWrwYmTQK2bVNC0tX+/nflUn8iIhfDYFSNikvuBOzr66tyJ1SdSkPupUuXGIyqon59YNUq5cGzkyYBa9cq07VGjwZefRUoCZ9ERK7ghs71JCUlISwsDH5+foiMjMS2bdsqrU9JSUFERAR0Oh0iIiKw9pr/kRQRzJo1C6GhofD390fv3r1x4MABh5qzZ8/CZDLBYDDAYDDAZDLh3LlzDjWZmZmIioqCv78/mjZtitmzZ+PqseXLli1Dz5490bBhQzRs2BD33HMPdu7ceSNfQaU4FsW98O/zBmg0wPPPA999BzzxBDBkyJVpwAClZskSoGtX5bQbEZGrECclJyeLj4+PLFu2TLKysmTChAkSEBAgR48eLbc+LS1NtFqtzJ07V7Kzs2Xu3Lni7e0tO3bssNckJCSIXq+XlJQUyczMlMGDB0tISIhYrVZ7TUxMjLRv317S0tIkLS1N2rdvL/3797evt1gsEhwcLEOGDJHMzExJSUkRvV4viYmJ9pphw4bJ4sWLJSMjQ7Kzs+WJJ54Qg8Egv/zyS5U/v8ViEQBisVjKrLt48aJkZWXJxYsXq7w9cn38e60BX34pEhQkAoj4+4u8/baIzaZ2V0Tkxir7/b6a08GoS5cuMmrUKIdl7dq1kylTppRbP2jQIImJiXFYFh0dLUOGDBEREZvNJkajURISEuzrCwoKxGAwyNKlS0VEJCsrSwA4hCmz2SwA5ODBgyIikpSUJAaDQQoKCuw18fHxEhoaKrYK/gf38uXLotfr5d13363qx3fLYBQVFSUTJkxQbf8jR46UgQMHukw/16qrf68u77ffRPr2VcIRIPLooyKnT6vdFRG5qaoGI6dOpRUVFWH37t3o16+fw/J+/fohLS2t3PeYzeYy9dHR0fb6nJwc5OXlOdTodDpERUXZa8xmMwwGA7p27Wqv6datGwwGg0NNVFQUdDqdw35OnDiB3Nzccnu7cOECLl26hJtuuqnCz1xYWAir1eowUc1KTU3FnNKHlZL7MhqBjRuBhATA2xv45BOgQwfgyy/V7oyIPJhTwej06dMoLi5G8DU3bgsODkZeXl6578nLy6u0vvT1ejVBQUFlth0UFORQU942rt7HtaZMmYKmTZvinnvuKXc9AMTHx9vHNRkMBjRr1qzCWqoeN910E/R6vdptUG3w8gImTwZ27ADatQN++w2IiQHGjQMuXFC7OyLyQDc0+PrawagiUukA1arUX6+mvO1fr0ZKBl6X99758+dj9erVSE1NhZ+fX4W9T506FRaLxT4dP368wtq67PLly3j++efRoEEDNGrUCNOnT7d/fx988AE6d+4MvV4Po9GIYcOG2e/tAygD42NjY9GkSRP4+/ujTZs2WLFihX39r7/+isGDB6Nhw4Zo1KgRBg4cWOFRPADo3bs34uLi7H9u2bIl5s6diyeffBJ6vR7NmzfHW2+95fAeZ/dBLiYyEti9WwlEALBoEdCpEx9OS0S1zqlg1LhxY2i12jJHYE6ePFnmaE0po9FYab3RaARQ9qjOtTW///57mW2fOnXKoaa8bQBlj0YlJiZi7ty52LRpEzp27FjxB4ZyWi8wMNBhqioR4M8/1ZmcfdDLu+++C29vb6Snp+ONN97Aa6+9hrfffhuAcgp1zpw52Lt3Lz799FPk5OTg8ccft793xowZyMrKwn//+19kZ2djyZIlaNy4MQDldGWfPn1Qv359bN26Fd999x3q16+PmJgYpx6b8uqrr6Jz587IyMjAmDFjMHr0aBw8eLBa90Eqq1cPeOMN5VRaaChw6JDysNp//INHj4io9jg7eKlLly4yevRoh2Xh4eGVDr6+9957HZbFxMSUGXw9b948+/rCwsJyB1+np6fba3bs2FFm8HWDBg2ksLDQXpOQkFBm8PX8+fMlMDBQzGazsx9dRJwbfH3+/JVxpbU9nT9f9c8UFRUl4eHhDt/T5MmTJTw8vNz6nTt3CgDJz88XEZEBAwbIE088UW7t8uXLpW3btg7bLiwsFH9/f/nyyy9F5PqDr1u0aCHDhw+3/9lms0lQUJAsWbKkyvv4Kzj4WgV//CEycuSVf9Bt2ohs26Z2V0RUh9XI4GsAmDRpEt5++2288847yM7OxsSJE3Hs2DGMGjUKADBixAhMnTrVXj9hwgRs2rQJ8+bNw8GDBzFv3jz873//s58q0Wg0iIuLw9y5c7F27Vrs378fjz/+OOrVq4dhw4YBAMLDwxETE4NnnnkGO3bswI4dO/DMM8+gf//+aNu2LQBg2LBh0Ol0ePzxx7F//36sXbsWc+fOxaRJk+yn0ubPn4/p06fjnXfeQcuWLZGXl4e8vDycP3/+hoOlu+jWrZvDKcfu3bvjp59+QnFxMTIyMjBw4EC0aNECer0evUvuYnzs2DEAwOjRo5GcnIy///3veOGFFxwG4u/evRuHDx+GXq9H/fr1Ub9+fdx0000oKCjAzz//XOX+rj6yp9FoYDQa7UcEq2sf5EIaNgRWrgTWrQOaNgV++km5U/a4cQAvgCCiGuT0na8HDx6MM2fOYPbs2fjtt9/Qvn17bNiwAS1atACg/Fhe/YywHj16IDk5GdOnT8eMGTPQunVrfPTRRw5XmL3wwgu4ePEixowZg7Nnz6Jr167YtGmTwwDcVatWYfz48far1x544AEsWrTIvt5gMGDz5s0YO3YsOnfujIYNG2LSpEmYNGmSvSYpKQlFRUV49NFHHT7TzJkzMWvWLGe/iuuqVw9QK3NV1xNJCgoK0K9fP/Tr1w8ffPABmjRpgmPHjiE6Otp+muree+/F0aNHsX79evzvf//D3XffjbFjxyIxMRE2mw2RkZFYtWpVmW03adKkyn34+Pg4/Fmj0dgf1Ftd+yAXdP/9wP79yum0d95Rxh6lpiqvDz2kdndE5I5q6QiW23DX+xhde9psypQpEh4eLrt27RIAcuzYMfu6999/XwBIRkZGudtbunSp6PV6ERF56623pGHDhpUeuqzKqbTXXnvN4T233XabzJw5s8r7+Cvq6t+r29m8WaR16yun1wYOFLnq3yURUWVq7FQauafjx49j0qRJOHToEFavXo2FCxdiwoQJaN68OXx9fbFw4UIcOXIEn3/+eZl7DL344ov47LPPcPjwYRw4cADr1q1DeHg4ACA2NhaNGzfGwIEDsW3bNuTk5GDLli2YMGECfvnll2rpvTb2QS7gnnuAzExg2jTlvkeffaY8tPaVVwAOsieiasJgRACUsWEXL15Ely5dMHbsWIwbNw7PPvssmjRpgpUrV2LNmjWIiIhAQkICEhMTHd7r6+uLqVOnomPHjujVqxe0Wi2Sk5MBKA9g3bp1K5o3b46HH34Y4eHhePLJJ3Hx4kWnrvCrTG3sg1yEvz/w0kvAnj3KFWt//gm88AJw223AV1+p3R0RuQGNiLMXdns2q9UKg8EAi8VS5ke3oKAAOTk59gfsknvg36uLstmA995TgtGpU8qyxx4DEhOB5s3V7Y2IXE5lv99X4xEjIqqbvLyAxx8HfvwRGD9e+fOaNcodtF98Ub0rH4ioTmMwIqK6rUED4D//ATIylEv6L14E5swB2rYF3n1XObJERFRFDEZE5B46dgS+/VZ5GG1YGHDihHJEqUsX4Jtv1O6OiOoIBiMich8aDfDII0B2NjB/PqDXK89gu+su4N57gb171e6QiFwcgxERuR+dDvh//w84fBh4/nnl8v6NG4HbbwdMJiAnR+0OichFMRgRkfsKCgIWLgQOHgSGDFFuDfnBB8CttwKjRwO8zxURXYPBiIjcX+vWwOrVwK5dQN++wOXLwNKlwC23ABMmAHl5andIRC6CwYiIPEdkJLBpE7Bli3IFW2Eh8MYbwM03A/XrO06RkUByMlBcrHbXRFSLGIyIyPP06qVcwbZ5M9CtmxJ+/vzTcfrhB2DoUOBvf1NuJHn5stpdE1EtYDAil/Xtt99Co9Hg3LlzardC7kijUZ6/lpamjDU6cuTK9OOPwOzZQMOGwKFDwMiRyrikpUuV+yQRkdtiMCK7vLw8TJgwAbfccgv8/PwQHByMO++8E0uXLsWFCxfUbq9KNBoNPv3003LXlQat0qlRo0a46667sH379lruklyKRgM0barc+6h0atMGmDEDOHoUSEgAmjRRrmQbPRpo0UJ5Xtsff6jdORHVAG+1GyDXcOTIEdxxxx1o0KAB5s6diw4dOuDy5cv48ccf8c477yA0NBQPPPBAmfddunQJPj4+KnR84w4dOoTAwECcOnUKL730Eu6//378+OOPCAoKUrs1cjV6PTB5MjBuHLB8OfDqq0pYmjFDCUz336/cGqCUlxdw993A4MGAr696fRPRDeMRIwIAjBkzBt7e3ti1axcGDRqE8PBwdOjQAY888gjWr1+PAQMGAFCOyCxduhQDBw5EQEAAXnrpJQBAVlYW7rvvPtSvXx/BwcEwmUw4ffq0ffsigvnz56NVq1bw9/fHbbfdhk8++cShhw0bNuDWW2+Fv78/+vTpg9zcXPu6P//8E4GBgWXe88UXXyAgIAD5+flV/qxBQUEwGo3o0KEDpk+fDovFgvT0dGe/MvIk9eop4ejwYeDDD4HbblPGIX38MfD++1emd98FRoxQjirNmXPl4bZEVGfwiFFNEgHUOgVVr55yiqAKzpw5g02bNmHu3LkICAgot0Zz1bZmzpyJ+Ph4vPbaa9Bqtfjtt98QFRWFZ555BgsWLMDFixcxefJkDBo0CF9//TUAYPr06UhNTcWSJUvQpk0bbN26FcOHD0eTJk0QFRWF48eP4+GHH8aoUaMwevRo7Nq1C//4xz/s+wwICMCQIUOwYsUKPProo/blpX/W6/VOf0UXLlzAihUrAKDOHfUilXh7KwOyhwwBvv4a2LPHcf0ffwArVyqPI3nxReDll4HYWOUmk7ffrkrLROQkIadYLBYBIBaLpcy6ixcvSlZWlly8eFFZcP68iBKPan86f77Kn2nHjh0CQFJTUx2WN2rUSAICAiQgIEBeeOEFEREBIHFxcQ51M2bMkH79+jksO378uACQQ4cOyfnz58XPz0/S0tIcap566ikZOnSoiIhMnTpVwsPDxWaz2ddPnjxZAMjZs2dFRCQ9PV20Wq38+uuvIiJy6tQp8fHxkW+//db+HgCydu3acj/nN998IwDsn0mj0QgAiYyMlKKiogq/nzJ/r0SVKSoSWbVKpHNnx/8mu3cX+eADkYICtTsk8kiV/X5fjUeMyE5zzRGmnTt3wmazITY2FoWFhfblnTt3dqjbvXs3vvnmG9SvX7/MNn/++WdYLBYUFBSgb9++DuuKiopwe8n/i87Ozka3bt0ceujevbtDfZcuXfC3v/0N7733HqZMmYL3338fzZs3R69evZz6nNu2bUNAQAAyMjIwefJkrFy5kkeMqPr4+ADDhilHltLSgEWLlAfbms3KNHGi8sDb6tCqFfDEE8otB6p4hJiIKsdgVJPq1QPOn1dv31V0yy23QKPR4ODBgw7LW7VqBQDw9/d3WH7t6TabzYYBAwZg3rx5ZbYdEhKC/fv3AwDWr1+Ppk2bOqzXlQxcFZEq9fr0009j0aJFmDJlClasWIEnnniiTKC7nrCwMDRo0AC33norCgoK8NBDD2H//v32XoiqhUYD3HGHMr32GrBsGfDmm8CvvwJffVU9+/jqK2W77dsDzzyjPAeuYcPq2TaRh2IwqkkaDVDBmB1X0qhRI/Tt2xeLFi3CuHHjKhxnVJFOnTohJSUFLVu2hLd32X9SERER0Ol0OHbsGKKiosrdRkRERJnL7Hfs2FGmbvjw4XjhhRfwxhtv4MCBAxg5cqRTvV7LZDJh9uzZSEpKwsSJE//StogqZDQqV7JNnaqMTTpz5q9vs7hYuUHlxx8D+/crjzaZPBl46CHlKNJddwFa7V/fD5GnqZ0ze+7DqTFGdcjhw4clODhY2rVrJ8nJyZKVlSUHDx6U999/X4KDg2XSpEkiUv4Ynl9//VWaNGkijz76qKSnp8vPP/8sX375pTzxxBNy+fJlERGZNm2aNGrUSFauXCmHDx+WH374QRYtWiQrV64UEZGjR4+Kr6+vTJw4UQ4ePCirVq0So9HoMMao1LBhw8TX11diYmLKfA4AsmDBAsnIyHCY8vPz7WOMrt3eG2+8IUFBQfLnn3+W+93U5b9X8gB//CGycKFIx46OY5puvllk2jSRQ4fU7pDIJVR1jBGDkZPcNRiJiJw4cUKef/55CQsLEx8fH6lfv7506dJFXnnlFXtoKC8YiYj8+OOP8tBDD0mDBg3E399f2rVrJ3FxcfbB1DabTf7zn/9I27ZtxcfHR5o0aSLR0dGyZcsW+za++OILueWWW0Sn00nPnj3lnXfeKTfIfPXVVwJAPv744zJ9ACh3+uabbyoMRufPn5eGDRvKvHnzyv1e6vrfK3kIm01k506RMWNEGjRwDEnt24u8+KJIRoZSR+SBqhqMNCJVHNxBAACr1QqDwQCLxYLAwECHdQUFBcjJyUFYWBj8/PxU6tD9rVq1ChMmTMCJEyfgWws30ePfK9U5BQXAF18AK1Yop9uufs5by5bKnb6JXNmbbyrPKaxGlf1+X41jjKjOuHDhAnJychAfH4/nnnuuVkIRUZ3k5wc89pgynT0LrFsHpKYCX34J5OYqE5Erc+KmvdWNwYjqjPnz5+Pll19Gr169MHXqVLXbIaobGjZUrlYzmZS7dX/3AcMC3gAACsZJREFUnfJK5MpuvVW1XfNUmpN4Ks3z8O+ViKjuq+qpND4rjYiIiKgEgxERERFRCQajGsCzk+7FZrOp3QIREdUSDr6uRj4+PtBoNDh16hSaNGni9KMqyLWICIqKinDq1Cl4eXnxKjgiIg/AYFSNtFotbr75Zvzyyy/I5eWwbqNevXpo3rw5vLx4gJWIyN0xGFWz+vXro02bNrh06ZLarVA10Gq18Pb25tE/IiIPwWBUA7RaLbR8eCMREVGdw3MDRERERCUYjIiIiIhKMBgRERERleAYIyeV3qPIarWq3AkRERFVVenv9vXuNchg5KT8kif+NmvWTOVOiIiIyFn5+fkwGAwVrudDZJ1ks9lw4sQJ6PX6v3QJt9VqRbNmzXD8+PFKH2ZHfx2/69rD77r28LuuPfyua09Nftcigvz8fISGhlZ6XzoeMXKSl5cXbr755mrbXmBgIP9DqyX8rmsPv+vaw++69vC7rj019V1XdqSoFAdfExEREZVgMCIiIiIqoZ01a9YstZvwVFqtFr1794a3N89o1jR+17WH33Xt4Xdde/hd1x61v2sOviYiIiIqwVNpRERERCUYjIiIiIhKMBgRERERlWAwIiIiIirBYKSCpKQkhIWFwc/PD5GRkdi2bZvaLdU58fHx+L//+z/o9XoEBQXhwQcfxKFDhxxqCgsLMW7cODRu3BgBAQF44IEH8MsvvzjUHDt2DAMGDEBAQAAaN26M8ePHo6ioqDY/Sp0SHx8PjUaDuLg4+zJ+z9Xr119/xfDhw9GoUSP8//buLSSqtg0D8O12GstvyMQZR8kMAqvJNkplWbYjI+skiBIzoyOjKU1oQwWFZHkQEUEbiuikjRFaWEQ4linhlOFojUlU5CbKyTY6FW1M5/4Pmm/9rsbvr2zU/P7nggF91zOLd90Ll48z8y6DgoIwadIkVFdXK9tJYvfu3TAajdBqtZgzZw4ePHig2kdbWxvS09Oh0+mg0+mQnp6O9vb2/j6UP1pnZyd27tyJ6OhoaLVajB49Grm5uXC5XEqNZN07FRUVWLp0KYxGI3x8fHDp0iXVdm/larfbkZSUBK1Wi4iICOTm5v7w/6D9FIp+VVBQwICAAJ44cYL19fXMysri0KFD2dTUNNBTG1SSk5N56tQp1tXVsba2likpKRw5ciQ/fPig1GRmZjIiIoIWi4U2m41z587lxIkT2dnZSZLs7OykyWTi3LlzabPZaLFYaDQaaTabB+qw/mhVVVUcNWoUY2NjmZWVpYxLzt7z9u1bRkVFcc2aNbxz5w4bGhpYWlrKJ0+eKDX5+fkMDg5mYWEh7XY7V6xYwfDwcL57906pWbRoEU0mEysrK1lZWUmTycQlS5YMxCH9sfbs2cMRI0bwypUrbGho4IULFzhs2DAePHhQqZGse+fq1avcsWMHCwsLCYAXL15UbfdGrk6nk3q9nitXrqTdbmdhYSGDg4O5f//+356/NEb9bOrUqczMzFSNxcTEcNu2bQM0o3+H1tZWAmB5eTlJsr29nQEBASwoKFBqnj9/Tl9fX167do3ktx9eX19fPn/+XKk5d+4cNRoNnU5n/x7AH+79+/ccM2YMLRYLk5KSlMZIcvaurVu3MjEx8R+3u1wuGgwG5ufnK2OfP3+mTqfjsWPHSJL19fUEwNu3bys1VquVAPjw4cO+m/wgk5KSwrVr16rGli1bxlWrVpGUrL3l+8bIW7keOXKEOp2Onz9/Vmr27dtHo9FIl8v1W3OWt9L6UUdHB6qrq7Fw4ULV+MKFC1FZWTlAs/p3cDqdAICQkBAAQHV1Nb5+/arK2mg0wmQyKVlbrVaYTCYYjUalJjk5GV++fFG9dSGA9evXIyUlBQsWLFCNS87eVVxcjPj4eCxfvhxhYWGYPHkyTpw4oWxvaGiAw+FQ5a3RaJCUlKTKW6fTYdq0aUrN9OnTodPp5DrTTWJiIq5fv45Hjx4BAO7du4dbt25h8eLFACTrvuKtXK1WK5KSkqDRaJSa5ORkvHjxAo2Njb81R7mFZz96/fo1urq6oNfrVeN6vR4Oh2OAZjX4kUROTg4SExNhMpkAAA6HA4GBgRg+fLiqtnvWDofD41wMHz4cgYGBcj66KSgogM1mw927dz22Sc7e9fTpUxw9ehQ5OTnYvn07qqqqsHHjRmg0GqxevVrJq6drSFNTE4BveYeFhXnsOywsTPLuZuvWrXA6nYiJiYGfnx+6urqQl5eH1NRUAJCs+4i3cnU4HBg1apTHPv7eFh0d3es5SmM0AHx8fFTfk/QYEz/PbDbj/v37uHXr1g9rv8+6p9zlfPzXs2fPkJWVhZKSEgwZMuSnnyc5947L5UJ8fDz27t0LAJg8eTIePHiAo0ePYvXq1Urdj64hkvePnT9/HqdPn8bZs2cxfvx41NbWIjs7G0ajERkZGUqdZN03vJFrT/v4p+f+CnkrrR+FhobCz8/P4y+J1tZWj+5Z/JwNGzaguLgYZWVliIyMVMYNBgM6OjrQ1tamqu+etcFg8DgXbW1t+Pr1q5wPt+rqarS2tiIuLg7+/v7w9/dHeXk5Dh06BH9/f+j1esnZi8LDwzFu3DjV2NixY9Hc3AzgW5YA/uc1xGAw4OXLlx77fvXqleTdzebNm7Ft2zasXLkSEyZMQHp6OjZt2oR9+/YBkKz7irdy7em60traCsDz1ahfJY1RPwoMDERcXBwsFotq3GKxYMaMGQM0q8GJJMxmM4qKinDjxg2Pl03j4uIQEBCgyrqlpQV1dXVK1gkJCairq0NLS4tSU1JSAo1Gg7i4uP45kD/c/PnzYbfbUVtbqzzi4+ORlpamfC05e8/MmTM9bjvx6NEjREVFAQCio6NhMBhUeXd0dKC8vFyVt9PpRFVVlVJz584dOJ1Ouc508/HjR/j6qn8F+vn5Kcv1Jeu+4a1cExISUFFRobrtR0lJCYxGo8dbbL/stz66LX7Z38v1T548yfr6emZnZ3Po0KFsbGwc6KkNKuvWraNOp+PNmzfZ0tKiPD5+/KjUZGZmMjIykqWlpbTZbJw3b16Py8jnz59Pm83G0tJSRkZGyjLyH+i+Ko2UnL2pqqqK/v7+zMvL4+PHj3nmzBkGBQXx9OnTSk1+fj51Oh2Liopot9uZmpra41Ln2NhYWq1WWq1WTpgw4f9+Cfn3MjIyGBERoSzXLyoqYmhoKLds2aLUSNa98/79e9bU1LCmpoYAeODAAdbU1Ci3pfFGru3t7dTr9UxNTaXdbmdRURH/+usvWa4/WB0+fJhRUVEMDAzklClTlCXm4ucB6PFx6tQppebTp080m80MCQmhVqvlkiVL2NzcrNpPU1MTU1JSqNVqGRISQrPZrFr+KTx93xhJzt51+fJlmkwmajQaxsTE8Pjx46rtLpeLu3btosFgoEaj4ezZs2m321U1b968YVpaGoODgxkcHMy0tDS2tbX152H88d69e8esrCyOHDmSQ4YM4ejRo7ljxw5++fJFqZGse6esrKzH63NGRgZJ7+V6//59zpo1ixqNhgaDgbt37/7tpfok6UN64zaRQgghhBCDn3zGSAghhBDCTRojIYQQQgg3aYyEEEIIIdykMRJCCCGEcJPGSAghhBDCTRojIYQQQgg3aYyEEEIIIdykMRJCCCGEcJPGSAghhBDCTRojIYQQQgg3aYyEEEIIIdykMRJCCCGEcPsP1FDuFPyFL3QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "242f3ee3-50c8-4d94-83c4-67e700e5b1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "8fd835ef-3593-4fe7-85c8-8f09302cc9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.015399999999999636"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcba56-8e88-48cd-9386-2b0984ecbf9e",
   "metadata": {},
   "source": [
    "# Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b8bfe8-edd4-4b51-9349-c4d4c7cf9bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Invalid requirement: 'git://github.com/huggingface/accelerate.git' (from line 1 of semantic-segmentation/requirements.txt)\n",
      "Hint: It looks like a path. File 'git://github.com/huggingface/accelerate.git' does not exist.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r semantic-segmentation/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "344751db-124f-42bb-bcd0-3cc75df01fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_semantic_segmentation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "0ff4a94f-2496-4a89-8892-09edc996f069",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-23 16:12:34,351 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-23 16:12:34,351 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 16:12:34 - WARNING - run_semantic_segmentation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/23/2023 16:12:34 - INFO - run_semantic_segmentation - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp6txdsajd/runs/Mar23_16-12-34_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_warmup,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp6txdsajd,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=2,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp6txdsajd,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/23/2023 16:12:34 - INFO - datasets.builder - Using custom data configuration segments--sidewalk-semantic-2-007b1ee78ca1e890\n",
      "03/23/2023 16:12:34 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/23/2023 16:12:34 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\n",
      "03/23/2023 16:12:34 - WARNING - datasets.builder - Found cached dataset parquet (/root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "03/23/2023 16:12:34 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707fa59af6ef4268a165634d12238fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 16:12:34 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0380284e0713d034.arrow and /root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-958c67d9d7300917.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-23 16:12:34,841 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--nvidia--mit-b0/snapshots/ed0b85c75627eab6a3c6989627450cf95f115381/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 16:12:34,843 >> Model config SegformerConfig {\n",
      "  \"_name_or_path\": \"nvidia/mit-b0\",\n",
      "  \"architectures\": [\n",
      "    \"SegformerForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"decoder_hidden_size\": 256,\n",
      "  \"depths\": [\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"downsampling_rates\": [\n",
      "    1,\n",
      "    4,\n",
      "    8,\n",
      "    16\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_sizes\": [\n",
      "    32,\n",
      "    64,\n",
      "    160,\n",
      "    256\n",
      "  ],\n",
      "  \"id2label\": {\n",
      "    \"0\": \"unlabeled\",\n",
      "    \"1\": \"flat-road\",\n",
      "    \"2\": \"flat-sidewalk\",\n",
      "    \"3\": \"flat-crosswalk\",\n",
      "    \"4\": \"flat-cyclinglane\",\n",
      "    \"5\": \"flat-parkingdriveway\",\n",
      "    \"6\": \"flat-railtrack\",\n",
      "    \"7\": \"flat-curb\",\n",
      "    \"8\": \"human-person\",\n",
      "    \"9\": \"human-rider\",\n",
      "    \"10\": \"vehicle-car\",\n",
      "    \"11\": \"vehicle-truck\",\n",
      "    \"12\": \"vehicle-bus\",\n",
      "    \"13\": \"vehicle-tramtrain\",\n",
      "    \"14\": \"vehicle-motorcycle\",\n",
      "    \"15\": \"vehicle-bicycle\",\n",
      "    \"16\": \"vehicle-caravan\",\n",
      "    \"17\": \"vehicle-cartrailer\",\n",
      "    \"18\": \"construction-building\",\n",
      "    \"19\": \"construction-door\",\n",
      "    \"20\": \"construction-wall\",\n",
      "    \"21\": \"construction-fenceguardrail\",\n",
      "    \"22\": \"construction-bridge\",\n",
      "    \"23\": \"construction-tunnel\",\n",
      "    \"24\": \"construction-stairs\",\n",
      "    \"25\": \"object-pole\",\n",
      "    \"26\": \"object-trafficsign\",\n",
      "    \"27\": \"object-trafficlight\",\n",
      "    \"28\": \"nature-vegetation\",\n",
      "    \"29\": \"nature-terrain\",\n",
      "    \"30\": \"sky\",\n",
      "    \"31\": \"void-ground\",\n",
      "    \"32\": \"void-dynamic\",\n",
      "    \"33\": \"void-static\",\n",
      "    \"34\": \"void-unclear\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"construction-bridge\": \"22\",\n",
      "    \"construction-building\": \"18\",\n",
      "    \"construction-door\": \"19\",\n",
      "    \"construction-fenceguardrail\": \"21\",\n",
      "    \"construction-stairs\": \"24\",\n",
      "    \"construction-tunnel\": \"23\",\n",
      "    \"construction-wall\": \"20\",\n",
      "    \"flat-crosswalk\": \"3\",\n",
      "    \"flat-curb\": \"7\",\n",
      "    \"flat-cyclinglane\": \"4\",\n",
      "    \"flat-parkingdriveway\": \"5\",\n",
      "    \"flat-railtrack\": \"6\",\n",
      "    \"flat-road\": \"1\",\n",
      "    \"flat-sidewalk\": \"2\",\n",
      "    \"human-person\": \"8\",\n",
      "    \"human-rider\": \"9\",\n",
      "    \"nature-terrain\": \"29\",\n",
      "    \"nature-vegetation\": \"28\",\n",
      "    \"object-pole\": \"25\",\n",
      "    \"object-trafficlight\": \"27\",\n",
      "    \"object-trafficsign\": \"26\",\n",
      "    \"sky\": \"30\",\n",
      "    \"unlabeled\": \"0\",\n",
      "    \"vehicle-bicycle\": \"15\",\n",
      "    \"vehicle-bus\": \"12\",\n",
      "    \"vehicle-car\": \"10\",\n",
      "    \"vehicle-caravan\": \"16\",\n",
      "    \"vehicle-cartrailer\": \"17\",\n",
      "    \"vehicle-motorcycle\": \"14\",\n",
      "    \"vehicle-tramtrain\": \"13\",\n",
      "    \"vehicle-truck\": \"11\",\n",
      "    \"void-dynamic\": \"32\",\n",
      "    \"void-ground\": \"31\",\n",
      "    \"void-static\": \"33\",\n",
      "    \"void-unclear\": \"34\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-06,\n",
      "  \"mlp_ratios\": [\n",
      "    4,\n",
      "    4,\n",
      "    4,\n",
      "    4\n",
      "  ],\n",
      "  \"model_type\": \"segformer\",\n",
      "  \"num_attention_heads\": [\n",
      "    1,\n",
      "    2,\n",
      "    5,\n",
      "    8\n",
      "  ],\n",
      "  \"num_channels\": 3,\n",
      "  \"num_encoder_blocks\": 4,\n",
      "  \"patch_sizes\": [\n",
      "    7,\n",
      "    3,\n",
      "    3,\n",
      "    3\n",
      "  ],\n",
      "  \"reshape_last_stage\": true,\n",
      "  \"semantic_loss_ignore_index\": 255,\n",
      "  \"sr_ratios\": [\n",
      "    8,\n",
      "    4,\n",
      "    2,\n",
      "    1\n",
      "  ],\n",
      "  \"strides\": [\n",
      "    4,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-23 16:12:34,859 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--nvidia--mit-b0/snapshots/ed0b85c75627eab6a3c6989627450cf95f115381/pytorch_model.bin\n",
      "[WARNING|modeling_utils.py:3010] 2023-03-23 16:12:34,945 >> Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3022] 2023-03-23 16:12:34,946 >> Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.classifier.bias', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.running_var', 'decode_head.linear_fuse.weight', 'decode_head.classifier.weight', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.0.proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-03-23 16:12:34,980 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--nvidia--mit-b0/snapshots/ed0b85c75627eab6a3c6989627450cf95f115381/preprocessor_config.json\n",
      "[WARNING|image_processing_auto.py:325] 2023-03-23 16:12:34,981 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "/root/transformers/src/transformers/models/segformer/image_processing_segformer.py:102: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  FutureWarning,\n",
      "[INFO|image_processing_utils.py:533] 2023-03-23 16:12:34,983 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}), got 512. Converted to {'height': 512, 'width': 512}.\n",
      "[INFO|image_processing_utils.py:353] 2023-03-23 16:12:34,983 >> Image processor SegformerImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_reduce_labels\": false,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"SegformerImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 512,\n",
      "    \"width\": 512\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO|trainer.py:543] 2023-03-23 16:12:34,997 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-03-23 16:12:35,003 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-23 16:12:35,003 >>   Num examples = 850\n",
      "[INFO|trainer.py:1760] 2023-03-23 16:12:35,004 >>   Num Epochs = 3\n",
      "[INFO|trainer.py:1761] 2023-03-23 16:12:35,004 >>   Instantaneous batch size per device = 2\n",
      "[INFO|trainer.py:1762] 2023-03-23 16:12:35,005 >>   Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "[INFO|trainer.py:1763] 2023-03-23 16:12:35,006 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-23 16:12:35,007 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-23 16:12:35,008 >>   Number of trainable parameters = 3723139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 01:55, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.687800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.691200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.641300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.626100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.620200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.581300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.584300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.549700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.508200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.509900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.514800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.579300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.476400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.466900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.447300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.448700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.384200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.421100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.423500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.395700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.335400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.363900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.350800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.373200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.289200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.259100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.338100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.243700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.303300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.252300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.286800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.235300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.162400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.106400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.115700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.106200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.066200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.173100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.108900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.157300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.948100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.083700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.985600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.903700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.933400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.980900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.086800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.932000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.826000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.843800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.805400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.861800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.839100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.876300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.848900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.937900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.865400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.772300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.576400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.835200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-23 16:14:30,186 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-23 16:14:30,189 >> Saving model checkpoint to /tmp/tmp6txdsajd\n",
      "[INFO|configuration_utils.py:457] 2023-03-23 16:14:30,191 >> Configuration saved in /tmp/tmp6txdsajd/config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-23 16:14:30,219 >> Model weights saved in /tmp/tmp6txdsajd/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:203] 2023-03-23 16:14:30,220 >> Image processor saved in /tmp/tmp6txdsajd/preprocessor_config.json\n",
      "[INFO|modelcard.py:449] 2023-03-23 16:14:30,263 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       2.35\n",
      "  total_flos               = 32722901GF\n",
      "  train_loss               =     3.2186\n",
      "  train_runtime            = 0:01:55.17\n",
      "  train_samples_per_second =     17.364\n",
      "  train_steps_per_second   =      8.682\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_semantic_segmentation.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path nvidia/mit-b0\n",
    "    --dataset_name segments/sidewalk-semantic\n",
    "    --dataset_config mini\n",
    "    --do_train\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --max_steps 1000\n",
    "    --learning_rate=1e-3\n",
    "    --per_device_train_batch_size=2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_semantic_segmentation.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "645266d4-aed7-473a-83d3-6b48b4562bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'pymp*': No such file or directory\n",
      "rm: cannot remove './tmp*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6e86863b-662e-4ca3-8dc5-d3275eb11540",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-23 16:14:31,022 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-23 16:14:31,023 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 16:14:31 - WARNING - run_semantic_segmentation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/23/2023 16:14:31 - INFO - run_semantic_segmentation - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpqrbxn7l4/runs/Mar23_16-14-31_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=greedy,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=1e-05,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpqrbxn7l4,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpqrbxn7l4,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/23/2023 16:14:31 - INFO - datasets.builder - Using custom data configuration segments--sidewalk-semantic-2-007b1ee78ca1e890\n",
      "03/23/2023 16:14:31 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/23/2023 16:14:31 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\n",
      "03/23/2023 16:14:31 - WARNING - datasets.builder - Found cached dataset parquet (/root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "03/23/2023 16:14:31 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d86f83221f4589b9f5f505ba20d669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 16:14:31 - WARNING - datasets.arrow_dataset - Loading cached split indices for dataset at /root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-0380284e0713d034.arrow and /root/.cache/huggingface/datasets/segments___parquet/segments--sidewalk-semantic-2-007b1ee78ca1e890/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-958c67d9d7300917.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-23 16:14:31,426 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--nvidia--mit-b0/snapshots/ed0b85c75627eab6a3c6989627450cf95f115381/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 16:14:31,428 >> Model config SegformerConfig {\n",
      "  \"_name_or_path\": \"nvidia/mit-b0\",\n",
      "  \"architectures\": [\n",
      "    \"SegformerForImageClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"classifier_dropout_prob\": 0.1,\n",
      "  \"decoder_hidden_size\": 256,\n",
      "  \"depths\": [\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"downsampling_rates\": [\n",
      "    1,\n",
      "    4,\n",
      "    8,\n",
      "    16\n",
      "  ],\n",
      "  \"drop_path_rate\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_sizes\": [\n",
      "    32,\n",
      "    64,\n",
      "    160,\n",
      "    256\n",
      "  ],\n",
      "  \"id2label\": {\n",
      "    \"0\": \"unlabeled\",\n",
      "    \"1\": \"flat-road\",\n",
      "    \"2\": \"flat-sidewalk\",\n",
      "    \"3\": \"flat-crosswalk\",\n",
      "    \"4\": \"flat-cyclinglane\",\n",
      "    \"5\": \"flat-parkingdriveway\",\n",
      "    \"6\": \"flat-railtrack\",\n",
      "    \"7\": \"flat-curb\",\n",
      "    \"8\": \"human-person\",\n",
      "    \"9\": \"human-rider\",\n",
      "    \"10\": \"vehicle-car\",\n",
      "    \"11\": \"vehicle-truck\",\n",
      "    \"12\": \"vehicle-bus\",\n",
      "    \"13\": \"vehicle-tramtrain\",\n",
      "    \"14\": \"vehicle-motorcycle\",\n",
      "    \"15\": \"vehicle-bicycle\",\n",
      "    \"16\": \"vehicle-caravan\",\n",
      "    \"17\": \"vehicle-cartrailer\",\n",
      "    \"18\": \"construction-building\",\n",
      "    \"19\": \"construction-door\",\n",
      "    \"20\": \"construction-wall\",\n",
      "    \"21\": \"construction-fenceguardrail\",\n",
      "    \"22\": \"construction-bridge\",\n",
      "    \"23\": \"construction-tunnel\",\n",
      "    \"24\": \"construction-stairs\",\n",
      "    \"25\": \"object-pole\",\n",
      "    \"26\": \"object-trafficsign\",\n",
      "    \"27\": \"object-trafficlight\",\n",
      "    \"28\": \"nature-vegetation\",\n",
      "    \"29\": \"nature-terrain\",\n",
      "    \"30\": \"sky\",\n",
      "    \"31\": \"void-ground\",\n",
      "    \"32\": \"void-dynamic\",\n",
      "    \"33\": \"void-static\",\n",
      "    \"34\": \"void-unclear\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"construction-bridge\": \"22\",\n",
      "    \"construction-building\": \"18\",\n",
      "    \"construction-door\": \"19\",\n",
      "    \"construction-fenceguardrail\": \"21\",\n",
      "    \"construction-stairs\": \"24\",\n",
      "    \"construction-tunnel\": \"23\",\n",
      "    \"construction-wall\": \"20\",\n",
      "    \"flat-crosswalk\": \"3\",\n",
      "    \"flat-curb\": \"7\",\n",
      "    \"flat-cyclinglane\": \"4\",\n",
      "    \"flat-parkingdriveway\": \"5\",\n",
      "    \"flat-railtrack\": \"6\",\n",
      "    \"flat-road\": \"1\",\n",
      "    \"flat-sidewalk\": \"2\",\n",
      "    \"human-person\": \"8\",\n",
      "    \"human-rider\": \"9\",\n",
      "    \"nature-terrain\": \"29\",\n",
      "    \"nature-vegetation\": \"28\",\n",
      "    \"object-pole\": \"25\",\n",
      "    \"object-trafficlight\": \"27\",\n",
      "    \"object-trafficsign\": \"26\",\n",
      "    \"sky\": \"30\",\n",
      "    \"unlabeled\": \"0\",\n",
      "    \"vehicle-bicycle\": \"15\",\n",
      "    \"vehicle-bus\": \"12\",\n",
      "    \"vehicle-car\": \"10\",\n",
      "    \"vehicle-caravan\": \"16\",\n",
      "    \"vehicle-cartrailer\": \"17\",\n",
      "    \"vehicle-motorcycle\": \"14\",\n",
      "    \"vehicle-tramtrain\": \"13\",\n",
      "    \"vehicle-truck\": \"11\",\n",
      "    \"void-dynamic\": \"32\",\n",
      "    \"void-ground\": \"31\",\n",
      "    \"void-static\": \"33\",\n",
      "    \"void-unclear\": \"34\"\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-06,\n",
      "  \"mlp_ratios\": [\n",
      "    4,\n",
      "    4,\n",
      "    4,\n",
      "    4\n",
      "  ],\n",
      "  \"model_type\": \"segformer\",\n",
      "  \"num_attention_heads\": [\n",
      "    1,\n",
      "    2,\n",
      "    5,\n",
      "    8\n",
      "  ],\n",
      "  \"num_channels\": 3,\n",
      "  \"num_encoder_blocks\": 4,\n",
      "  \"patch_sizes\": [\n",
      "    7,\n",
      "    3,\n",
      "    3,\n",
      "    3\n",
      "  ],\n",
      "  \"reshape_last_stage\": true,\n",
      "  \"semantic_loss_ignore_index\": 255,\n",
      "  \"sr_ratios\": [\n",
      "    8,\n",
      "    4,\n",
      "    2,\n",
      "    1\n",
      "  ],\n",
      "  \"strides\": [\n",
      "    4,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-23 16:14:31,443 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--nvidia--mit-b0/snapshots/ed0b85c75627eab6a3c6989627450cf95f115381/pytorch_model.bin\n",
      "[WARNING|modeling_utils.py:3010] 2023-03-23 16:14:31,539 >> Some weights of the model checkpoint at nvidia/mit-b0 were not used when initializing SegformerForSemanticSegmentation: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SegformerForSemanticSegmentation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3022] 2023-03-23 16:14:31,540 >> Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.batch_norm.weight', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.classifier.bias', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.0.proj.bias', 'decode_head.batch_norm.bias', 'decode_head.batch_norm.running_var', 'decode_head.linear_fuse.weight', 'decode_head.classifier.weight', 'decode_head.batch_norm.running_mean', 'decode_head.linear_c.0.proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[INFO|image_processing_utils.py:309] 2023-03-23 16:14:31,572 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--nvidia--mit-b0/snapshots/ed0b85c75627eab6a3c6989627450cf95f115381/preprocessor_config.json\n",
      "[WARNING|image_processing_auto.py:325] 2023-03-23 16:14:31,573 >> Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "[INFO|image_processing_utils.py:533] 2023-03-23 16:14:31,574 >> size should be a dictionary on of the following set of keys: ({'height', 'width'}, {'shortest_edge'}, {'longest_edge', 'shortest_edge'}), got 512. Converted to {'height': 512, 'width': 512}.\n",
      "[INFO|image_processing_utils.py:353] 2023-03-23 16:14:31,575 >> Image processor SegformerImageProcessor {\n",
      "  \"do_normalize\": true,\n",
      "  \"do_reduce_labels\": false,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"SegformerImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"height\": 512,\n",
      "    \"width\": 512\n",
      "  }\n",
      "}\n",
      "\n",
      "[INFO|trainer.py:543] 2023-03-23 16:14:31,589 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-03-23 16:14:31,594 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-23 16:14:31,594 >>   Num examples = 850\n",
      "[INFO|trainer.py:1760] 2023-03-23 16:14:31,595 >>   Num Epochs = 5\n",
      "[INFO|trainer.py:1761] 2023-03-23 16:14:31,596 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1762] 2023-03-23 16:14:31,597 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1763] 2023-03-23 16:14:31,597 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-23 16:14:31,598 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-23 16:14:31,599 >>   Number of trainable parameters = 3723139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreedyLR settings: patience=10 smooth=True min_lr=1e-05 factor=0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:16, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.545800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.569800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.525600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.507600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.479400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.468700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.471900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.438500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.443700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.446300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.403800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.396000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.368900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.395900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.369300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.416300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.355400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.351800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.346200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.294400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.304000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.307800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.271000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.277300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.261800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.202200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.167900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.270300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.211700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.169100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.145500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.133900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.134900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.197900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.176400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.161500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.155600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.139900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.185200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.131300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.978000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.060200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.097000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.033800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.012300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.075800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.991300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.964800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.942600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.907700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.081600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.999300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.958100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.949200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.918400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.968100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.994300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.993500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-23 16:17:48,009 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-23 16:17:48,012 >> Saving model checkpoint to /tmp/tmpqrbxn7l4\n",
      "[INFO|configuration_utils.py:457] 2023-03-23 16:17:48,014 >> Configuration saved in /tmp/tmpqrbxn7l4/config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-23 16:17:48,042 >> Model weights saved in /tmp/tmpqrbxn7l4/pytorch_model.bin\n",
      "[INFO|image_processing_utils.py:203] 2023-03-23 16:17:48,044 >> Image processor saved in /tmp/tmpqrbxn7l4/preprocessor_config.json\n",
      "[INFO|modelcard.py:449] 2023-03-23 16:17:48,091 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       4.69\n",
      "  total_flos               = 65314911GF\n",
      "  train_loss               =     3.1817\n",
      "  train_runtime            = 0:03:16.40\n",
      "  train_samples_per_second =     20.366\n",
      "  train_steps_per_second   =      5.091\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_semantic_segmentation.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path nvidia/mit-b0\n",
    "    --dataset_name segments/sidewalk-semantic\n",
    "    --do_train\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --max_steps 1000\n",
    "    --learning_rate=1e-3\n",
    "    --per_device_train_batch_size=4\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_semantic_segmentation.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5e4007fc-f5f2-40f3-9954-804ce3812da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "f4186932-ff3f-43b9-86fd-293951cb677b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "7b7461d1-1d45-440b-a654-e439dcf1c108",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5331de07-cf21-40e3-bc97-3bc147e5656d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1583000000000001"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dafeeb-7e9b-49c2-9c3a-6dc03db10093",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a5af4175-63f1-47e7-aa37-ae71aec292c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Using cached rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[20 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 36, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-7ftn8d1j/rouge-score/setup.py\", line 55, in <module>\n",
      "  \u001b[31m   \u001b[0m     python_requires=\">=3.7\",\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "  \u001b[31m   \u001b[0m     return distutils.core.setup(**attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "  \u001b[31m   \u001b[0m     _setup_distribution = dist = klass(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "  \u001b[31m   \u001b[0m     for k, v in attrs.items()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "  \u001b[31m   \u001b[0m     self.finalize_options()\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "  \u001b[31m   \u001b[0m     for ep in sorted(loaded, key=by_order):\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "  \u001b[31m   \u001b[0m     loaded = map(lambda e: e.load(), filtered)\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "  \u001b[31m   \u001b[0m     return functools.reduce(getattr, attrs, module)\n",
      "  \u001b[31m   \u001b[0m AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m rouge-score\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --use-deprecated=legacy-resolver rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ed20f913-05cc-474b-8886-a2d6a5d5dcf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip --no-cache-dir install -r summarization/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "45a2b1a0-b4a7-462d-adb5-6076675eec6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install absl-py nltk numpy six>=1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2dbb974-af08-41f2-8718-6bc5983c07f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip==21.0.0\n",
      "  Using cached pip-21.0-py3-none-any.whl (1.5 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.0.1\n",
      "    Uninstalling pip-23.0.1:\n",
      "      Successfully uninstalled pip-23.0.1\n",
      "Successfully installed pip-21.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip==21.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b41854-4f84-4557-a72e-fb2a3ab1f0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: rouge-score in /opt/conda/lib/python3.7/site-packages (0.0.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.21.6)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.14.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge-score) (3.8.1)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.7/site-packages (from nltk->rouge-score) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->rouge-score) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk->rouge-score) (4.65.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->rouge-score) (7.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --no-cache-dir rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bc8a9769-eec2-4f73-8e61-7447ef7c4ea6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_summarization\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "42c263c4-2bc0-496c-ba1e-c5bcbef474be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-23 14:50:37,762 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-23 14:50:37,762 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 14:50:37 - WARNING - run_summarization - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
      "03/23/2023 14:50:37 - INFO - run_summarization - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp4f3b3oxg/runs/Mar23_14-50-37_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=polynomial,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adagrad,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp4f3b3oxg,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp4f3b3oxg,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/23/2023 14:50:38 - WARNING - datasets.builder - No config specified, defaulting to: amazon_reviews_multi/all_languages\n",
      "03/23/2023 14:50:38 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/amazon_reviews_multi/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\n",
      "03/23/2023 14:50:38 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/23/2023 14:50:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\n",
      "03/23/2023 14:50:38 - WARNING - datasets.builder - Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n",
      "03/23/2023 14:50:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1d3ea97c564707bf902238ca7f1de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-23 14:50:38,184 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 14:50:38,185 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-23 14:50:38,228 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 14:50:38,254 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 14:50:38,255 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:50:38,317 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:50:38,317 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:50:38,318 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:50:38,318 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:50:38,319 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:50:38,319 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 14:50:38,322 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 14:50:38,324 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-23 14:50:38,395 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-23 14:50:38,565 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-23 14:50:40,489 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-23 14:50:40,490 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "[INFO|modeling_utils.py:2678] 2023-03-23 14:50:40,535 >> Generation config file not found, using a generation config created from the model config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 14:50:40 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-0ca927eec117e5f2.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-23 14:50:40,745 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:597] 2023-03-23 14:50:40,746 >> Using cuda_amp half precision backend\n",
      "[INFO|trainer.py:1758] 2023-03-23 14:50:40,759 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-23 14:50:40,760 >>   Num examples = 1199996\n",
      "[INFO|trainer.py:1760] 2023-03-23 14:50:40,761 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-23 14:50:40,761 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1762] 2023-03-23 14:50:40,762 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1763] 2023-03-23 14:50:40,763 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-23 14:50:40,763 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-23 14:50:40,764 >>   Number of trainable parameters = 139420416\n",
      "[WARNING|logging.py:280] 2023-03-23 14:50:40,828 >> You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 01:29, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.909900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.925900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.884900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.755900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.870000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.692600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.871400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.600300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.705900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.249700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.840100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.753900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.952400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.702600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.544300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.943200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.710200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.877400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.801200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.860100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.107500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.771400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.664300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.854900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.863000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.804100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.818500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.028300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.067000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.458000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.886700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.166300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.759700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.802500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.927400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.744600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.050300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.106500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.076300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.951200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.968400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.627100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.643000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.696500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.874800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.557000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.753700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.694100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.640300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.885000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.814300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.881300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.576900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.497900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.832700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.994100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.827200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.783600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.876300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.849100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.431500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.652500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.906700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.854600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.698700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.899200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-23 14:52:10,597 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-23 14:52:10,600 >> Saving model checkpoint to /tmp/tmp4f3b3oxg\n",
      "[INFO|configuration_utils.py:457] 2023-03-23 14:52:10,602 >> Configuration saved in /tmp/tmp4f3b3oxg/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-03-23 14:52:10,604 >> Configuration saved in /tmp/tmp4f3b3oxg/generation_config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-23 14:52:11,002 >> Model weights saved in /tmp/tmp4f3b3oxg/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2163] 2023-03-23 14:52:11,004 >> tokenizer config file saved in /tmp/tmp4f3b3oxg/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-03-23 14:52:11,005 >> Special tokens file saved in /tmp/tmp4f3b3oxg/special_tokens_map.json\n",
      "[INFO|modelcard.py:449] 2023-03-23 14:52:11,136 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Summarization', 'type': 'summarization'}, 'dataset': {'name': 'amazon_reviews_multi', 'type': 'amazon_reviews_multi', 'config': 'all_languages', 'split': 'train', 'args': 'all_languages'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.01\n",
      "  total_flos               =  1026231GF\n",
      "  train_loss               =     2.8676\n",
      "  train_runtime            = 0:01:29.83\n",
      "  train_samples            =    1199996\n",
      "  train_samples_per_second =     89.055\n",
      "  train_steps_per_second   =     11.132\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_summarization.py\n",
    "    --model_name_or_path facebook/bart-base\n",
    "    --dataset_name amazon_reviews_multi\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=8\n",
    "    --predict_with_generate\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --fp16 true\n",
    "    --optim adagrad\n",
    "    --lr_scheduler_type polynomial\n",
    "\"\"\".split()\n",
    "\n",
    "testargs.append('--source_prefix')\n",
    "testargs.append(\"summarize: \")\n",
    "\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_summarization.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6e007896-d24b-4fcc-a585-b84ad272bb65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'pymp*': No such file or directory\n",
      "rm: cannot remove './tmp*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d3daf4e3-e9f3-4f15-89de-32d6eebfe7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %store -r d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8a1968bf-c8b0-48e3-8cdf-510d13852d78",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-23 14:52:11,980 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-23 14:52:11,980 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 14:52:12 - WARNING - run_summarization - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
      "03/23/2023 14:52:12 - INFO - run_summarization - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpfe3fo8da/runs/Mar23_14-52-11_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=greedy,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=1e-05,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adagrad,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpfe3fo8da,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpfe3fo8da,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=True,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/23/2023 14:52:12 - WARNING - datasets.builder - No config specified, defaulting to: amazon_reviews_multi/all_languages\n",
      "03/23/2023 14:52:12 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/amazon_reviews_multi/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\n",
      "03/23/2023 14:52:12 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/23/2023 14:52:12 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\n",
      "03/23/2023 14:52:12 - WARNING - datasets.builder - Found cached dataset amazon_reviews_multi (/root/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609)\n",
      "03/23/2023 14:52:12 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c5006d98704b68abdfcfdf28fe2af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-23 14:52:12,396 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 14:52:12,398 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-23 14:52:12,428 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 14:52:12,455 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 14:52:12,456 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:52:12,524 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/vocab.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:52:12,525 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:52:12,526 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:52:12,526 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:52:12,527 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 14:52:12,527 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 14:52:12,531 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 14:52:12,532 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-23 14:52:12,606 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--bart-base/snapshots/aadd2ab0ae0c8268c7c9693540e9904811f36177/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-23 14:52:12,777 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"early_stopping\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"num_beams\": 4,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-23 14:52:14,682 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-23 14:52:14,683 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "[INFO|modeling_utils.py:2678] 2023-03-23 14:52:14,725 >> Generation config file not found, using a generation config created from the model config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 14:52:14 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/amazon_reviews_multi/all_languages/1.0.0/724e94f4b0c6c405ce7e476a6c5ef4f87db30799ad49f765094cf9770e0f7609/cache-0ca927eec117e5f2.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-23 14:52:14,929 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:597] 2023-03-23 14:52:14,930 >> Using cuda_amp half precision backend\n",
      "[INFO|trainer.py:1758] 2023-03-23 14:52:14,943 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-23 14:52:14,943 >>   Num examples = 1199996\n",
      "[INFO|trainer.py:1760] 2023-03-23 14:52:14,944 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-23 14:52:14,944 >>   Instantaneous batch size per device = 8\n",
      "[INFO|trainer.py:1762] 2023-03-23 14:52:14,945 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "[INFO|trainer.py:1763] 2023-03-23 14:52:14,945 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-23 14:52:14,947 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-23 14:52:14,948 >>   Number of trainable parameters = 139420416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreedyLR settings: patience=10 smooth=True min_lr=1e-05 factor=0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|logging.py:280] 2023-03-23 14:52:15,011 >> You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 01:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.989600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.265100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.408200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.908200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.795800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.898900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.863100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.974700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.931000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.052500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.591500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.241600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.794500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.950900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.693200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.698900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.537200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.874500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.073300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.951800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.799800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.861700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.108600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.774300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.665100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.790700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.857100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.811900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.826800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.072600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.745100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.463600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.893500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.176600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.610100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.773700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.789000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.933900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.750800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.086800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.987800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.146700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.644000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.706200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.890900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.770600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.075200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.753300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.712600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.905500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.838300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.879500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.856000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.773500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.598800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.856300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.851100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.811600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.870500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.687900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.448700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.933700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.875200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.713000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.932500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-23 14:53:45,390 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-23 14:53:45,393 >> Saving model checkpoint to /tmp/tmpfe3fo8da\n",
      "[INFO|configuration_utils.py:457] 2023-03-23 14:53:45,395 >> Configuration saved in /tmp/tmpfe3fo8da/config.json\n",
      "[INFO|configuration_utils.py:362] 2023-03-23 14:53:45,397 >> Configuration saved in /tmp/tmpfe3fo8da/generation_config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-23 14:53:45,795 >> Model weights saved in /tmp/tmpfe3fo8da/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2163] 2023-03-23 14:53:45,797 >> tokenizer config file saved in /tmp/tmpfe3fo8da/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-03-23 14:53:45,798 >> Special tokens file saved in /tmp/tmpfe3fo8da/special_tokens_map.json\n",
      "[INFO|modelcard.py:449] 2023-03-23 14:53:45,935 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Summarization', 'type': 'summarization'}, 'dataset': {'name': 'amazon_reviews_multi', 'type': 'amazon_reviews_multi', 'config': 'all_languages', 'split': 'train', 'args': 'all_languages'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.01\n",
      "  total_flos               =  1026231GF\n",
      "  train_loss               =     2.8747\n",
      "  train_runtime            = 0:01:30.44\n",
      "  train_samples            =    1199996\n",
      "  train_samples_per_second =     88.454\n",
      "  train_steps_per_second   =     11.057\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_summarization.py\n",
    "    --model_name_or_path facebook/bart-base\n",
    "    --dataset_name amazon_reviews_multi\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=8\n",
    "    --predict_with_generate\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --fp16 true\n",
    "    --optim adagrad\n",
    "\"\"\".split()\n",
    "\n",
    "testargs.append('--source_prefix')\n",
    "testargs.append(\"summarize: \")\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_summarization.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3d516204-cac8-4bdd-a0dd-fdcc7a4350c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1e284eb8-79ef-4b6e-987a-48cdcc4d9f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9c0f5dc8-44e1-4255-825c-f9c2650843e4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LRs')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "d5453585-e436-40b4-b42d-d8b35f816e76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_figheight(4)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8d308c02-f959-49e3-8029-50ba050fd3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.03330000000000011"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1[-1][-1] - d2[-1][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f284a-2457-4a23-938d-24d584e46bd8",
   "metadata": {},
   "source": [
    "# Audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6172ddfa-22b7-4424-b931-25c1fe38aa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_wav2vec2_pretraining_no_trainer\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03a7c8e0-692f-4cd1-8420-744d7d9a5756",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: datasets>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from -r speech-pretraining/requirements.txt (line 1)) (2.10.1)\n",
      "Requirement already satisfied: torch>=1.5 in /opt/conda/lib/python3.7/site-packages (from -r speech-pretraining/requirements.txt (line 2)) (1.13.1)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-0.13.1-cp37-cp37m-manylinux1_x86_64.whl (4.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.2 MB 28.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: accelerate>=0.12.0 in /opt/conda/lib/python3.7/site-packages (from -r speech-pretraining/requirements.txt (line 4)) (0.17.1)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
      "\u001b[K     |████████████████████████████████| 253 kB 116.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r speech-pretraining/requirements.txt (line 4)) (6.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r speech-pretraining/requirements.txt (line 4)) (5.6.7)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r speech-pretraining/requirements.txt (line 4)) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r speech-pretraining/requirements.txt (line 4)) (23.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (0.13.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (0.18.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (0.3.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (2.28.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (2023.1.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (3.8.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (1.3.5)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (11.0.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch>=1.5->-r speech-pretraining/requirements.txt (line 2)) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch>=1.5->-r speech-pretraining/requirements.txt (line 2)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.5->-r speech-pretraining/requirements.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.5->-r speech-pretraining/requirements.txt (line 2)) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.5->-r speech-pretraining/requirements.txt (line 2)) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.5->-r speech-pretraining/requirements.txt (line 2)) (65.7.0)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.5->-r speech-pretraining/requirements.txt (line 2)) (0.40.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (1.3.3)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (0.13.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (22.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (3.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.12.0->-r speech-pretraining/requirements.txt (line 1)) (1.26.15)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.7/site-packages (from librosa->-r speech-pretraining/requirements.txt (line 5)) (0.22.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.7/site-packages (from librosa->-r speech-pretraining/requirements.txt (line 5)) (0.56.4)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.7/site-packages (from librosa->-r speech-pretraining/requirements.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.7/site-packages (from librosa->-r speech-pretraining/requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from librosa->-r speech-pretraining/requirements.txt (line 5)) (4.4.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from librosa->-r speech-pretraining/requirements.txt (line 5)) (1.4.1)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.2-py3-none-any.whl (8.6 kB)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 113.8 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_e4053b01c72b47158d277363f467309b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_e4053b01c72b47158d277363f467309b/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-qwkx7pri\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_e4053b01c72b47158d277363f467309b/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/audioread_e4053b01c72b47158d277363f467309b/setup.py:17: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_e4053b01c72b47158d277363f467309b/setup.py\", line 49, in <module>\n",
      "        python_requires='>=3.6',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/5d/cb/82a002441902dccbe427406785db07af10182245ee639ea9f4d92907c923/audioread-3.0.0.tar.gz#sha256=121995bd207eb1fda3d566beb851d3534275925bc35a4fb6da0cb11de0f7251a (from https://pypi.org/simple/audioread/) (requires-python:>=3.6). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 99.3 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_c6f1d54d52064173a38be5d86c23c628/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_c6f1d54d52064173a38be5d86c23c628/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-64f7_9jj\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_c6f1d54d52064173a38be5d86c23c628/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/audioread_c6f1d54d52064173a38be5d86c23c628/setup.py:17: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_c6f1d54d52064173a38be5d86c23c628/setup.py\", line 55, in <module>\n",
      "        'Programming Language :: Python :: 3.6',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b3/d1/e324634c5867a668774d6fe233a83228da4ba16521e19059c15df899737d/audioread-2.1.9.tar.gz#sha256=a3480e42056c8e80a8192a54f6729a280ef66d27782ee11cbd63e9d4d1523089 (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n",
      "\u001b[K     |████████████████████████████████| 252 kB 95.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.7.0-py3-none-any.whl (60 kB)\n",
      "\u001b[K     |████████████████████████████████| 60 kB 2.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
      "\u001b[K     |████████████████████████████████| 252 kB 118.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 116.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting resampy>=0.2.2\n",
      "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 114.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.9.1-py3-none-any.whl (213 kB)\n",
      "\u001b[K     |████████████████████████████████| 213 kB 119.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting audioread>=2.1.5\n",
      "  Downloading audioread-2.1.8.tar.gz (21 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_886a76d224154cb99cff216ba7585fc3/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_886a76d224154cb99cff216ba7585fc3/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-u5q4rqps\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_886a76d224154cb99cff216ba7585fc3/\n",
      "    Complete output (44 lines):\n",
      "    Keyring is skipped due to an exception: 'keyring.backends'\n",
      "    /tmp/pip-install-p48k5jnx/audioread_886a76d224154cb99cff216ba7585fc3/setup.py:17: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    /opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "      PkgResourcesDeprecationWarning,\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/installer.py:30: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "      SetuptoolsDeprecationWarning,\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_886a76d224154cb99cff216ba7585fc3/setup.py\", line 58, in <module>\n",
      "        'Programming Language :: Python :: 3.6',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 86, in setup\n",
      "        _install_setup_requires(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 80, in _install_setup_requires\n",
      "        dist.fetch_build_eggs(dist.setup_requires)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 877, in fetch_build_eggs\n",
      "        replace_conflicting=True,\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
      "        replace_conflicting=replace_conflicting\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1075, in best_match\n",
      "        return self.obtain(req, installer)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1087, in obtain\n",
      "        return installer(requirement)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 944, in fetch_build_egg\n",
      "        return fetch_build_egg(self, req)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/installer.py\", line 87, in fetch_build_egg\n",
      "        wheel.install_as_egg(dist_location)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/wheel.py\", line 110, in install_as_egg\n",
      "        self._install_as_egg(destination_eggdir, zf)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/wheel.py\", line 118, in _install_as_egg\n",
      "        self._convert_metadata(zf, destination_eggdir, dist_info, egg_info)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/wheel.py\", line 170, in _convert_metadata\n",
      "        extras_require=extras_require,\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/2e/0b/940ea7861e0e9049f09dcfd72a90c9ae55f697c17c299a323f0148f913d2/audioread-2.1.8.tar.gz#sha256=073904fabc842881e07bd3e4a5776623535562f70b1655b635d22886168dd168 (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading audioread-2.1.7.tar.gz (21 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_683be23f9e4a43b283ccce0b86a5155d/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_683be23f9e4a43b283ccce0b86a5155d/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-r1r9helx\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_683be23f9e4a43b283ccce0b86a5155d/\n",
      "    Complete output (44 lines):\n",
      "    Keyring is skipped due to an exception: 'keyring.backends'\n",
      "    /tmp/pip-install-p48k5jnx/audioread_683be23f9e4a43b283ccce0b86a5155d/setup.py:17: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    /opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py:126: PkgResourcesDeprecationWarning: 4.0.0-unsupported is an invalid version and will not be supported in a future release\n",
      "      PkgResourcesDeprecationWarning,\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/installer.py:30: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.\n",
      "      SetuptoolsDeprecationWarning,\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_683be23f9e4a43b283ccce0b86a5155d/setup.py\", line 58, in <module>\n",
      "        'Programming Language :: Python :: 3.6',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 86, in setup\n",
      "        _install_setup_requires(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 80, in _install_setup_requires\n",
      "        dist.fetch_build_eggs(dist.setup_requires)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 877, in fetch_build_eggs\n",
      "        replace_conflicting=True,\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
      "        replace_conflicting=replace_conflicting\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1075, in best_match\n",
      "        return self.obtain(req, installer)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/pkg_resources/__init__.py\", line 1087, in obtain\n",
      "        return installer(requirement)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 944, in fetch_build_egg\n",
      "        return fetch_build_egg(self, req)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/installer.py\", line 87, in fetch_build_egg\n",
      "        wheel.install_as_egg(dist_location)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/wheel.py\", line 110, in install_as_egg\n",
      "        self._install_as_egg(destination_eggdir, zf)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/wheel.py\", line 118, in _install_as_egg\n",
      "        self._convert_metadata(zf, destination_eggdir, dist_info, egg_info)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/wheel.py\", line 170, in _convert_metadata\n",
      "        extras_require=extras_require,\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/e6/33/46ada16d76548c2dfbcb8d06b3481df7ecd08239402b2e7f0086bffaed22/audioread-2.1.7.tar.gz#sha256=f488f9e6fa1ccb09289e3db194639bc6388168b27ef27b2c62380aa1d35a3abe (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading audioread-2.1.6.tar.gz (15 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_6c4d0000c2fe49979a4951ae45664abc/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_6c4d0000c2fe49979a4951ae45664abc/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-cbe7bf1c\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_6c4d0000c2fe49979a4951ae45664abc/\n",
      "    Complete output (19 lines):\n",
      "    /tmp/pip-install-p48k5jnx/audioread_6c4d0000c2fe49979a4951ae45664abc/setup.py:17: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_6c4d0000c2fe49979a4951ae45664abc/setup.py\", line 50, in <module>\n",
      "        'Programming Language :: Python :: 3.6',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/f0/41/8cd160c6b2046b997d571a744a7f398f39e954a62dd747b2aae1ad7f07d4/audioread-2.1.6.tar.gz#sha256=b0b9270c20833a75ce0d167fb2fdad52ddcd8e8f300be8afad3ac9715850bc50 (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading audioread-2.1.5.tar.gz (15 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_1f29364e050243a8b68bcc69c7693f29/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_1f29364e050243a8b68bcc69c7693f29/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-0872b0wz\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_1f29364e050243a8b68bcc69c7693f29/\n",
      "    Complete output (19 lines):\n",
      "    /tmp/pip-install-p48k5jnx/audioread_1f29364e050243a8b68bcc69c7693f29/setup.py:17: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_1f29364e050243a8b68bcc69c7693f29/setup.py\", line 50, in <module>\n",
      "        'Programming Language :: Python :: 3.6',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/21/81/d6dfb88379ab03d7f385c5a2e5ed045af0959418c38ce7cc4efc0fba0da2/audioread-2.1.5.tar.gz#sha256=36c3b118f097c58ba073b7d040c4319eff200756f094295677567e256282d0d7 (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.9.0-py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 108.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading librosa-0.8.1-py3-none-any.whl (203 kB)\n",
      "\u001b[K     |████████████████████████████████| 203 kB 119.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting audioread>=2.0.0\n",
      "  Downloading audioread-2.1.4.tar.gz (15 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_d1f7248cf101421f8882cf41e3b98e2e/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_d1f7248cf101421f8882cf41e3b98e2e/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-v2cnj7af\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_d1f7248cf101421f8882cf41e3b98e2e/\n",
      "    Complete output (17 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_d1f7248cf101421f8882cf41e3b98e2e/setup.py\", line 46, in <module>\n",
      "        'Programming Language :: Python :: 3.5',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/7a/d6/6d28473521ebf0b69174fbfdcca7e3ce46f6f9665af6c15bdfe880213076/audioread-2.1.4.tar.gz#sha256=8ffee2d2787258c214841853f600c52943baea9ad2303cb3d4b625cde4f08fff (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading audioread-2.1.3.tar.gz (14 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_a37aa754d2a8408886cddac6a406e01e/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_a37aa754d2a8408886cddac6a406e01e/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-tb06ur3l\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_a37aa754d2a8408886cddac6a406e01e/\n",
      "    Complete output (17 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_a37aa754d2a8408886cddac6a406e01e/setup.py\", line 46, in <module>\n",
      "        'Programming Language :: Python :: 3.5',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/00/07/6f6580ec31032712d282b7c54bb5d77a23835b9281550c7d17ed46e64b3d/audioread-2.1.3.tar.gz#sha256=e9dc54c8b9f18766a7e113ee467324119b03688b050b5a174c398d9f0d45f932 (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading audioread-2.1.2.tar.gz (14 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_a63101ae966747fcbdbe69e831b3ef8e/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_a63101ae966747fcbdbe69e831b3ef8e/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-sv4o3qx7\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_a63101ae966747fcbdbe69e831b3ef8e/\n",
      "    Complete output (17 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_a63101ae966747fcbdbe69e831b3ef8e/setup.py\", line 46, in <module>\n",
      "        'Programming Language :: Python :: 3.5',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/79/56/b9e55f213f7e0c75434275429c13afba5f0e02899a301ab804bc935cfefa/audioread-2.1.2.tar.gz#sha256=c624232c7e9341dd4283fc2777129f522bef3c3350b0e6f02b288799e1cba1af (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading audioread-2.1.1.tar.gz (14 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_3d5922692f614cde8089f369193eb1e9/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_3d5922692f614cde8089f369193eb1e9/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-9yhcumt0\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_3d5922692f614cde8089f369193eb1e9/\n",
      "    Complete output (17 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_3d5922692f614cde8089f369193eb1e9/setup.py\", line 46, in <module>\n",
      "        'Programming Language :: Python :: 3.5',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/94/64/b1eedccc27574cc84edf948f3ab3292b5b60be4757298dc7eef430792ebb/audioread-2.1.1.tar.gz#sha256=ffb601de7a9e40850d4ec3256a3a6bbe8fa40466dafb5c65f41b08e4bb963f1e (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading audioread-2.1.0.tar.gz (14 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_b13b6ecf664a40a9b56947934c3b95cb/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_b13b6ecf664a40a9b56947934c3b95cb/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-3l5xymro\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_b13b6ecf664a40a9b56947934c3b95cb/\n",
      "    Complete output (17 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_b13b6ecf664a40a9b56947934c3b95cb/setup.py\", line 46, in <module>\n",
      "        'Programming Language :: Python :: 3.5',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b8/48/55a6ca72f58d196dac573b9737ed5448dda1ddd463b9d6460ca745cd26c3/audioread-2.1.0.tar.gz#sha256=e576bd5c01d2a8c43c9447e6cbba3db32258b47b4b95ec2c3c9523b63f7b604a (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading audioread-2.0.0.tar.gz (14 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/audioread_2fc2a7d794624e679526c4d04d330484/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/audioread_2fc2a7d794624e679526c4d04d330484/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-gxw8kb3k\n",
      "         cwd: /tmp/pip-install-p48k5jnx/audioread_2fc2a7d794624e679526c4d04d330484/\n",
      "    Complete output (17 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/audioread_2fc2a7d794624e679526c4d04d330484/setup.py\", line 46, in <module>\n",
      "        'Programming Language :: Python :: 3.5',\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/4f/71/7e5a0d29b2565a8181ebf093fa0c6d5d4564c54c49080c7280f5303b0bfe/audioread-2.0.0.tar.gz#sha256=88c73dad947f92cdb98787d6f30913a3bce2636305ac4cd0dac1738908cb2055 (from https://pypi.org/simple/audioread/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.8.0.tar.gz (183 kB)\n",
      "\u001b[K     |████████████████████████████████| 183 kB 109.1 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_2cd26d56b29a4c4294632cfbd3745495/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_2cd26d56b29a4c4294632cfbd3745495/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-xssym_m9\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_2cd26d56b29a4c4294632cfbd3745495/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_2cd26d56b29a4c4294632cfbd3745495/setup.py\", line 65, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/26/4d/c22d8ca74ca2c13cd4ac430fa353954886104321877b65fa871939e78591/librosa-0.8.0.tar.gz#sha256=af0b9f2ed4bbf6aecbc448a4cd27c16453c397cb6bef0f0cfba0e63afea2b839 (from https://pypi.org/simple/librosa/) (requires-python:>=3.6). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 103.5 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_38103a693dde45808af106e923c503ae/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_38103a693dde45808af106e923c503ae/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-jramwcur\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_38103a693dde45808af106e923c503ae/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_38103a693dde45808af106e923c503ae/setup.py\", line 69, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz#sha256=656bbda80e98e6330db1ead79cd084b13a762284834d7603fcf7cf7c0dc65f3c (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.7.1.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 101.9 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_f405c4e836064738a0a47f22a7ca616b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_f405c4e836064738a0a47f22a7ca616b/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-ieuqsaeu\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_f405c4e836064738a0a47f22a7ca616b/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_f405c4e836064738a0a47f22a7ca616b/setup.py\", line 69, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/0b/71/c21ccef81276d85b9e3a36d80dad5baaf8a91f912e65eff0fd0d74a5a19c/librosa-0.7.1.tar.gz#sha256=cca58a2d9a47e35be63a3ce36482d241453bfe9b14bde2005430f969bd7d013a (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.7.0.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 83.9 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_87ea8029d80749a7966ccd92b2af3902/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_87ea8029d80749a7966ccd92b2af3902/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-rj0vekpj\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_87ea8029d80749a7966ccd92b2af3902/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_87ea8029d80749a7966ccd92b2af3902/setup.py\", line 68, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ad/6e/0eb0de1c9c4e02df0b40e56f258eb79bd957be79b918511a184268e01720/librosa-0.7.0.tar.gz#sha256=f9459dabe09e056e1cba39fe01365e50fb03db2f70f8673cfb2705353b759b81 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.6.3.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 106.7 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_107e56f2209943779abc931e877fb0ed/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_107e56f2209943779abc931e877fb0ed/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-qn8sfqac\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_107e56f2209943779abc931e877fb0ed/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_107e56f2209943779abc931e877fb0ed/setup.py\", line 65, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/e9/7e/7a0f66f79a70a0a4c163ecf30429f6c1644c88654f135a9eee0bda457626/librosa-0.6.3.tar.gz#sha256=b332225ac29bfae1ba386deca2b6566271576de3ab17617ad0a71892c799b118 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.6.2.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 94.7 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_48c3b174dd5b474981cd2ab9a38be344/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_48c3b174dd5b474981cd2ab9a38be344/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-44irk42q\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_48c3b174dd5b474981cd2ab9a38be344/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_48c3b174dd5b474981cd2ab9a38be344/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_48c3b174dd5b474981cd2ab9a38be344/setup.py\", line 54, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/09/b4/5b411f19de48f8fc1a0ff615555aa9124952e4156e94d4803377e50cfa4c/librosa-0.6.2.tar.gz#sha256=2aa868b8aade749b9904eeb7034fcf44115601c367969b6d01f5e1b4b9b6031d (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.6.1.tar.gz (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 108.2 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_867f82dd2d7148b29ac7d51868676e02/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_867f82dd2d7148b29ac7d51868676e02/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-mq22n6v6\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_867f82dd2d7148b29ac7d51868676e02/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_867f82dd2d7148b29ac7d51868676e02/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_867f82dd2d7148b29ac7d51868676e02/setup.py\", line 54, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/32/3d/7d1677f363bf2d576930be96371112a053264455885f40ff4299cd2a9348/librosa-0.6.1.tar.gz#sha256=3fd2dee31d51a3186ff098d4c651d84a81879c99662b1785d41482344c6ef761 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.6.0.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 108.4 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_b154306f015e4334ab23301485e8a4e9/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_b154306f015e4334ab23301485e8a4e9/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-xdjbva94\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_b154306f015e4334ab23301485e8a4e9/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_b154306f015e4334ab23301485e8a4e9/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_b154306f015e4334ab23301485e8a4e9/setup.py\", line 49, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/6b/f4/422bfbefd581f74354ef05176aa48558c548243c87e359d91512d4b65523/librosa-0.6.0.tar.gz#sha256=65b5169f4980a1ae73a7c82ac77ae11614ce3654d1f5df9af1dc0b09181b46fe (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.5.1.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 109.6 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_dbe32b628b4f411fa4a53048ba1c9150/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_dbe32b628b4f411fa4a53048ba1c9150/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-dp8hdj10\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_dbe32b628b4f411fa4a53048ba1c9150/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_dbe32b628b4f411fa4a53048ba1c9150/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_dbe32b628b4f411fa4a53048ba1c9150/setup.py\", line 49, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/51/c2/d8d8498252a2430ec9b90481754aca287c0ecc237a8feb331fa3b8933575/librosa-0.5.1.tar.gz#sha256=38db7d02600c9113401a66c0ce79bc75d2ef90ef778e2093bbbf5bc6e4640406 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.5.0.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 115.8 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_c68e5f7e353a42c2ac9faa3d0900e668/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_c68e5f7e353a42c2ac9faa3d0900e668/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-3dbkkdxi\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_c68e5f7e353a42c2ac9faa3d0900e668/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_c68e5f7e353a42c2ac9faa3d0900e668/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_c68e5f7e353a42c2ac9faa3d0900e668/setup.py\", line 49, in <module>\n",
      "        'display': ['matplotlib >= 1.5'],\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/79/1a/d8ff585588945fb4e86bf861c0b7b8b13954e40de442bf342cfe950bdcc0/librosa-0.5.0.tar.gz#sha256=72f67e5cbc3d3e6fe27a71b02ff81df15a610a91cd81380f69a03037981e253e (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.4.3.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 91.4 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_fa3d578a895f406ca1abaaa67d8f423a/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_fa3d578a895f406ca1abaaa67d8f423a/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-iy1yfh1x\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_fa3d578a895f406ca1abaaa67d8f423a/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_fa3d578a895f406ca1abaaa67d8f423a/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_fa3d578a895f406ca1abaaa67d8f423a/setup.py\", line 44, in <module>\n",
      "        'docs': ['numpydoc', 'seaborn', 'sphinx!=1.3.1', 'sphinx_rtd_theme']\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/50/91/c9bcda616c17b6d920e637b7b72cd3ab64a85ceed0353a4e6f4a56698007/librosa-0.4.3.tar.gz#sha256=209626c53556ca3922e52d2fae767bf5b398948c867fcc8898f948695dacb247 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.4.2.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 103.7 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_1c0fa651eb914ac18e809b2092f63c9f/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_1c0fa651eb914ac18e809b2092f63c9f/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-df9grj4p\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_1c0fa651eb914ac18e809b2092f63c9f/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_1c0fa651eb914ac18e809b2092f63c9f/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_1c0fa651eb914ac18e809b2092f63c9f/setup.py\", line 44, in <module>\n",
      "        'docs': ['numpydoc', 'seaborn', 'sphinx_rtd_theme']\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/c1/56/220add3ed779415d84eef86b91a1eb74d3cac3ef5c4d2ea651f435ff2141/librosa-0.4.2.tar.gz#sha256=51dbffe2d247acecc400df9879c4a11617dd01e109ef6edfcf6a6a19366d633a (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.4.1.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 105.2 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_b7e95cfcd00341ef898376ce8cd4b36c/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_b7e95cfcd00341ef898376ce8cd4b36c/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-03n2o_31\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_b7e95cfcd00341ef898376ce8cd4b36c/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_b7e95cfcd00341ef898376ce8cd4b36c/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_b7e95cfcd00341ef898376ce8cd4b36c/setup.py\", line 44, in <module>\n",
      "        'docs': ['numpydoc', 'seaborn', 'sphinx_rtd_theme']\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/06/b7/95618206ad90613acd0b5bb0ead7049c9dd683f986ff12fb7e3e46331255/librosa-0.4.1.tar.gz#sha256=8f29703309c7b59da045ee4760c4c73829c99b83e702fc61802d517fa23b337c (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.4.0.tar.gz (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 103.0 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_f4525f6df4f04c2ababd034374d2081e/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_f4525f6df4f04c2ababd034374d2081e/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-0a5jhdxe\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_f4525f6df4f04c2ababd034374d2081e/\n",
      "    Complete output (21 lines):\n",
      "    /tmp/pip-install-p48k5jnx/librosa_f4525f6df4f04c2ababd034374d2081e/setup.py:3: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "      import imp\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_f4525f6df4f04c2ababd034374d2081e/setup.py\", line 43, in <module>\n",
      "        'docs': ['numpydoc', 'seaborn', 'sphinx_rtd_theme']\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/d3/2d/b986cfa87188e2db5ffeea1f7558ec7bc5371bbce6d0709eaba839132303/librosa-0.4.0.tar.gz#sha256=cc11dcc41f51c08e442292e8a2fc7d7ee77e0d47ff771259eb63f57fcee6f6e7 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.3.1.tar.gz (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 111.2 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_0c2d41a2477f4b7ab062173db2633188/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_0c2d41a2477f4b7ab062173db2633188/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-gmfxdwsu\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_0c2d41a2477f4b7ab062173db2633188/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_0c2d41a2477f4b7ab062173db2633188/setup.py\", line 35, in <module>\n",
      "        'resample': 'scikits.samplerate>=0.3'\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/15/e6/e9aaaf9f8a6c251bf535aa8a0054c6004130aca2af4c3a3e997c26c795b4/librosa-0.3.1.tar.gz#sha256=98da251c4a6ff350e4f0303b927ef9fca93d6e747929934a4af986559a32a1b3 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.3.0.tar.gz (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 103.9 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_5c59b07afde9452c9d109398b5eee12c/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_5c59b07afde9452c9d109398b5eee12c/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-46k4djn9\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_5c59b07afde9452c9d109398b5eee12c/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_5c59b07afde9452c9d109398b5eee12c/setup.py\", line 31, in <module>\n",
      "        'resample': 'scikits.samplerate>=0.3'\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/63/91/36efac16a8646c133b895ec023125eb206ae9d0fa3625b8673c73870eedf/librosa-0.3.0.tar.gz#sha256=223908390acf2e7b567f8a858a4b318a998d5b8dd7d18601b002dae913851b64 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading librosa-0.2.1.tar.gz (36 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_0bc836325151413a87ccdc448675efed/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_0bc836325151413a87ccdc448675efed/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-rd_vnk2k\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_0bc836325151413a87ccdc448675efed/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_0bc836325151413a87ccdc448675efed/setup.py\", line 32, in <module>\n",
      "        'resample': 'scikits.samplerate >= 0.3'\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/55/ad/ecd21387e2d144befbdcc3f4d27c149fea5a5377ff888a985ebd5afe11ad/librosa-0.2.1.tar.gz#sha256=64aa9123d2133f8cf69be56a1d51c9c85a667ac6b9b02493e96bf53cbf572719 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "  Downloading librosa-0.2.0.tar.gz (32 kB)\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/librosa_4a1210f488754f1d9bcfcc5d21da6ea7/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/librosa_4a1210f488754f1d9bcfcc5d21da6ea7/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-mgyya4uu\n",
      "         cwd: /tmp/pip-install-p48k5jnx/librosa_4a1210f488754f1d9bcfcc5d21da6ea7/\n",
      "    Complete output (19 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/librosa_4a1210f488754f1d9bcfcc5d21da6ea7/setup.py\", line 32, in <module>\n",
      "        'resample': 'scikits.samplerate >= 0.3'\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/97/f4/13ef24552a474a3a9061146202632662e3473d6a87e4540c46fbebeac9b3/librosa-0.2.0.tar.gz#sha256=13543733c9652aa245c4b590da5fa9f1b3057f180e667ca863bc2f591dd571b9 (from https://pypi.org/simple/librosa/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "INFO: pip is looking at multiple versions of yarl to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 110.0 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "\u001b[K     |████████████████████████████████| 231 kB 115.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 122.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 118.9 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.7.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
      "\u001b[K     |████████████████████████████████| 271 kB 123.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 118.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.6.2-cp37-cp37m-manylinux2014_x86_64.whl (295 kB)\n",
      "\u001b[K     |████████████████████████████████| 295 kB 116.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.6.1-cp37-cp37m-manylinux2014_x86_64.whl (295 kB)\n",
      "\u001b[K     |████████████████████████████████| 295 kB 125.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (258 kB)\n",
      "\u001b[K     |████████████████████████████████| 258 kB 121.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (258 kB)\n",
      "\u001b[K     |████████████████████████████████| 258 kB 118.0 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.4.2-cp37-cp37m-manylinux1_x86_64.whl (256 kB)\n",
      "\u001b[K     |████████████████████████████████| 256 kB 120.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.4.1-cp37-cp37m-manylinux1_x86_64.whl (255 kB)\n",
      "\u001b[K     |████████████████████████████████| 255 kB 106.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (255 kB)\n",
      "\u001b[K     |████████████████████████████████| 255 kB 121.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading yarl-1.3.0.tar.gz (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 122.0 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_c81645a85656492d861691eea96621c8/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_c81645a85656492d861691eea96621c8/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-xz5g0_vb\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_c81645a85656492d861691eea96621c8/\n",
      "    Complete output (23 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n",
      "      warnings.warn(msg, warning_class)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_c81645a85656492d861691eea96621c8/setup.py\", line 102, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/fb/84/6d82f6be218c50b547aa29d0315e430cf8a23c52064c92d0a8377d7b7357/yarl-1.3.0.tar.gz#sha256=024ecdc12bc02b321bc66b41327f930d1c2c543fa9a561b39861da9388ba7aa9 (from https://pypi.org/simple/yarl/) (requires-python:>=3.5.3). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.2.6.tar.gz (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 100.9 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_59fabf30553e41ac99b01e65d084049b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_59fabf30553e41ac99b01e65d084049b/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-t_e3srj6\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_59fabf30553e41ac99b01e65d084049b/\n",
      "    Complete output (23 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n",
      "      warnings.warn(msg, warning_class)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_59fabf30553e41ac99b01e65d084049b/setup.py\", line 103, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/43/b8/057c3e5b546ff4b24263164ecda13f6962d85c9dc477fcc0bcdcb3adb658/yarl-1.2.6.tar.gz#sha256=c8cbc21bbfa1dd7d5386d48cc814fe3d35b80f60299cdde9279046f399c3b0d8 (from https://pypi.org/simple/yarl/) (requires-python:>=3.5.3). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.2.5.tar.gz (160 kB)\n",
      "\u001b[K     |████████████████████████████████| 160 kB 94.7 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_9a9754caf68540409d248a5855192dee/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_9a9754caf68540409d248a5855192dee/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-dd5dg7kd\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_9a9754caf68540409d248a5855192dee/\n",
      "    Complete output (23 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n",
      "      warnings.warn(msg, warning_class)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_9a9754caf68540409d248a5855192dee/setup.py\", line 104, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/20/e7/dfebda1c1f1690f102f4f16b2add843aeeed2b692ab16be758641fe16e83/yarl-1.2.5.tar.gz#sha256=dd5da4150a882f5cd26aeec7939f38e4b08b790717b9d696409dba9e18ff3ab6 (from https://pypi.org/simple/yarl/) (requires-python:>=3.5.3). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.2.4.tar.gz (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 105.7 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_623f0aad336c4065aab856ed2b7243b5/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_623f0aad336c4065aab856ed2b7243b5/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-yq6saea0\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_623f0aad336c4065aab856ed2b7243b5/\n",
      "    Complete output (23 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n",
      "      warnings.warn(msg, warning_class)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_623f0aad336c4065aab856ed2b7243b5/setup.py\", line 104, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/6b/0f/7551d131e3a116bdb8e23bde3f34613cd3ad719f28dcf996c922fe285925/yarl-1.2.4.tar.gz#sha256=437c51e7e31d9fa462ad99f829fb8282eccba836d67868ab61a513d20ec467b7 (from https://pypi.org/simple/yarl/) (requires-python:>=3.5.3). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.2.3.tar.gz (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 100.9 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_2aa0cdf064314c33956b29a4f4185a57/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_2aa0cdf064314c33956b29a4f4185a57/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-fgmv82jf\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_2aa0cdf064314c33956b29a4f4185a57/\n",
      "    Complete output (23 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n",
      "      warnings.warn(msg, warning_class)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_2aa0cdf064314c33956b29a4f4185a57/setup.py\", line 104, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/a9/9b/966b8bb5760a784fb777df619f0f44029fe1bbc9d5bd0da246ca5cfc8cf3/yarl-1.2.3.tar.gz#sha256=1fc3e17ab13e46cae1a6067ad4c210d6efa378267d312ed6a47803d0e5ca0d97 (from https://pypi.org/simple/yarl/) (requires-python:>=3.5.3). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.2.2.tar.gz (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 99.7 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_806f57d51fde437da8a136d2208da617/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_806f57d51fde437da8a136d2208da617/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-z1iq_wzq\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_806f57d51fde437da8a136d2208da617/\n",
      "    Complete output (23 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n",
      "      warnings.warn(msg, warning_class)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_806f57d51fde437da8a136d2208da617/setup.py\", line 104, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/b1/fa/1662b6f358a863e563fa871e4f1c91c8ef250de32db2029548a9f8005a5f/yarl-1.2.2.tar.gz#sha256=a3bd7788294d7e1ad6bb34afb18ee4dba9f94536e4ca58f8b0fe4d6625e51ffb (from https://pypi.org/simple/yarl/) (requires-python:>=3.5.3). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.2.1.tar.gz (158 kB)\n",
      "\u001b[K     |████████████████████████████████| 158 kB 98.5 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_25dc0de7aa094b87ae3e2d69890fde58/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_25dc0de7aa094b87ae3e2d69890fde58/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-igbu29pg\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_25dc0de7aa094b87ae3e2d69890fde58/\n",
      "    Complete output (23 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n",
      "      warnings.warn(msg, warning_class)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_25dc0de7aa094b87ae3e2d69890fde58/setup.py\", line 104, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/ce/25/b3d7a22780f84e7c32a35a5c1747c2b36ef617c94334f6b61c3b7ca9b8d1/yarl-1.2.1.tar.gz#sha256=9085882fc43965530b781cf376ce9ea51827a7e79be825ad21eed2a2770a848b (from https://pypi.org/simple/yarl/) (requires-python:>=3.5.3). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.2.0.tar.gz (157 kB)\n",
      "\u001b[K     |████████████████████████████████| 157 kB 102.1 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_3a63684429e345bab78c26304b41b147/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_3a63684429e345bab78c26304b41b147/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-9__45arw\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_3a63684429e345bab78c26304b41b147/\n",
      "    Complete output (23 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    /opt/conda/lib/python3.7/site-packages/setuptools/config/setupcfg.py:508: SetuptoolsDeprecationWarning: The license_file parameter is deprecated, use license_files instead.\n",
      "      warnings.warn(msg, warning_class)\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_3a63684429e345bab78c26304b41b147/setup.py\", line 103, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/63/9f/1cfd6d213ca534589f864a478573103771559c9cec14473bb09412f0d2f8/yarl-1.2.0.tar.gz#sha256=fbbb10276d53629c0300cfd4a2092e3bbfa9a5aa95cd49808e01c59492052077 (from https://pypi.org/simple/yarl/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.1.1.tar.gz (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 96.4 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_9b95df4183474bf48d5ed782f19993d1/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_9b95df4183474bf48d5ed782f19993d1/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-14ez7wrr\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_9b95df4183474bf48d5ed782f19993d1/\n",
      "    Complete output (21 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_9b95df4183474bf48d5ed782f19993d1/setup.py\", line 103, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/91/14/5983db75b143681058d31a0a89a770f40a7f68f9b94cfeb6e6495b0039bf/yarl-1.1.1.tar.gz#sha256=a69dd7e262cdb265ac7d5e929d55f2f3d07baaadd158c8f19caebf8dde08dfe8 (from https://pypi.org/simple/yarl/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.1.0.tar.gz (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 109.2 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_d4832f1506414e0eb38d8a74e6d11bed/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_d4832f1506414e0eb38d8a74e6d11bed/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-v5xbyaul\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_d4832f1506414e0eb38d8a74e6d11bed/\n",
      "    Complete output (21 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_d4832f1506414e0eb38d8a74e6d11bed/setup.py\", line 103, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/a3/08/05b2d731ef5163b3bcb993f569c4d2b303642f7ee3cbdea373f59e4bd42a/yarl-1.1.0.tar.gz#sha256=6af895b45bd49254cc309ac0fe6e1595636a024953d710e01114257736184698 (from https://pypi.org/simple/yarl/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25h  Downloading yarl-1.0.0.tar.gz (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 103.7 MB/s eta 0:00:01\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-p48k5jnx/yarl_11163b57efc446d28ae5417b59364abd/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-p48k5jnx/yarl_11163b57efc446d28ae5417b59364abd/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base /tmp/pip-pip-egg-info-qu48stao\n",
      "         cwd: /tmp/pip-install-p48k5jnx/yarl_11163b57efc446d28ae5417b59364abd/\n",
      "    Complete output (21 lines):\n",
      "    Compiling yarl/_quoting.pyx because it depends on /opt/conda/lib/python3.7/site-packages/Cython/Includes/libc/string.pxd.\n",
      "    [1/1] Cythonizing yarl/_quoting.pyx\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-p48k5jnx/yarl_11163b57efc446d28ae5417b59364abd/setup.py\", line 103, in <module>\n",
      "        setup(**args)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/__init__.py\", line 87, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/core.py\", line 147, in setup\n",
      "        _setup_distribution = dist = klass(attrs)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 479, in __init__\n",
      "        for k, v in attrs.items()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_distutils/dist.py\", line 283, in __init__\n",
      "        self.finalize_options()\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 898, in finalize_options\n",
      "        for ep in sorted(loaded, key=by_order):\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/dist.py\", line 897, in <lambda>\n",
      "        loaded = map(lambda e: e.load(), filtered)\n",
      "      File \"/opt/conda/lib/python3.7/site-packages/setuptools/_vendor/importlib_metadata/__init__.py\", line 196, in load\n",
      "        return functools.reduce(getattr, attrs, module)\n",
      "    AttributeError: type object 'Distribution' has no attribute '_finalize_feature_opts'\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/33/92/2fa917aa6961d35fe2809fd16200441f49a347313a203b75f6a1b03915ba/yarl-1.0.0.tar.gz#sha256=5ea610467a04d99bfc8878186330b28859eafc6ca589cdd24ba6fb7234c4b011 (from https://pypi.org/simple/yarl/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of yarl to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "INFO: pip is looking at multiple versions of urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 109.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 123.4 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 121.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 119.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 117.2 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 111.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 117.6 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 119.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 123.8 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
      "\u001b[K     |████████████████████████████████| 138 kB 86.5 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "\u001b[K     |████████████████████████████████| 153 kB 123.2 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.3-py2.py3-none-any.whl (137 kB)\n",
      "\u001b[K     |████████████████████████████████| 137 kB 121.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.2-py2.py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 121.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.1-py2.py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 115.3 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.26.0-py2.py3-none-any.whl (136 kB)\n",
      "\u001b[K     |████████████████████████████████| 136 kB 111.7 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 117.2 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading urllib3-1.25.10-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 107.9 MB/s eta 0:00:01\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "INFO: pip is looking at multiple versions of urllib3 to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "INFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "  Downloading typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "  Downloading typing_extensions-4.1.0-py3-none-any.whl (26 kB)\n",
      "  Downloading typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
      "  Downloading typing_extensions-4.0.0-py3-none-any.whl (22 kB)\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "  Downloading typing_extensions-3.10.0.1-py3-none-any.whl (26 kB)\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "INFO: pip is looking at multiple versions of typing-extensions to determine which version is compatible with other requirements. This could take a while.\n",
      "INFO: pip is looking at multiple versions of tqdm to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tqdm>=4.62.1\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[?25h  Downloading tqdm-4.63.2-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 1.0 MB/s s eta 0:00:01\n",
      "\u001b[?25h  Downloading tqdm-4.63.1-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 856 kB/s s eta 0:00:01\n",
      "\u001b[?25h  Downloading tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 891 kB/s s eta 0:00:01\n",
      "\u001b[?25h  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 789 kB/s s eta 0:00:01\n",
      "\u001b[?25h  Downloading tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 782 kB/s s eta 0:00:01\n",
      "\u001b[?25h  Downloading tqdm-4.62.1-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 900 kB/s s eta 0:00:01\n",
      "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r speech-pretraining/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0e45a3-da26-48a4-9623-2abd6bcb99f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset librispeech_asr/clean to /root/.cache/huggingface/datasets/librispeech_asr/clean/2.1.0/cff5df6e7955c80a67f80e27e7e655de71c689e2d2364bece785b972acb37fe7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5c45b761554d1884a4914c611bdf74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8429b109e8564d5f882371b37dadd20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fe2c1a3a91470e902876a95af00551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train.100 split:   0%|          | 0/28539 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0m_soundfile_data\u001b[0m  \u001b[0;31m# ImportError if this doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0m_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_soundfile_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TypeError if __file__ is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_soundfile_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_libname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sndfile library not found using ctypes.util.find_library'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0m_snd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_libname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: sndfile library not found using ctypes.util.find_library",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[1;32m   1624\u001b[0m                         )\n\u001b[0;32m-> 1625\u001b[0;31m                     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_example\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             }\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1214\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1215\u001b[0m             }\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj, level)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassLabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTranslationVariableLanguages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ArrayXD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m     \u001b[0;31m# Other object should be directly convertible to a native Arrow type (like Translation and Translation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/features/audio.py\u001b[0m in \u001b[0;36mencode_example\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msf\u001b[0m  \u001b[0;31m# soundfile is a dependency of librosa, needed to decode audio files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/soundfile.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0m_snd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ffi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_explicit_libname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot load library 'libsndfile.so': libsndfile.so: cannot open shared object file: No such file or directory",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-42d593646996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"argv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mrun_wav2vec2_pretraining_no_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ForPreTraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massertIsNotNone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/transformers/examples/pytorch/speech-pretraining/run_wav2vec2_pretraining_no_trainer.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mdataset_config_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_split_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m         )\n\u001b[1;32m    443\u001b[0m         \u001b[0mdatasets_splits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, **config_kwargs)\u001b[0m\n\u001b[1;32m   1785\u001b[0m         \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mtry_from_hf_gcs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtry_from_hf_gcs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1787\u001b[0;31m         \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1788\u001b[0m     )\n\u001b[1;32m   1789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    874\u001b[0m                             \u001b[0mverification_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                             \u001b[0;34m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m                             \u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m                         )\n\u001b[1;32m    878\u001b[0m                     \u001b[0;31m# Sync info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1652\u001b[0m             \u001b[0mcheck_duplicate_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverification_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mVerificationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBASIC_CHECKS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mverification_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mVerificationMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_CHECKS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mprepare_splits_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1655\u001b[0m         )\n\u001b[1;32m   1656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m                 \u001b[0;31m# Prepare split will record examples associated to the split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    968\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m                 raise OSError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_prepare_split\u001b[0;34m(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m             for job_id, done, content in self._prepare_split_single(\n\u001b[0;32m-> 1489\u001b[0;31m                 \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_prepare_split_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m             ):\n\u001b[1;32m   1491\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_prepare_split_single\u001b[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\u001b[0m\n\u001b[1;32m   1642\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSchemaInferenceError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__context__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m                 \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__context__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDatasetGenerationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"An error occurred while generating the dataset\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_num_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_num_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_shards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshard_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDatasetGenerationError\u001b[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_wav2vec2_pretraining_no_trainer.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path hf-internal-testing/tiny-random-wav2vec2\n",
    "    --dataset_name librispeech_asr\n",
    "    --dataset_config_names clean\n",
    "    --dataset_split_names validation\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 4\n",
    "    --per_device_eval_batch_size 4\n",
    "    --preprocessing_num_workers 16\n",
    "    --max_train_steps 2\n",
    "    --validation_split_percentage 5\n",
    "    --seed 42\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_wav2vec2_pretraining_no_trainer.main()\n",
    "    model = Wav2Vec2ForPreTraining.from_pretrained(tmp_dir)\n",
    "    self.assertIsNotNone(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396d71f-11fb-491b-98e3-4900184830bc",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f1c0a34-9136-4218-b4a5-3703ae93ce15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_ner\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96a28beb-ea88-4d61-9f8c-16c91b2b3ead",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -r token-classification/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c4b5fb1-13da-43ba-89dc-99b594551d95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 22 16:16:04 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10G         Off  | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   24C    P0    55W / 300W |   6535MiB / 22731MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d0a645e9-48cc-4da9-b59f-e8f3d8ea03eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-23 15:42:38,042 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-23 15:42:38,042 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 15:42:38 - WARNING - run_ner - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
      "03/23/2023 15:42:38 - INFO - run_ner - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpecuep_dj/runs/Mar23_15-42-38_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_warmup,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpecuep_dj,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpecuep_dj,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/23/2023 15:42:38 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/xglue/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08\n",
      "03/23/2023 15:42:38 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/23/2023 15:42:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/xglue/ner/1.0.0/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08\n",
      "03/23/2023 15:42:38 - WARNING - datasets.builder - Found cached dataset xglue (/root/.cache/huggingface/datasets/xglue/ner/1.0.0/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08)\n",
      "03/23/2023 15:42:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/xglue/ner/1.0.0/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce7fc22605444ecb0cfa2a22f14b6f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cfac08aa8aa4e68b8dd0a7e4b1cb20e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/456 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-23 15:42:38,626 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 15:42:38,627 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert/camembert-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"ner\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-23 15:42:38,672 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 15:42:38,703 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 15:42:38,705 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert/camembert-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeefa257f700442daf0937722e6c3bdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/809k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:42:39,036 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/sentencepiece.bpe.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:42:39,037 >> loading file tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:42:39,038 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:42:39,038 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:42:39,039 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 15:42:39,045 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 15:42:39,046 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert/camembert-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 15:42:39,110 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 15:42:39,111 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert/camembert-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fbfe395cd94c39ad8d260ca3ffe934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.35G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|modeling_utils.py:2398] 2023-03-23 15:43:26,823 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/pytorch_model.bin\n",
      "[WARNING|modeling_utils.py:3010] 2023-03-23 15:43:33,744 >> Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3022] 2023-03-23 15:43:33,745 >> Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on train dataset:   0%|          | 0/14042 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING|tokenization_utils_base.py:2425] 2023-03-23 15:43:33,787 >> Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 15:43:33 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/xglue/ner/1.0.0/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08/cache-2b27230313dc344b.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-23 15:43:35,273 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:597] 2023-03-23 15:43:35,274 >> Using cuda_amp half precision backend\n",
      "[INFO|trainer.py:739] 2023-03-23 15:43:35,275 >> The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: words, ner. If words, ner are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:1758] 2023-03-23 15:43:35,284 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-23 15:43:35,285 >>   Num examples = 14042\n",
      "[INFO|trainer.py:1760] 2023-03-23 15:43:35,286 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1761] 2023-03-23 15:43:35,286 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:1762] 2023-03-23 15:43:35,287 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1763] 2023-03-23 15:43:35,287 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-23 15:43:35,288 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-23 15:43:35,290 >>   Number of trainable parameters = 335621129\n",
      "[WARNING|logging.py:280] 2023-03-23 15:43:35,295 >> You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:10, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.297800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.280200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.268500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.269500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.258300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.233200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.212700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.199000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.196000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.182800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.161700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.171400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.151100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.151300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.133400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.132700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.070700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.075100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.045600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.040500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.993400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.990200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.977800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.976200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.957300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.929400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.925700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.925100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.900500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.902200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.880200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.898700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.874600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.874300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.864700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>1.861600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>1.852100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>1.837300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>1.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>1.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.838000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>1.795900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>1.810300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>1.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>1.777300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.779500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>1.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>1.767300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>1.767100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.723400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>1.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>1.715200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>1.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>1.718600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>1.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>1.662700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>1.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>1.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.667000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>1.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>1.646300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>1.647100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>1.624700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>1.651300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>1.624400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>1.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>1.604800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.591800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>1.579900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>1.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>1.554100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>1.574000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.541000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-23 15:45:45,500 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-23 15:45:45,502 >> Saving model checkpoint to /tmp/tmpecuep_dj\n",
      "[INFO|configuration_utils.py:457] 2023-03-23 15:45:45,504 >> Configuration saved in /tmp/tmpecuep_dj/config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-23 15:45:46,459 >> Model weights saved in /tmp/tmpecuep_dj/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2163] 2023-03-23 15:45:46,461 >> tokenizer config file saved in /tmp/tmpecuep_dj/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-03-23 15:45:46,462 >> Special tokens file saved in /tmp/tmpecuep_dj/special_tokens_map.json\n",
      "[INFO|modelcard.py:449] 2023-03-23 15:45:46,552 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Token Classification', 'type': 'token-classification'}, 'dataset': {'name': 'xglue ner', 'type': 'xglue', 'config': 'ner', 'split': 'train', 'args': 'ner'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       1.14\n",
      "  total_flos               =  2044570GF\n",
      "  train_loss               =     1.9292\n",
      "  train_runtime            = 0:02:10.21\n",
      "  train_samples            =      14042\n",
      "  train_samples_per_second =    122.878\n",
      "  train_steps_per_second   =       7.68\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_ner.py\n",
    "    --model_name_or_path camembert/camembert-large\n",
    "    --dataset_name xglue\n",
    "    --dataset_config ner\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --do_train\n",
    "    --max_steps=1000\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=16\n",
    "    --save_strategy no\n",
    "    --seed 42\n",
    "    --logging_steps 10\n",
    "    --fp16 true\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "#     --lr_scheduler_type greedy\n",
    "#     --logging_steps 10\n",
    "#     --min_lr=1e-5\n",
    "#     --smooth True\n",
    "#     --patience 10\n",
    "#     --factor 0.95\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_ner.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    \n",
    "    \n",
    "    # --optim: invalid choice: 'as' (choose from 'adamw_hf', 'adamw_torch', 'adamw_torch_xla', 'adamw_apex_fused', 'adafactor', 'adamw_bnb_8bit', 'adamw_anyprecision', 'sgd', 'adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "363fc7c6-da67-4367-9820-370063359ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'pymp*': No such file or directory\n",
      "rm: cannot remove './tmp*': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6ad74ccd-b3d8-4d3e-9468-12472ca06f4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-23 15:45:47,424 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-23 15:45:47,425 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 15:45:47 - WARNING - run_ner - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: True\n",
      "03/23/2023 15:45:47 - INFO - run_ner - Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=-1,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.95,\n",
      "fp16=True,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp5tk46jw1/runs/Mar23_15-45-47_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=greedy,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=1e-05,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=sgd,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp5tk46jw1,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp5tk46jw1,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/23/2023 15:45:47 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/xglue/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08\n",
      "03/23/2023 15:45:47 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/23/2023 15:45:47 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/xglue/ner/1.0.0/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08\n",
      "03/23/2023 15:45:47 - WARNING - datasets.builder - Found cached dataset xglue (/root/.cache/huggingface/datasets/xglue/ner/1.0.0/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08)\n",
      "03/23/2023 15:45:47 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/xglue/ner/1.0.0/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d987f7fc9ba54f788f6cfbf0b815349f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-23 15:45:47,896 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 15:45:47,898 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert/camembert-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"finetuning_task\": \"ner\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-23 15:45:47,929 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 15:45:47,957 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 15:45:47,958 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert/camembert-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:45:48,015 >> loading file sentencepiece.bpe.model from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/sentencepiece.bpe.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:45:48,016 >> loading file tokenizer.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:45:48,017 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:45:48,017 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-23 15:45:48,018 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 15:45:48,022 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 15:45:48,023 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert/camembert-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:668] 2023-03-23 15:45:48,077 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-23 15:45:48,078 >> Model config CamembertConfig {\n",
      "  \"_name_or_path\": \"camembert/camembert-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"camembert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32005\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-23 15:45:48,175 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--camembert--camembert-large/snapshots/df7dbf53dd70551faa6b4ec45deb4a566445c7cc/pytorch_model.bin\n",
      "[WARNING|modeling_utils.py:3010] 2023-03-23 15:45:51,006 >> Some weights of the model checkpoint at camembert/camembert-large were not used when initializing CamembertForTokenClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[WARNING|modeling_utils.py:3022] 2023-03-23 15:45:51,007 >> Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at camembert/camembert-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/23/2023 15:45:51 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/xglue/ner/1.0.0/8566eedecd9ab28e01c051c023dadf97bf408e5195f76b06aba70ebd4697ae08/cache-2b27230313dc344b.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-23 15:45:51,252 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:597] 2023-03-23 15:45:51,253 >> Using cuda_amp half precision backend\n",
      "[INFO|trainer.py:739] 2023-03-23 15:45:51,254 >> The following columns in the training set don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: words, ner. If words, ner are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "[INFO|trainer.py:1758] 2023-03-23 15:45:51,263 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-23 15:45:51,264 >>   Num examples = 14042\n",
      "[INFO|trainer.py:1760] 2023-03-23 15:45:51,264 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1761] 2023-03-23 15:45:51,265 >>   Instantaneous batch size per device = 16\n",
      "[INFO|trainer.py:1762] 2023-03-23 15:45:51,265 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1763] 2023-03-23 15:45:51,267 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-23 15:45:51,267 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-23 15:45:51,269 >>   Number of trainable parameters = 335621129\n",
      "[WARNING|logging.py:280] 2023-03-23 15:45:51,273 >> You're using a CamembertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GreedyLR settings: patience=10 smooth=True min_lr=1e-05 factor=0.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:09, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.310300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.297800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.295300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.280200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.268500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.269100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.257500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.239500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.242000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.236800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.227600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.208400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.204600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.183500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.178800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.137300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.141200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.087700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.077300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.066600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.046000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>1.977700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.965100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>1.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>1.926900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>1.888000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1.859200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.849400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>1.823000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>1.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>1.758000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>1.720300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.726800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>1.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>1.638100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>1.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>1.573400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.544500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>1.503100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>1.477000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>1.398800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>1.360500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.320900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>1.299300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>1.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>1.182700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>1.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.141800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>1.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>1.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>1.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.882000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.842400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.890500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.815100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.775800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.746700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.767600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.793100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.787100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.737600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.689400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.733400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.675200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.684000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.662200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.613400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.621500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.637700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.597500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.648100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.676700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.641200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.585100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.553700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.527600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.549800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-23 15:48:01,327 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|trainer.py:2834] 2023-03-23 15:48:01,331 >> Saving model checkpoint to /tmp/tmp5tk46jw1\n",
      "[INFO|configuration_utils.py:457] 2023-03-23 15:48:01,333 >> Configuration saved in /tmp/tmp5tk46jw1/config.json\n",
      "[INFO|modeling_utils.py:1762] 2023-03-23 15:48:02,291 >> Model weights saved in /tmp/tmp5tk46jw1/pytorch_model.bin\n",
      "[INFO|tokenization_utils_base.py:2163] 2023-03-23 15:48:02,293 >> tokenizer config file saved in /tmp/tmp5tk46jw1/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2170] 2023-03-23 15:48:02,295 >> Special tokens file saved in /tmp/tmp5tk46jw1/special_tokens_map.json\n",
      "[INFO|modelcard.py:449] 2023-03-23 15:48:02,380 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Token Classification', 'type': 'token-classification'}, 'dataset': {'name': 'xglue ner', 'type': 'xglue', 'config': 'ner', 'split': 'train', 'args': 'ner'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       1.14\n",
      "  total_flos               =  2044570GF\n",
      "  train_loss               =     1.3753\n",
      "  train_runtime            = 0:02:10.05\n",
      "  train_samples            =      14042\n",
      "  train_samples_per_second =    123.021\n",
      "  train_steps_per_second   =      7.689\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_ner.py\n",
    "    --model_name_or_path camembert/camembert-large\n",
    "    --dataset_name xglue\n",
    "    --dataset_config ner\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --do_train\n",
    "    --max_steps=1000\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=16\n",
    "    --save_strategy no\n",
    "    --seed 42\n",
    "    --logging_steps 10\n",
    "    --fp16 true\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --fp16 True\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_ner.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "cff33a14-c3bf-4e9d-b2a1-b06e9082151d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "738b17c0-a916-4fe5-aca3-d7941246655a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LRs')"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d081d889-fe76-4eb1-9929-2516536573e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss')"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_figheight(4)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "cb029095-b388-4802-b5d4-43fa1a787665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9912"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(d1[-1][int(0.1*len(d1[-1]))-1] > d2[-1][int(0.1*len(d2[-1]))-1])\n",
    "# print(d1[-1][int(0.5*len(d1[-1]))-1] > d2[-1][int(0.5*len(d2[-1]))-1])\n",
    "# print(d1[-1][int(1*len(d1[-1]))-1] > d2[-1][int(1*len(d2[-1]))-1])\n",
    "\n",
    "\n",
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26df4887-3e62-44aa-9e86-20effde50418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "SRC_DIRS = [\n",
    "    os.path.join('./', dirname) for dirname in [\n",
    "        \"text-generation\",\n",
    "        \"text-classification\",\n",
    "        \"token-classification\",\n",
    "        \"language-modeling\",\n",
    "        \"multiple-choice\",\n",
    "        \"question-answering\",\n",
    "        \"summarization\",\n",
    "        \"translation\",\n",
    "        \"image-classification\",\n",
    "        \"speech-recognition\",\n",
    "        \"audio-classification\",\n",
    "        \"speech-pretraining\",\n",
    "        \"image-pretraining\",\n",
    "        \"semantic-segmentation\",\n",
    "    ]\n",
    "]\n",
    "sys.path.extend(SRC_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5bd42-3a1e-4492-a885-94c16bea8176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22c63d-c80d-42fd-941a-f3cce42bd534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g5.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
