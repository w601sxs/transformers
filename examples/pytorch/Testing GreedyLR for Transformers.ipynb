{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109ba453-d065-4aa3-ab70-a054b49a28d0",
   "metadata": {},
   "source": [
    "# Testing ⏭ GreedLR Scheduler for 🤗 Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4360d05-6e8a-4951-a611-7b4b345a71b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ff579-2386-4114-b011-92c064f6f2ee",
   "metadata": {},
   "source": [
    "### Need to reinstall from source to register changes\n",
    "\n",
    "(may need to restart kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b0058d-4f24-43e4-af9d-510a5f02247d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate>=0.12.0 in /opt/conda/lib/python3.9/site-packages (from -r translation/requirements.txt (line 1)) (0.16.0)\n",
      "Requirement already satisfied: datasets>=1.8.0 in /opt/conda/lib/python3.9/site-packages (from -r translation/requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.9/site-packages (from -r translation/requirements.txt (line 3)) (0.1.97)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.9/site-packages (from -r translation/requirements.txt (line 4)) (3.20.2)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.9/site-packages (from -r translation/requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: py7zr in /opt/conda/lib/python3.9/site-packages (from -r translation/requirements.txt (line 6)) (0.20.4)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.9/site-packages (from -r translation/requirements.txt (line 7)) (1.13.1+cu117)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.9/site-packages (from -r translation/requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (1.23.5)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2023.1.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.8.4)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.13.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.5.3)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (0.4.4)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.9/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.9/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (2022.10.31)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.9/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (4.9.2)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.9/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /opt/conda/lib/python3.9/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.9/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.2.3)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in /opt/conda/lib/python3.9/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.15.4)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.9/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.6.7)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (3.17)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in /opt/conda/lib/python3.9/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in /opt/conda/lib/python3.9/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.9/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (4.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.1.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (22.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.9/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (4.0.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Obtaining file:///root/transformers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (1.23.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (23.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (0.13.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.27.0.dev1) (0.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev1) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.27.0.dev1) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.27.0.dev1) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.27.0.dev1) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.27.0.dev1) (1.26.14)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building editable for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.27.0.dev1-0.editable-py3-none-any.whl size=34577 sha256=7b8b1ba0ccc4a02285bca1643653e84808dd8206d855780c2c9dd20f55bdfa88\n",
      "  Stored in directory: /root/transformers/examples/pytorch/pip-ephem-wheel-cache-lf2pj9mo/wheels/c6/d4/24/fe65e904e9dddeaa02668d56c7a9bd848371752e768d6bb33b\n",
      "Successfully built transformers\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.27.0.dev1\n",
      "    Uninstalling transformers-4.27.0.dev1:\n",
      "      Successfully uninstalled transformers-4.27.0.dev1\n",
      "Successfully installed transformers-4.27.0.dev1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r translation/requirements.txt\n",
    "%pip install -e ~/transformers/ #Or wherever you downloaded this source "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea6e78-81cf-414a-a3d4-0a25fe776125",
   "metadata": {},
   "source": [
    "Add test folders to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b2dee55-2640-4b77-a261-b81d634e8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "SRC_DIRS = [\n",
    "    os.path.join('./', dirname) for dirname in [\n",
    "        \"text-generation\",\n",
    "        \"text-classification\",\n",
    "        \"token-classification\",\n",
    "        \"language-modeling\",\n",
    "        \"multiple-choice\",\n",
    "        \"question-answering\",\n",
    "        \"summarization\",\n",
    "        \"translation\",\n",
    "        \"image-classification\",\n",
    "        \"speech-recognition\",\n",
    "        \"audio-classification\",\n",
    "        \"speech-pretraining\",\n",
    "        \"image-pretraining\",\n",
    "        \"semantic-segmentation\",\n",
    "    ]\n",
    "]\n",
    "sys.path.extend(SRC_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c394a69-2fa5-4b3a-928b-ea8c8d7e5bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from translation import run_translation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b803785-a826-44cc-808f-ae4e7c53ab73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a8cb0-9242-4b31-a495-3a68de2dde60",
   "metadata": {},
   "source": [
    "### Default AdamW_HF with LambdaLR (linear, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193adaa-5083-48cb-993e-2c753f4f447a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/18/2023 04:57:54 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/18/2023 04:57:54 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/root/transformers/examples/pytorch/tmpq7oekuh1/runs/Mar18_04-57-54_pytorch-1-13-gpu-py-ml-g5-16xlarge-bff23aa7fcca0c0ba1c19f2e4a3e,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=cosine_with_restarts,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=5000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adafactor,\n",
      "optim_args=None,\n",
      "output_dir=/root/transformers/examples/pytorch/tmpq7oekuh1,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/root/transformers/examples/pytorch/tmpq7oekuh1,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/18/2023 04:57:54 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/wmt16/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227\n",
      "03/18/2023 04:57:54 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/18/2023 04:57:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227\n",
      "03/18/2023 04:57:54 - WARNING - datasets.builder - Found cached dataset wmt16 (/root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n",
      "03/18/2023 04:57:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 61.53it/s]\n",
      "[INFO|configuration_utils.py:668] 2023-03-18 04:57:54,580 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-18 04:57:54,584 >> Model config FSMTConfig {\n",
      "  \"_commit_hash\": \"f489ab7724347fcf69cf7cf057fe5a4d06920d64\",\n",
      "  \"_name_or_path\": \"facebook/wmt19-de-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"FSMTForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"fsmt_decoder\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.27.0.dev0\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"vocab_size\": 42024\n",
      "  },\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.2,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 8192,\n",
      "  \"encoder_layerdrop\": 0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"langs\": [\n",
      "    \"de\",\n",
      "    \"en\"\n",
      "  ],\n",
      "  \"length_penalty\": 1.1,\n",
      "  \"max_length\": 200,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"fsmt\",\n",
      "  \"num_beams\": 5,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"src_vocab_size\": 42024,\n",
      "  \"tgt_vocab_size\": 42024,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": null,\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n",
      "[INFO|configuration_utils.py:668] 2023-03-18 04:57:54,634 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-18 04:57:54,635 >> Model config FSMTConfig {\n",
      "  \"_commit_hash\": \"f489ab7724347fcf69cf7cf057fe5a4d06920d64\",\n",
      "  \"_name_or_path\": \"facebook/wmt19-de-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"FSMTForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"fsmt_decoder\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.27.0.dev0\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"vocab_size\": 42024\n",
      "  },\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.2,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 8192,\n",
      "  \"encoder_layerdrop\": 0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"langs\": [\n",
      "    \"de\",\n",
      "    \"en\"\n",
      "  ],\n",
      "  \"length_penalty\": 1.1,\n",
      "  \"max_length\": 200,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"fsmt\",\n",
      "  \"num_beams\": 5,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"src_vocab_size\": 42024,\n",
      "  \"tgt_vocab_size\": 42024,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": null,\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-18 04:57:54,650 >> loading file vocab-src.json from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/vocab-src.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-18 04:57:54,650 >> loading file vocab-tgt.json from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/vocab-tgt.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-18 04:57:54,651 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/merges.txt\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-18 04:57:54,651 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-18 04:57:54,652 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-18 04:57:54,652 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/tokenizer_config.json\n",
      "[INFO|configuration_utils.py:668] 2023-03-18 04:57:54,656 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-18 04:57:54,658 >> Model config FSMTConfig {\n",
      "  \"_commit_hash\": \"f489ab7724347fcf69cf7cf057fe5a4d06920d64\",\n",
      "  \"_name_or_path\": \"facebook/wmt19-de-en\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"relu\",\n",
      "  \"architectures\": [\n",
      "    \"FSMTForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder\": {\n",
      "    \"_name_or_path\": \"\",\n",
      "    \"add_cross_attention\": false,\n",
      "    \"architectures\": null,\n",
      "    \"bad_words_ids\": null,\n",
      "    \"begin_suppress_tokens\": null,\n",
      "    \"bos_token_id\": 2,\n",
      "    \"chunk_size_feed_forward\": 0,\n",
      "    \"cross_attention_hidden_size\": null,\n",
      "    \"decoder_start_token_id\": null,\n",
      "    \"diversity_penalty\": 0.0,\n",
      "    \"do_sample\": false,\n",
      "    \"early_stopping\": false,\n",
      "    \"encoder_no_repeat_ngram_size\": 0,\n",
      "    \"eos_token_id\": null,\n",
      "    \"exponential_decay_length_penalty\": null,\n",
      "    \"finetuning_task\": null,\n",
      "    \"forced_bos_token_id\": null,\n",
      "    \"forced_eos_token_id\": null,\n",
      "    \"id2label\": {\n",
      "      \"0\": \"LABEL_0\",\n",
      "      \"1\": \"LABEL_1\"\n",
      "    },\n",
      "    \"is_decoder\": false,\n",
      "    \"is_encoder_decoder\": false,\n",
      "    \"label2id\": {\n",
      "      \"LABEL_0\": 0,\n",
      "      \"LABEL_1\": 1\n",
      "    },\n",
      "    \"length_penalty\": 1.0,\n",
      "    \"max_length\": 20,\n",
      "    \"min_length\": 0,\n",
      "    \"model_type\": \"fsmt_decoder\",\n",
      "    \"no_repeat_ngram_size\": 0,\n",
      "    \"num_beam_groups\": 1,\n",
      "    \"num_beams\": 1,\n",
      "    \"num_return_sequences\": 1,\n",
      "    \"output_attentions\": false,\n",
      "    \"output_hidden_states\": false,\n",
      "    \"output_scores\": false,\n",
      "    \"pad_token_id\": null,\n",
      "    \"prefix\": null,\n",
      "    \"problem_type\": null,\n",
      "    \"pruned_heads\": {},\n",
      "    \"remove_invalid_values\": false,\n",
      "    \"repetition_penalty\": 1.0,\n",
      "    \"return_dict\": true,\n",
      "    \"return_dict_in_generate\": false,\n",
      "    \"sep_token_id\": null,\n",
      "    \"suppress_tokens\": null,\n",
      "    \"task_specific_params\": null,\n",
      "    \"temperature\": 1.0,\n",
      "    \"tf_legacy_loss\": false,\n",
      "    \"tie_encoder_decoder\": false,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"tokenizer_class\": null,\n",
      "    \"top_k\": 50,\n",
      "    \"top_p\": 1.0,\n",
      "    \"torch_dtype\": null,\n",
      "    \"torchscript\": false,\n",
      "    \"transformers_version\": \"4.27.0.dev0\",\n",
      "    \"typical_p\": 1.0,\n",
      "    \"use_bfloat16\": false,\n",
      "    \"vocab_size\": 42024\n",
      "  },\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.2,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 8192,\n",
      "  \"encoder_layerdrop\": 0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"langs\": [\n",
      "    \"de\",\n",
      "    \"en\"\n",
      "  ],\n",
      "  \"length_penalty\": 1.1,\n",
      "  \"max_length\": 200,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"fsmt\",\n",
      "  \"num_beams\": 5,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": true,\n",
      "  \"src_vocab_size\": 42024,\n",
      "  \"tgt_vocab_size\": 42024,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": null,\n",
      "  \"use_cache\": true\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-18 04:57:54,803 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-18 04:57:55,142 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 1.1,\n",
      "  \"max_length\": 200,\n",
      "  \"num_beams\": 5,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-18 04:57:57,701 >> All model checkpoint weights were used when initializing FSMTForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3027] 2023-03-18 04:57:57,702 >> All the weights of FSMTForConditionalGeneration were initialized from the model checkpoint at facebook/wmt19-de-en.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use FSMTForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-18 04:57:57,752 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--facebook--wmt19-de-en/snapshots/f489ab7724347fcf69cf7cf057fe5a4d06920d64/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-18 04:57:57,753 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"length_penalty\": 1.1,\n",
      "  \"max_length\": 200,\n",
      "  \"num_beams\": 5,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/18/2023 04:57:58 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227/cache-23204a732454da9c.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-18 04:58:00,156 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-18 04:58:00,174 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-18 04:58:00,175 >>   Num examples = 4548885\n",
      "[INFO|trainer.py:1747] 2023-03-18 04:58:00,175 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-18 04:58:00,176 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-18 04:58:00,176 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-18 04:58:00,176 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-18 04:58:00,177 >>   Total optimization steps = 5000\n",
      "[INFO|trainer.py:1752] 2023-03-18 04:58:00,178 >>   Number of trainable parameters = 312778752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-03-18 04:58:00.322: W smdistributed/modelparallel/torch/nn/predefined_hooks.py:78] Found unsupported HuggingFace version 4.27.0.dev0 for automated tensor parallelism. HuggingFace modules will not be automatically distributed. You can use smp.tp_register_with_module API to register desired modules for tensor parallelism, or directly instantiate an smp.nn.DistributedModule. Supported HuggingFace transformers versions for automated tensor parallelism: ['4.17.0', '4.20.1', '4.21.0']\n",
      "[2023-03-18 04:58:00.351 pytorch-1-13-gpu-py-ml-g5-16xlarge-bff23aa7fcca0c0ba1c19f2e4a3e:36376 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2023-03-18 04:58:00.376 pytorch-1-13-gpu-py-ml-g5-16xlarge-bff23aa7fcca0c0ba1c19f2e4a3e:36376 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='202' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 202/5000 00:26 < 10:33, 7.57 it/s, Epoch 0.00/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.626900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.229100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.325300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.939700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.949700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.000900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.334500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.393500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.998500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.890600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.210200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>1.146500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>1.276400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>1.282300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>1.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.974900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path facebook/wmt19-de-en\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name wmt16\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --per_device_eval_batch_size=4\n",
    "    --predict_with_generate\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --lr_scheduler_type cosine_with_restarts\n",
    "    --optim adafactor\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca578d-b857-4b0f-9973-77ca99913e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7667a-875f-410b-89a7-8c9207fcc745",
   "metadata": {},
   "source": [
    "### With GreedyLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b9170-1e41-441c-b2d1-e6799ab74db0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path facebook/wmt19-de-en\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name wmt16\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --per_device_eval_batch_size=4\n",
    "    --predict_with_generate\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim adafactor\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca37c9e-a80a-40e8-982f-319a088edad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d4f6b-5eda-4e06-89c4-1d608d2e886e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696dc61a-178f-4213-98c9-130d03d5b38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafae40a-f887-47ab-8f5e-1948128b8d72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-',label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-',label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c195ead-5cf7-46ac-899b-02bf7b4c75ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c77c7e-75eb-4946-8fa9-1665c89e96ca",
   "metadata": {},
   "source": [
    "## 2. Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de744-e910-4bd1-86f8-b4e388d58a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_qa as run_squad\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e736f06-d6e3-46af-a6e4-317ff5623090",
   "metadata": {},
   "source": [
    "### Default ADAMHF / Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8317c07-cd7b-4130-a7ca-af5448577575",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    --model_name_or_path xlm-roberta-base\n",
    "    --version_2_with_negative\n",
    "    --dataset_name squad\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=2\n",
    "    --per_device_eval_batch_size=1\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --lr_scheduler_type cosine_with_restarts\n",
    "    --optim adafactor\n",
    "\"\"\".split()\n",
    "\n",
    "    # --lr_scheduler_type cosine_with_restarts\n",
    "    # --optim adafactor\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_squad.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5ed56-53bc-47fc-b58e-933d60d304ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b40af-44d6-44fb-9880-338c3b01ac17",
   "metadata": {},
   "source": [
    "### Greedy LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fabf8-33f9-497a-a361-2597cd1b5de4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    --model_name_or_path xlm-roberta-base\n",
    "    --version_2_with_negative\n",
    "    --dataset_name squad\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --per_device_eval_batch_size=2\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim adafactor\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_squad.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c2f59-2765-4f74-9860-d616bab549c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641246a-0668-4fcd-a298-1f9eb9f68ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6e45a-246d-4aa5-83e0-f508cf5536ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55deca4e-7319-4529-a03d-c27624fe977f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de0731-21f6-4e6a-9cf4-5594cd7b00db",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b274bc4-e96e-4e39-82ab-1f0eadecbe20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_image_classification\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22a59a-5a94-4488-bd6e-f2e8e7b7062a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_image_classification.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path microsoft/resnet-152\n",
    "    --dataset_name cifar100\n",
    "    --do_train\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 64\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --metric_for_best_model accuracy\n",
    "    --max_steps 1000\n",
    "    --train_val_split 0.2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --ignore_mismatched_sizes True\n",
    "    --seed 42\n",
    "    --lr_scheduler_type cosine_with_restarts\n",
    "    --optim adafactor\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_image_classification.main()\n",
    "    result = get_results(tmp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6856c7-3c94-4d27-823b-16e9c981d5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a269d-2d96-4e5c-99d9-b91d08622b1f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_image_classification.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path microsoft/resnet-152\n",
    "    --dataset_name cifar100\n",
    "    --do_train\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 64\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --metric_for_best_model accuracy\n",
    "    --max_steps 1000\n",
    "    --train_val_split 0.2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --ignore_mismatched_sizes True\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim adafactor\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_image_classification.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63602e64-b64d-477b-b5f9-580a93df158b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505dbd11-fa02-46c7-afbb-4009dfcb2db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f3ee3-50c8-4d94-83c4-67e700e5b1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd835ef-3593-4fe7-85c8-8f09302cc9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094456e-d434-45c3-a930-1902816762f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4a94f-2496-4a89-8892-09edc996f069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g5.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.13 Python 3.9 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/pytorch-1.13-gpu-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
