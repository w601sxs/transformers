{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da327dae-67ce-4803-a0d9-b6d93dc8a6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Found existing installation: transformers 4.27.0.dev1\n",
      "Uninstalling transformers-4.27.0.dev1:\n",
      "  Successfully uninstalled transformers-4.27.0.dev1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "722e29e0-f11b-4559-967a-587f31378072",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Requirement already satisfied: accelerate>=0.12.0 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 1)) (0.17.1)\n",
      "Requirement already satisfied: datasets>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 2)) (2.10.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 3)) (0.1.97)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 4)) (3.20.3)\n",
      "Requirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: py7zr in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 6)) (0.20.4)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (1.21.6)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (5.6.7)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (11.0.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2023.1.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.18.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (6.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.5)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.3.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.13.2)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.8.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.28.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.70.14)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (2.7.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (2022.10.31)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (4.9.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (4.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (11.7.99)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3->-r translation/requirements.txt (line 7)) (0.40.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3->-r translation/requirements.txt (line 7)) (65.7.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.8.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2022.12.7)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.2.3)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (3.17)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.15.4)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.6.7)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from py7zr->-r translation/requirements.txt (line 6)) (0.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Keyring is skipped due to an exception: 'keyring.backends'\n",
      "Obtaining file:///root/transformers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (0.13.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (4.65.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (6.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (2.28.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev1) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.27.0.dev1) (3.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (1.26.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2.0.4)\n",
      "Installing collected packages: transformers\n",
      "  Running setup.py develop for transformers\n",
      "Successfully installed transformers\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r translation/requirements.txt\n",
    "%pip install -e ~/transformers/ #Or wherever you downloaded this source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04ebcef5-f6ec-45d2-967a-3d6aaadeb490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "SRC_DIRS = [\n",
    "    os.path.join('./', dirname) for dirname in [\n",
    "        \"text-generation\",\n",
    "        \"text-classification\",\n",
    "        \"token-classification\",\n",
    "        \"language-modeling\",\n",
    "        \"multiple-choice\",\n",
    "        \"question-answering\",\n",
    "        \"summarization\",\n",
    "        \"translation\",\n",
    "        \"image-classification\",\n",
    "        \"speech-recognition\",\n",
    "        \"audio-classification\",\n",
    "        \"speech-pretraining\",\n",
    "        \"image-pretraining\",\n",
    "        \"semantic-segmentation\",\n",
    "    ]\n",
    "]\n",
    "sys.path.extend(SRC_DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669dc47a-8491-4827-b52f-8d9f9cd2c343",
   "metadata": {},
   "source": [
    "# Comparing seeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffce3a1-f682-49ee-8983-5b144afe3c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation import run_translation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78ec9113-8ced-4197-8d15-2d8d357d5316",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_translation_func(lr, seed):\n",
    "    tmp_dir = get_auto_remove_tmp_dir()\n",
    "    testargs = f\"\"\"\n",
    "        run_translation.py\n",
    "        --model_name_or_path google/long-t5-tglobal-base\n",
    "        --source_lang en\n",
    "        --target_lang fr\n",
    "        --dataset_name news_commentary\n",
    "        --dataset_config_name en-fr\n",
    "        --output_dir {tmp_dir}\n",
    "        --overwrite_output_dir\n",
    "        --max_steps=1000\n",
    "        --warmup_steps=0\n",
    "        --do_train\n",
    "        --learning_rate={lr}\n",
    "        --per_device_train_batch_size=4\n",
    "        --per_device_eval_batch_size=4\n",
    "        --predict_with_generate\n",
    "        --save_strategy no\n",
    "        --logging_steps 10\n",
    "        --lr_scheduler_type constant\n",
    "        --seed {seed}\n",
    "    \"\"\".split()\n",
    "\n",
    "    with patch.object(sys, \"argv\", testargs):\n",
    "        run_translation.main()\n",
    "        result = get_results(tmp_dir)\n",
    "        # print(result[\"eval_bleu\"]>30)\n",
    "    \n",
    "    return tmp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fd3f72-3abe-43e7-b722-deeee1fb6c0d",
   "metadata": {},
   "source": [
    "Grid search Lr with same fixed seed - 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719edb33-d306-4de9-a91f-22355bc76cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lrs = [1e-6,1e-6,5e-5,5e-5,1e-5,1e-5,5e-4,5e-4,1e-4,1e-4, 5e-3,5e-3, 1e-3,1e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680c81bb-680a-4733-8f3a-f264c06e0894",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 00:51:09 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 00:51:09 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmptjv78jx7/runs/Mar21_00-51-09_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmptjv78jx7,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmptjv78jx7,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 00:51:09 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 00:51:10 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 00:51:10 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 00:51:10 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 00:51:10 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f072705aa745108aa15b842a446283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 00:51:10,313 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 00:51:10,329 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 00:51:10,358 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 00:51:10,384 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 00:51:10,385 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:51:10,444 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:51:10,444 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:51:10,445 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:51:10,445 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:51:10,446 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 00:51:10,449 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 00:51:10,451 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 00:51:10,557 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 00:51:10,899 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 00:51:13,678 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 00:51:13,679 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 00:51:13,718 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 00:51:13,719 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 00:51:13 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 00:51:16,487 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "/root/transformers/src/transformers/optimization.py:424: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "[INFO|trainer.py:1745] 2023-03-21 00:51:16,514 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 00:51:16,515 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 00:51:16,515 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 00:51:16,516 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 00:51:16,516 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 00:51:16,517 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 00:51:16,517 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 00:51:16,520 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 00:51:16,544 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/root/transformers/src/transformers/modeling_utils.py:785: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 05:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.596900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.508200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.077100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.960500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.918800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>5.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>5.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.795600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.071100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.770100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.757800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.746300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.920100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>5.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.859500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>5.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.729500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>4.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.889800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>4.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.731900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.837600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.832600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.737200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>4.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>4.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.611600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.781300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>4.613900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>4.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.644200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.479200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>4.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>4.512400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>4.527400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.699200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 00:56:18,840 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 00:56:18,882 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 00:56:18,910 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 00:56:18,911 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     4.9908\n",
      "  train_runtime            = 0:05:02.32\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     13.231\n",
      "  train_steps_per_second   =      3.308\n",
      "03/21/2023 00:56:18 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 00:56:18 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpp2ar8pfd/runs/Mar21_00-56-18_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpp2ar8pfd,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpp2ar8pfd,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 00:56:19 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 00:56:19 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 00:56:19 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 00:56:19 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 00:56:19 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e1c4109b8b470cb23c846ff1d42d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 00:56:19,329 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 00:56:19,331 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 00:56:19,362 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 00:56:19,391 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 00:56:19,392 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:56:19,456 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:56:19,457 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:56:19,457 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:56:19,458 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 00:56:19,459 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 00:56:19,463 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 00:56:19,464 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 00:56:19,524 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 00:56:19,868 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 00:56:22,655 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 00:56:22,656 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 00:56:22,697 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 00:56:22,698 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 00:56:22 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 00:56:23,022 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 00:56:23,044 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 00:56:23,045 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 00:56:23,046 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 00:56:23,046 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 00:56:23,047 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 00:56:23,047 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 00:56:23,048 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 00:56:23,050 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 00:56:23,073 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 04:20, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.596900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.508200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.077100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.960500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.918800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>5.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>5.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.795600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.071100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.770100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.757800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.746300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.920100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>5.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.859500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>5.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.729500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>4.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.889800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>4.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.731900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.837600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.832600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.737200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>4.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>4.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.611600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.781300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>4.613900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>4.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.644200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.479200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>4.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>4.512400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>4.527400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.699200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:00:43,804 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:00:43,845 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:00:43,875 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:00:43,875 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     4.9908\n",
      "  train_runtime            = 0:04:20.75\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =      15.34\n",
      "  train_steps_per_second   =      3.835\n",
      "03/21/2023 01:00:43 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:00:43 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpm2klbki3/runs/Mar21_01-00-43_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpm2klbki3,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpm2klbki3,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:00:44 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:00:44 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:00:44 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:00:44 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:00:44 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0482c8026c424071820b840d9b03329b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:00:44,291 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:00:44,292 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:00:44,320 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:00:44,345 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:00:44,347 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:00:44,404 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:00:44,404 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:00:44,405 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:00:44,406 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:00:44,406 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:00:44,409 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:00:44,410 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:00:44,463 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:00:44,625 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:00:46,841 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:00:46,843 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:00:46,891 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:00:46,892 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:00:46 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:00:47,119 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:00:47,139 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:00:47,140 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:00:47,140 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:00:47,141 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:00:47,141 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:00:47,142 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:00:47,142 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:00:47,144 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:00:47,158 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.722600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.512900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.380900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.260700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.121900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.987700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.864700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.742700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.735100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.599400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.695600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.559200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.310700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.442600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.622100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.468900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.408700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.387100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.465200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.282100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.275700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.995500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.278400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.289400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.189100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.180800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.273600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.206900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.093600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.954800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.191600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.934300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.953700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.987900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.876800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.946300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:03:42,603 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:03:42,644 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:03:42,675 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:03:42,675 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     3.3834\n",
      "  train_runtime            = 0:02:55.45\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.797\n",
      "  train_steps_per_second   =      5.699\n",
      "03/21/2023 01:03:42 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:03:42 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp6q80g4bj/runs/Mar21_01-03-42_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp6q80g4bj,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp6q80g4bj,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:03:42 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:03:43 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:03:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:03:43 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:03:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87af800ce70c4acb981f42fa4f1d45d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:03:43,108 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:03:43,109 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:03:43,140 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:03:43,167 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:03:43,168 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:03:43,235 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:03:43,236 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:03:43,237 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:03:43,237 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:03:43,238 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:03:43,241 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:03:43,243 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:03:43,295 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:03:43,457 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:03:45,549 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:03:45,550 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:03:45,588 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:03:45,589 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:03:45 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:03:45,804 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:03:45,823 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:03:45,824 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:03:45,824 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:03:45,825 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:03:45,825 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:03:45,826 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:03:45,827 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:03:45,829 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:03:45,840 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.530200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.722600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.512900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.380900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.260700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.121900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.987700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.916500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.864700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.742700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.735100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.599400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.695600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.559200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.310700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.442600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.622100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.468900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.408700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.471500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.433400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.387100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.480300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.465200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.415200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.392500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.282100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.275700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.406200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.170100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.307500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.995500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.447100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.278400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.062100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.289400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.189100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.180800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.314100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.947400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.296300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.273600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.249200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.123900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.192300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.206900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.098200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.092900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.154300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.093600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.941800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.954800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.191600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.934300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.953700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.987900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.876800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.885500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.051700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.946300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:06:41,042 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:06:41,083 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:06:41,128 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:06:41,128 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     3.3834\n",
      "  train_runtime            = 0:02:55.21\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.829\n",
      "  train_steps_per_second   =      5.707\n",
      "03/21/2023 01:06:41 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:06:41 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpnb4_yhrj/runs/Mar21_01-06-41_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpnb4_yhrj,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpnb4_yhrj,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:06:41 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:06:41 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:06:41 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:06:41 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:06:41 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20baf6989d69401cb7f5228b6073de16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:06:41,554 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:06:41,556 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:06:41,586 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:06:41,615 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:06:41,616 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:06:41,675 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:06:41,675 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:06:41,676 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:06:41,676 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:06:41,677 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:06:41,680 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:06:41,681 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:06:41,732 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:06:41,894 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:06:44,139 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:06:44,140 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:06:44,175 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:06:44,176 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:06:44 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:06:44,392 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:06:44,411 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:06:44,412 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:06:44,412 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:06:44,413 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:06:44,414 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:06:44,414 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:06:44,415 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:06:44,417 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:06:44,429 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:54, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.783900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.727200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.676200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.692700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.755200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.717400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.487600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.470900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.258700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.286900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.815800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.881700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.984700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.790500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.890700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.718300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.793000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.972300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.724100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.831300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.855900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.681200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.845900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.511300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.805200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.780400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.568100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.843900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.605500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.627700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.676300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.683400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.668100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.769700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.595700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.466300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.433100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.656100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.696600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.474400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.645200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.584700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.470600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.544300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.510400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:09:38,703 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:09:38,745 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:09:38,777 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:09:38,777 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     3.9872\n",
      "  train_runtime            = 0:02:54.28\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.951\n",
      "  train_steps_per_second   =      5.738\n",
      "03/21/2023 01:09:38 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:09:38 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpu8lkbpb4/runs/Mar21_01-09-38_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpu8lkbpb4,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpu8lkbpb4,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:09:38 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:09:39 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:09:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:09:39 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:09:39 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de5cdaafcca403d913792e6940b9ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:09:39,184 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:09:39,187 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:09:39,218 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:09:39,245 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:09:39,247 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:09:39,309 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:09:39,309 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:09:39,310 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:09:39,311 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:09:39,311 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:09:39,315 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:09:39,316 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:09:39,369 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:09:39,530 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:09:41,665 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:09:41,665 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:09:41,705 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:09:41,706 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:09:41 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:09:41,924 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:09:41,943 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:09:41,944 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:09:41,944 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:09:41,945 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:09:41,946 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:09:41,946 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:09:41,946 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:09:41,948 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:09:41,962 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:54, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.843700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.038900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.954000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.783900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.727200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.676200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.692700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.755200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.717400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.402500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.487600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.470900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.389900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.258700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.070500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.138800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.341100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.114100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.093900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.224200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.232700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.108800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.286900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.958300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.103600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.962700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.815800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.881700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.938700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.984700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.790500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.890700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.718300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.793000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.972300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.724100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.039100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.831300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.855900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.715500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.681200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.845900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.511300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.844200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.721500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.805200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.780400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.736500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.568100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.632800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.766000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.843900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.605500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.627700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.676300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.683400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.694000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.668100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.769700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.595700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.652300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.710500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.466300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.433100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.656100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.696600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.474400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.645200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.584700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.521800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.479900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.470600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.398400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.544300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.510400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:12:36,609 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:12:36,650 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:12:36,683 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:12:36,684 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     3.9872\n",
      "  train_runtime            = 0:02:54.66\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.902\n",
      "  train_steps_per_second   =      5.725\n",
      "03/21/2023 01:12:36 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:12:36 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpfk0h9h4p/runs/Mar21_01-12-36_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpfk0h9h4p,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpfk0h9h4p,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:12:36 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:12:37 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:12:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:12:37 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:12:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f83ec4947b84e8e9a05deafd3fc6ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:12:37,126 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:12:37,127 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:12:37,155 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:12:37,180 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:12:37,182 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:12:37,268 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:12:37,268 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:12:37,269 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:12:37,270 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:12:37,270 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:12:37,273 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:12:37,275 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:12:37,327 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:12:37,487 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:12:39,597 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:12:39,598 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:12:39,635 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:12:39,636 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:12:39 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:12:39,868 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:12:39,887 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:12:39,888 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:12:39,888 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:12:39,889 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:12:39,889 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:12:39,889 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:12:39,890 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:12:39,892 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:12:39,906 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:54, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.747700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.553100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.352100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.465600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.351900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.408800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.139700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.277800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.264500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.212300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.136900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.790500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.967300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.157800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.868700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.902900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.971700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.937700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.860100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.947800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.713100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.637900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.827800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.943600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.896600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.893500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.807100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.610200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.781700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.840500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.846700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.751200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.520200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.801900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.741400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.798200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.745600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.591400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.505400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.602900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.668500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.614300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.602200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.433700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.651400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.619100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.627300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.532900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.411900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.405900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.533100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.403300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.309100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.335800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:15:34,643 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:15:34,684 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:15:34,716 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:15:34,717 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     2.8484\n",
      "  train_runtime            = 0:02:54.75\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =      22.89\n",
      "  train_steps_per_second   =      5.722\n",
      "03/21/2023 01:15:34 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:15:34 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp5c0a96pt/runs/Mar21_01-15-34_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp5c0a96pt,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp5c0a96pt,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:15:34 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:15:35 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:15:35 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:15:35 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:15:35 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6016bfb152e54710a23fc0621128bfd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:15:35,144 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:15:35,145 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:15:35,175 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:15:35,202 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:15:35,203 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:15:35,267 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:15:35,267 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:15:35,268 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:15:35,268 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:15:35,269 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:15:35,273 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:15:35,275 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:15:35,327 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:15:35,488 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:15:37,579 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:15:37,580 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:15:37,617 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:15:37,618 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:15:37 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:15:37,834 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:15:37,854 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:15:37,855 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:15:37,855 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:15:37,856 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:15:37,856 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:15:37,857 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:15:37,857 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:15:37,859 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:15:37,873 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.747700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.553100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.352100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.297500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.421700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.465600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.351900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.398900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.408800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.139700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.277800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.264500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.212300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.238000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.136900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.178600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.790500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.967300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.157800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.868700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.902900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.971700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.937700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.860100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.947800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.713100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.637900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.827800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.943600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.896600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.893500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.807100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.610200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.781700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.840500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.597600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.846700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.751200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.520200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.801900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.667100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.687100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.413000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.741400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.699900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.798200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.745600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.591400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.505400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.602900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.668500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.578700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.614300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.602200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.696700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.433700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.651400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.619100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.507900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.627300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.636300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.551000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.617000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.427100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.532900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.411900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.405900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.533100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.403300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.309100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.574100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.335800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:18:40,576 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:18:40,616 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:18:40,647 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:18:40,648 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     2.8484\n",
      "  train_runtime            = 0:03:02.71\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     21.892\n",
      "  train_steps_per_second   =      5.473\n",
      "03/21/2023 01:18:40 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:18:40 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpc3zcvaaw/runs/Mar21_01-18-40_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpc3zcvaaw,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpc3zcvaaw,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:18:40 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:18:40 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:18:40 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:18:41 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:18:41 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88b83440f4143f498372a845003a08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:18:41,057 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:18:41,058 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:18:41,087 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:18:41,113 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:18:41,114 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:18:41,172 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:18:41,173 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:18:41,173 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:18:41,174 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:18:41,175 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:18:41,178 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:18:41,179 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:18:41,231 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:18:41,393 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:18:43,498 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:18:43,499 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:18:43,536 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:18:43,537 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:18:43 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:18:43,757 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:18:43,776 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:18:43,776 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:18:43,777 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:18:43,778 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:18:43,779 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:18:43,779 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:18:43,779 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:18:43,781 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:18:43,795 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.240800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.489100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.251700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.842200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.711900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.673100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.642300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.656600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.502300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.516800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.492100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.336800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.281100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.208100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.209100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.088700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.914100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.905200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.072900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.839900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.081200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.974400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.980500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.995300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.964300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.814900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.905800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.952800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.972500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.960800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.966500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.938200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.740500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.792900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.828600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.789600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.747400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.804500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.658800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.712700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:21:42,062 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:21:42,099 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:21:42,130 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:21:42,131 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     3.1601\n",
      "  train_runtime            = 0:02:58.28\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.437\n",
      "  train_steps_per_second   =      5.609\n",
      "03/21/2023 01:21:42 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:21:42 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpjgxfzy26/runs/Mar21_01-21-42_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpjgxfzy26,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpjgxfzy26,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:21:42 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:21:42 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:21:42 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:21:42 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:21:42 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd7acd3d1d44e1f9f74d258276f1919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:21:42,588 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:21:42,589 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:21:42,619 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:21:42,645 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:21:42,647 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:21:42,708 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:21:42,710 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:21:42,710 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:21:42,711 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:21:42,711 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:21:42,715 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:21:42,716 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:21:42,769 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:21:42,930 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:21:45,138 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:21:45,139 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:21:45,176 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:21:45,177 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:21:45 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:21:45,405 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:21:45,423 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:21:45,425 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:21:45,426 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:21:45,426 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:21:45,426 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:21:45,427 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:21:45,427 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:21:45,429 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:21:45,443 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:52, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.240800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.489100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.251700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.086100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.842200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.711900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.673100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.642300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.677200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.656600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.502300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.517100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.516800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.492100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.348900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.222400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.413300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.278000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.336800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.281100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.962000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.276500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.208100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.209100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.181700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.088700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.914100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.224300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.984800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.905200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.095500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.072900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.839900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.081200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.974400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.980500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.995300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.041200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.964300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.814900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.905800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.952800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.867500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.972500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.960800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.966500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.938200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.740500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.686000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.903900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.792900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.828600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.789600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.747400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.804500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.658800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.661400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.712700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:24:38,002 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:24:38,043 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:24:38,075 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:24:38,075 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     3.1601\n",
      "  train_runtime            = 0:02:52.57\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     23.179\n",
      "  train_steps_per_second   =      5.795\n",
      "03/21/2023 01:24:38 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:24:38 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp12j8audj/runs/Mar21_01-24-38_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp12j8audj,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp12j8audj,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:24:38 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:24:38 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:24:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:24:38 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:24:38 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378cdec278fb4d18a5bb31fa59d08344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:24:38,491 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:24:38,492 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:24:38,521 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:24:38,547 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:24:38,548 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:24:38,613 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:24:38,614 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:24:38,614 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:24:38,615 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:24:38,615 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:24:38,619 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:24:38,620 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:24:38,673 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:24:38,836 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:24:41,043 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:24:41,044 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:24:41,084 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:24:41,085 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:24:41 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:24:41,302 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:24:41,322 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:24:41,322 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:24:41,323 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:24:41,323 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:24:41,324 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:24:41,324 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:24:41,324 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:24:41,326 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:24:41,340 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:54, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.510800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.969300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.858400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.976500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.968100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.707900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.632600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.545100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.611400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.655400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.586300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.629400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.169700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.283100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.174900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.347900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.235700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.134600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>4.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.991900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.891900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.040400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.987400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.876500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.841200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.995300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.065100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.903700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.884500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.833800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.907600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.873000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.812800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.944700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.737800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.810200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.806900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.711800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.851400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:27:35,865 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:27:35,906 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:27:35,938 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:27:35,938 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     4.2121\n",
      "  train_runtime            = 0:02:54.53\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.918\n",
      "  train_steps_per_second   =      5.729\n",
      "03/21/2023 01:27:35 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:27:35 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp4rzdwo4s/runs/Mar21_01-27-35_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp4rzdwo4s,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp4rzdwo4s,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:27:36 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:27:36 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:27:36 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:27:36 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:27:36 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef021bfd4f2444808f628dd78474524e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:27:36,438 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:27:36,440 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:27:36,468 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:27:36,493 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:27:36,495 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:27:36,554 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:27:36,554 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:27:36,555 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:27:36,555 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:27:36,556 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:27:36,559 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:27:36,561 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:27:36,613 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:27:36,773 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:27:38,882 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:27:38,883 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:27:38,919 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:27:38,920 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:27:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:27:39,134 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:27:39,153 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:27:39,154 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:27:39,154 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:27:39,155 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:27:39,155 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:27:39,155 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:27:39,156 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:27:39,158 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:27:39,170 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.510800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.104400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.969300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.951000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.858400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.976500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.968100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.707900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.632600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.545100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.611400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.655400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.586300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.654600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.675300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.629400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.703400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.261000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.288600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.169700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.283100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.436900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.239100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.174900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.347900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.235700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.134600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.215800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.277700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.187600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.101800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>4.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.146300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.991900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.085500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.232000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.129600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.117300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.111200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.891900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.040400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.075900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.106300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.987400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.876500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.970900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.841200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.995300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.794000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.939200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.065100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.903700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.068800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.884500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.833800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.885600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.907600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.873000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.812800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.958200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.944700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.737800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.810200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.806900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.711800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.977200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.851400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:30:36,797 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:30:36,837 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:30:36,868 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:30:36,868 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     4.2121\n",
      "  train_runtime            = 0:02:57.63\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.518\n",
      "  train_steps_per_second   =      5.629\n",
      "03/21/2023 01:30:36 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:30:36 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp2f_a9333/runs/Mar21_01-30-36_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp2f_a9333,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp2f_a9333,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:30:37 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:30:37 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:30:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:30:37 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:30:37 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c9f7135b2e44cdb49aa8c64c3729ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:30:37,319 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:30:37,320 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:30:37,348 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:30:37,373 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:30:37,374 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:30:37,436 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:30:37,437 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:30:37,437 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:30:37,438 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:30:37,438 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:30:37,442 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:30:37,444 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:30:37,496 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:30:37,658 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:30:39,758 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:30:39,760 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:30:39,797 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:30:39,798 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:30:39 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:30:40,008 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:30:40,027 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:30:40,028 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:30:40,028 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:30:40,029 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:30:40,030 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:30:40,030 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:30:40,031 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:30:40,033 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:30:40,044 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:53, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.930100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.220400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.209600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.264200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.765400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.776200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.685300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.862600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.963700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.837000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.844900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.658700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.756900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.805400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.742300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.672900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.745400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.551300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.574500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.603200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.657900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.606300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.508400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.635800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.756200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.532800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.513300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.576800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.336900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.646800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.665700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.397200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.556900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.314900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:33:33,927 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:33:33,968 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:33:34,000 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:33:34,000 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     2.8765\n",
      "  train_runtime            = 0:02:53.89\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     23.002\n",
      "  train_steps_per_second   =      5.751\n",
      "03/21/2023 01:33:34 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:33:34 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpgn_ttji6/runs/Mar21_01-33-33_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpgn_ttji6,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpgn_ttji6,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:33:34 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:33:34 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:33:34 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:33:34 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:33:34 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14a046fccb04ac9b50b300ee37ed515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:33:34,425 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:33:34,426 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:33:34,456 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:33:34,483 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:33:34,485 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:33:34,544 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:33:34,544 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:33:34,545 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:33:34,545 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:33:34,546 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:33:34,550 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:33:34,551 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:33:34,604 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:33:34,767 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:33:36,918 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:33:36,919 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:33:36,954 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:33:36,955 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:33:36 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:33:37,167 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:33:37,186 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:33:37,186 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:33:37,187 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:33:37,187 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:33:37,188 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:33:37,188 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:33:37,189 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:33:37,190 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:33:37,204 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:53, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.930100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.220400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.209600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.264200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.765400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.776200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.685300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.862600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.963700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.837000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.844900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.658700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.756900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.805400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.742300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.672900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.745400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.551300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.574500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.603200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.657900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.606300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.508400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.635800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.756200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.532800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.513300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.576800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.336900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.646800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.665700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.397200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.556900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.314900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:36:30,674 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:36:30,715 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     2.8765\n",
      "  train_runtime            = 0:02:53.48\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     23.057\n",
      "  train_steps_per_second   =      5.764\n"
     ]
    }
   ],
   "source": [
    "result_dirs_42 = []\n",
    "for lr in lrs:\n",
    "    result_dirs_42.append(run_translation_func(lr, 42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a0f1ca6-3daa-493b-a075-4ce38264e77d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1509] 2023-03-21 01:36:30,755 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:36:30,756 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:36:30 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:36:30 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpvcexsk61/runs/Mar21_01-36-30_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpvcexsk61,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpvcexsk61,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:36:30 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:36:31 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:36:31 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:36:31 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:36:31 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49fb8ddb46624b2697c3404e54c8e5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:36:31,212 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:36:31,215 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:36:31,247 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:36:31,276 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:36:31,278 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:36:31,338 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:36:31,339 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:36:31,339 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:36:31,340 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:36:31,340 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:36:31,344 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:36:31,345 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:36:31,400 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:36:31,559 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:36:33,681 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:36:33,682 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:36:33,721 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:36:33,722 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:36:33 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:36:33,947 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:36:33,966 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:36:33,966 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:36:33,967 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:36:33,967 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:36:33,968 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:36:33,968 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:36:33,969 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:36:33,971 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:36:33,984 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:56, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.943500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.333500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.406600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.587600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.242300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.224100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.133600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.214500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.976200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.374800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.202900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.985200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.984600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.842700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>4.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.841800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.819400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.930500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.856600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.774700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>5.079600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.903200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.829700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>5.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>4.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.743400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>4.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.645900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.965900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.823700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.805800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.688200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>4.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>4.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.775200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>4.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>4.703100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.888600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.861100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>4.622300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>4.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>4.631200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.440700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:39:30,877 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:39:30,917 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:39:30,952 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:39:30,952 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =      5.009\n",
      "  train_runtime            = 0:02:56.90\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.611\n",
      "  train_steps_per_second   =      5.653\n",
      "03/21/2023 01:39:30 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:39:30 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp5r8g7e91/runs/Mar21_01-39-30_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp5r8g7e91,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp5r8g7e91,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:39:31 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:39:31 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:39:31 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:39:31 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:39:31 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5dc960ba1d40f6bc3ef546206ff30f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:39:31,394 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:39:31,396 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:39:31,425 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:39:31,450 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:39:31,451 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:39:31,515 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:39:31,516 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:39:31,516 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:39:31,517 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:39:31,517 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:39:31,521 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:39:31,522 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:39:31,573 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:39:31,734 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:39:33,887 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:39:33,888 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:39:33,925 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:39:33,926 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:39:33 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:39:34,152 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:39:34,171 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:39:34,172 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:39:34,173 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:39:34,173 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:39:34,174 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:39:34,174 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:39:34,175 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:39:34,177 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:39:34,188 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.943500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.333500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.714100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.720600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.710700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.476600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.406600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.338300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.587600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.243900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.302400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.242300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.536700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.181900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.224100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.137800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.044600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.133600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.214500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.976200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.164300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.374800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.100100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.202900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>5.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.985200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.984600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.842700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.943800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>4.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.947500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.841800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.819400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.930500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.856600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.774700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>5.079600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.903200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.829700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.704000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.933500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>5.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.739700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>4.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>5.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.743400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.754700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>4.781900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.917700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.645900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>5.394700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.775400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.965900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.823700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.805800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.688200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>4.701900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>4.782600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.670500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.705400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.775200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>4.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>4.703100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.664200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.888600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.861100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>4.622300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>4.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>4.631200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.440700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:42:41,947 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:42:41,993 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:42:42,022 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:42:42,023 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =      5.009\n",
      "  train_runtime            = 0:03:07.77\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     21.303\n",
      "  train_steps_per_second   =      5.326\n",
      "03/21/2023 01:42:42 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:42:42 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp94udgnpk/runs/Mar21_01-42-42_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp94udgnpk,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp94udgnpk,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:42:42 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:42:42 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:42:42 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:42:42 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:42:42 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f1a753adf94003a0a877ff939b0732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:42:42,525 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:42:42,527 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:42:42,557 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:42:42,584 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:42:42,585 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:42:42,643 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:42:42,643 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:42:42,644 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:42:42,644 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:42:42,645 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:42:42,648 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:42:42,650 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:42:42,704 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:42:42,867 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:42:44,954 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:42:44,955 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:42:44,992 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:42:44,993 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:42:45 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:42:45,219 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:42:45,238 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:42:45,239 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:42:45,239 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:42:45,240 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:42:45,240 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:42:45,242 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:42:45,242 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:42:45,244 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:42:45,257 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.662700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.804400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.491200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.881500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.882200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.732200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.784900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.627100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.563200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.486100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.412800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.305800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.275100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.277600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.336700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.239900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.360500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.296200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.139600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.217600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.191600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.080100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.980400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.073600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.068300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.929900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.966700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.853400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:45:43,471 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:45:43,520 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:45:43,559 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:45:43,560 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     3.3852\n",
      "  train_runtime            = 0:02:58.22\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.443\n",
      "  train_steps_per_second   =      5.611\n",
      "03/21/2023 01:45:43 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:45:43 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp6nwywrxz/runs/Mar21_01-45-43_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp6nwywrxz,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp6nwywrxz,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:45:43 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:45:43 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:45:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:45:43 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:45:43 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcc17e998504a1c985ce1d08e4c4f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:45:43,978 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:45:43,979 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:45:44,008 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:45:44,035 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:45:44,037 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:45:44,100 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:45:44,101 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:45:44,101 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:45:44,102 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:45:44,102 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:45:44,106 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:45:44,107 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:45:44,160 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:45:44,321 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:45:46,474 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:45:46,474 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:45:46,512 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:45:46,514 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:45:46 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:45:46,730 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:45:46,750 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:45:46,750 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:45:46,751 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:45:46,751 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:45:46,752 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:45:46,752 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:45:46,753 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:45:46,756 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:45:46,768 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:59, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.662700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.804400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.491200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.691100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.522000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.326500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.202100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.881500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.882200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.581600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.732200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.784900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.627100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.563200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.486100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.469400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.434400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.442500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.591700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.460700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.470400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.412800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.567200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.347700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.493200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.292700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.305800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.364400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.443000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.234700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.439000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.150400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.413100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.231800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.275100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.141900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.277600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.336700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.124800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.239900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.166100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.104700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.360500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.174800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.296200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.139600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.058200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.168300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.226000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.119300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.197000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.111300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.217600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.199100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.214000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.114900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.191600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.080100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.238700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.980400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.088900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.073600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.095000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.057700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.069600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.068300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.939000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.929900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.966700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.853400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:48:46,302 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:48:46,345 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:48:46,376 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:48:46,376 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     3.3852\n",
      "  train_runtime            = 0:02:59.54\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.278\n",
      "  train_steps_per_second   =       5.57\n",
      "03/21/2023 01:48:46 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:48:46 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpaa1rv6me/runs/Mar21_01-48-46_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpaa1rv6me,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpaa1rv6me,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:48:46 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:48:46 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:48:46 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:48:46 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:48:46 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4dc9b9831e4470fb26f7f1823ff6fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:48:46,792 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:48:46,794 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:48:46,822 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:48:46,850 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:48:46,852 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:48:46,911 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:48:46,912 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:48:46,913 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:48:46,913 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:48:46,914 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:48:46,917 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:48:46,919 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:48:46,970 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:48:47,130 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:48:49,239 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:48:49,240 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:48:49,275 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:48:49,276 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:48:49 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:48:49,484 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:48:49,502 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:48:49,503 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:48:49,503 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:48:49,504 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:48:49,504 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:48:49,505 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:48:49,505 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:48:49,507 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:48:49,518 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.858900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.275200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.744600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.622700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.602700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.306900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.330300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.339700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.249600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.188100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.191200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.994400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.974600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.967900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.715900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.776100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.863800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.742400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.682300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.817700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.894600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.815200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.657200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.763600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.719400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.736900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.817200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.817500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.713400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.635300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.814900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.536800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.835200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.687900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.578400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.755700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.607400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.649100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.706600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.525300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.703500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.662800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.629200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.351500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.652600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.351100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:51:53,543 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:51:53,583 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:51:53,615 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:51:53,615 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     3.9919\n",
      "  train_runtime            = 0:03:04.03\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     21.735\n",
      "  train_steps_per_second   =      5.434\n",
      "03/21/2023 01:51:53 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:51:53 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpew8uljxh/runs/Mar21_01-51-53_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpew8uljxh,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpew8uljxh,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:51:53 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:51:53 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:51:53 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:51:53 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:51:53 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136737e91b494df98ff22fe755f31e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:51:54,057 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:51:54,059 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:51:54,088 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:51:54,113 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:51:54,114 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:51:54,192 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:51:54,192 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:51:54,193 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:51:54,193 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:51:54,194 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:51:54,197 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:51:54,198 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:51:54,252 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:51:54,414 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:51:56,541 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:51:56,542 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:51:56,577 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:51:56,578 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:51:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:51:56,798 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:51:56,818 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:51:56,818 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:51:56,819 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:51:56,819 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:51:56,820 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:51:56,821 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:51:56,822 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:51:56,824 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:51:56,838 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:53, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.858900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.275200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.185500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.180200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.076600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.853400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.744600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.622700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.602700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.692800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.364500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.461000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.306900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.330300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.339700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.249600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.188100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.183400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.085000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.157400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.191200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.994400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.176000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.209500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.974600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.110900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.932300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.038800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.816000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.078400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.967900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.715900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.776100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.863800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.742400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.858300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.682300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.817700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.894600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.815200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.657200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.951300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.763600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.855100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.719400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.573500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.736900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.817200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.753100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.662300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.817500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.846400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.644400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.713400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.635300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.814900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.536800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.812100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.762700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.835200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.687900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.578400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.755700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.463100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.607400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.649100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.706600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.495300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.611500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.525300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.703500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.662800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.629200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.351500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.652600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.511000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.547300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.351100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:54:50,318 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:54:50,360 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:54:50,391 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:54:50,392 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     3.9919\n",
      "  train_runtime            = 0:02:53.49\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     23.055\n",
      "  train_steps_per_second   =      5.764\n",
      "03/21/2023 01:54:50 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:54:50 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpnei8prcm/runs/Mar21_01-54-50_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpnei8prcm,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpnei8prcm,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:54:50 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:54:50 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:54:50 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:54:50 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:54:50 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df520cf1e2a4ad89913ab8055b55046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:54:50,801 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:54:50,802 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:54:50,832 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:54:50,861 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:54:50,862 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:54:50,925 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:54:50,926 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:54:50,926 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:54:50,927 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:54:50,927 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:54:50,930 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:54:50,932 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:54:50,984 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:54:51,145 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:54:53,335 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:54:53,337 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:54:53,378 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:54:53,379 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:54:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:54:53,591 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:54:53,610 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:54:53,611 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:54:53,611 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:54:53,612 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:54:53,612 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:54:53,612 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:54:53,613 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:54:53,616 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:54:53,627 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.918800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.663600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.650800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.572400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.947700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.243800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.062800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.971500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.944100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.960800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.966500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.878100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.953500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.905300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.810600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.991300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.889300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.572200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.668500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.834800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.810200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.628700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.565800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.590800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.651200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.639900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.668400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.703800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.776100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.560500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.517300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.624300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.528800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.638100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.322300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.574900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.641200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.586200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.518200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.514500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.575700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.418200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.455100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.320600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.316000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 01:57:49,073 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 01:57:49,130 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 01:57:49,160 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 01:57:49,161 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     2.8307\n",
      "  train_runtime            = 0:02:55.45\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.797\n",
      "  train_steps_per_second   =      5.699\n",
      "03/21/2023 01:57:49 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 01:57:49 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpthjcb690/runs/Mar21_01-57-49_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpthjcb690,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpthjcb690,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 01:57:49 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:57:49 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 01:57:49 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 01:57:49 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 01:57:49 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51748149a451400984c6f2956719a6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 01:57:49,613 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:57:49,614 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 01:57:49,650 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:57:49,678 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:57:49,679 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:57:49,742 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:57:49,742 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:57:49,743 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:57:49,743 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 01:57:49,744 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 01:57:49,747 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 01:57:49,749 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 01:57:49,801 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:57:49,963 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 01:57:52,192 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 01:57:52,193 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 01:57:52,231 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 01:57:52,233 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 01:57:52 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 01:57:52,490 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 01:57:52,509 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 01:57:52,510 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 01:57:52,510 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 01:57:52,511 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 01:57:52,511 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 01:57:52,511 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 01:57:52,512 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 01:57:52,514 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 01:57:52,527 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:52, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.918800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.663600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.650800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.572400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.373500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.253900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.109900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.330400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.072700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.947700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.154100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.243800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.062800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.136000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.971500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.944100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.960800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.926000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.966500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.878100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.953500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.905300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.810600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.908400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.991300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.889300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.572200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.668500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.731100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.834800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.766300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.615900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.748700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.810200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.631300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.676800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.628700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.565800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.683800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.590800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.651200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.689800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.639900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.668400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.703800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.655600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.776100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.560500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.521600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.597900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.517300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.619000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.624300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.528800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.461500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.638100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.436000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.322300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.574900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.532300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.641200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.586200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.518200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.387800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.514500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.575700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.461700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.418200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.488900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.455100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.465800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.320600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.316000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:00:45,444 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:00:45,492 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:00:45,522 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:00:45,523 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     2.8307\n",
      "  train_runtime            = 0:02:52.93\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     23.131\n",
      "  train_steps_per_second   =      5.783\n",
      "03/21/2023 02:00:45 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:00:45 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpz89106ii/runs/Mar21_02-00-45_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpz89106ii,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpz89106ii,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:00:45 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:00:45 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:00:45 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:00:45 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:00:45 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d16ab4226a4766891b77e74ab4b078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:00:46,041 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:00:46,043 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:00:46,073 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:00:46,100 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:00:46,102 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:00:46,165 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:00:46,166 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:00:46,166 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:00:46,167 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:00:46,168 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:00:46,172 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:00:46,173 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:00:46,225 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:00:46,386 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:00:48,504 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:00:48,505 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:00:48,543 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:00:48,544 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:00:48 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:00:48,763 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:00:48,782 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:00:48,782 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:00:48,783 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:00:48,783 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:00:48,784 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:00:48,784 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:00:48,784 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:00:48,788 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:00:48,798 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:56, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.867300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.722300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.629200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.358800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.531200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.349400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.246700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.372600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.324100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.249300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.152200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.398100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.038600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.915100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.870400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.945800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.990800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.882700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.808600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.980900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.794500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.732700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.874900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.772100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.797600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.767900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.886600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.801500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.775700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.749300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.649700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:03:45,757 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:03:45,794 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:03:45,826 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:03:45,827 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     3.1609\n",
      "  train_runtime            = 0:02:56.97\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.603\n",
      "  train_steps_per_second   =      5.651\n",
      "03/21/2023 02:03:45 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:03:45 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpihulvuyh/runs/Mar21_02-03-45_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpihulvuyh,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpihulvuyh,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:03:46 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:03:46 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:03:46 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:03:46 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:03:46 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0572f87457224fb88684bc1c6de28239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:03:46,292 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:03:46,294 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:03:46,324 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:03:46,350 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:03:46,352 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:03:46,412 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:03:46,413 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:03:46,413 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:03:46,414 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:03:46,414 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:03:46,417 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:03:46,418 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:03:46,470 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:03:46,630 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:03:48,744 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:03:48,745 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:03:48,781 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:03:48,782 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:03:48 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:03:49,005 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:03:49,024 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:03:49,024 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:03:49,025 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:03:49,025 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:03:49,026 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:03:49,026 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:03:49,026 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:03:49,028 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:03:49,041 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:01, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.457000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.521300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.201600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.172600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.867300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.722300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.598500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.461400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.629200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.517500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.358800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.531200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.259200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.349400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.249000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.246700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.372600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.258000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.148900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.324100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.249300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.202300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.152200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.398100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.152600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.282000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.084200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.089600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.161100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.038600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.214600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.209900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.937600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.037700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.118000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.915100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.896400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.142300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.931400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.930400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.870400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.945800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.990800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.944400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.928400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.907300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.882700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.963300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.808600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.980900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.994200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.881400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.794500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.975700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.732700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.874900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.772100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.904100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.863900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.797600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.767900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.886600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.899900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.801500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.775700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.571400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.857900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.749300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.679400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.649700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:06:50,242 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:06:50,281 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:06:50,313 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:06:50,314 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     3.1609\n",
      "  train_runtime            = 0:03:01.21\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.073\n",
      "  train_steps_per_second   =      5.518\n",
      "03/21/2023 02:06:50 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:06:50 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmprf2cq5m1/runs/Mar21_02-06-50_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmprf2cq5m1,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmprf2cq5m1,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:06:50 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:06:50 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:06:50 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:06:50 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:06:50 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c50cdcd7b8d4ae984da780a4bc469dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:06:50,728 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:06:50,729 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:06:50,758 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:06:50,784 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:06:50,785 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:06:50,847 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:06:50,848 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:06:50,848 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:06:50,849 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:06:50,849 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:06:50,853 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:06:50,854 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:06:50,906 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:06:51,078 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:06:53,198 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:06:53,199 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:06:53,236 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:06:53,237 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:06:53 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:06:53,454 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:06:53,473 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:06:53,474 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:06:53,475 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:06:53,475 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:06:53,476 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:06:53,477 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:06:53,479 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:06:53,481 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:06:53,492 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.967200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.900100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.785200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.586100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.501200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.414300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.364100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.452400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.493300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.534500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.331300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.369600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.240600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.337700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.254900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.187200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>4.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>4.053400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.092700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.959400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.929300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.931100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>4.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.912300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.945300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.804200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.721600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.900100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.949500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.835400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.202400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.896200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.721800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.796500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.998300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.913200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.829300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:09:48,685 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:09:48,728 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:09:48,760 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:09:48,761 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     4.1783\n",
      "  train_runtime            = 0:02:55.20\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.831\n",
      "  train_steps_per_second   =      5.708\n",
      "03/21/2023 02:09:48 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:09:48 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmplqchla0x/runs/Mar21_02-09-48_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmplqchla0x,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmplqchla0x,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:09:48 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:09:49 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:09:49 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:09:49 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:09:49 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef35744db0684c4780b82d67db01cfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:09:49,168 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:09:49,170 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:09:49,198 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:09:49,224 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:09:49,226 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:09:49,282 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:09:49,283 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:09:49,284 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:09:49,284 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:09:49,285 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:09:49,288 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:09:49,289 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:09:49,341 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:09:49,503 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:09:51,623 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:09:51,624 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:09:51,670 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:09:51,670 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:09:51 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:09:51,897 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:09:51,917 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:09:51,917 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:09:51,918 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:09:51,918 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:09:51,918 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:09:51,919 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:09:51,919 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:09:51,921 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:09:51,934 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.147400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.967200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.900100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.975800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.785200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.586100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.501200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.438100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.591200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.414300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.364100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.452400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.493300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.364300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.534500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.331300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.401600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.103500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.369600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.319300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.256300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.240600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.210500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.337700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.254900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.157500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.187200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.149900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>4.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>4.053400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.319000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.071400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.219000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.168400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.097100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.999200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.904000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.889500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.092700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.959400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.929300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.931100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>4.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.912300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.945300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.804200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.846500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.721600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.900100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.949500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.835400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.202400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.812900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.684300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.896200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.942700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.721800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.796500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.998300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.650500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.913200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.829300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:12:49,502 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:12:49,548 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:12:49,579 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:12:49,580 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     4.1783\n",
      "  train_runtime            = 0:02:57.58\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.525\n",
      "  train_steps_per_second   =      5.631\n",
      "03/21/2023 02:12:49 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:12:49 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpoyrto5mt/runs/Mar21_02-12-49_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpoyrto5mt,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpoyrto5mt,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:12:49 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:12:49 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:12:49 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:12:49 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:12:49 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f0931a8bff4f96849318822c9e92ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:12:50,047 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:12:50,048 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:12:50,080 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:12:50,108 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:12:50,109 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:12:50,173 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:12:50,174 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:12:50,174 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:12:50,175 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:12:50,175 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:12:50,178 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:12:50,180 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:12:50,232 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:12:50,392 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:12:52,489 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:12:52,490 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:12:52,529 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:12:52,530 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:12:52 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:12:52,760 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:12:52,779 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:12:52,780 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:12:52,780 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:12:52,781 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:12:52,781 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:12:52,782 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:12:52,782 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:12:52,784 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:12:52,797 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:08, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.853300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.175900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.740200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.871700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.719500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.604100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.359600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.061200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.284900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.992800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.044100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.905700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.995600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.697300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.833700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.590700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.672900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.753800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.847200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.820900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.796200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.872400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.675900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.621500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.657800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.608700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.622300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.659300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.674800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.681700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.827600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.544700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.533800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.621800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.564400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.714400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.639400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.436300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.381900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.633600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.419800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.523100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.379800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.499200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.535300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.466300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.477300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.493100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.434300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:16:01,490 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:16:01,530 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:16:01,561 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:16:01,561 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     2.8659\n",
      "  train_runtime            = 0:03:08.70\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     21.197\n",
      "  train_steps_per_second   =      5.299\n",
      "03/21/2023 02:16:01 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:16:01 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpr8sbyrko/runs/Mar21_02-16-01_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpr8sbyrko,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpr8sbyrko,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=20,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:16:01 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:16:01 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:16:01 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:16:01 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:16:01 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10164b9cd99c480280d512f26fc0d91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:16:01,981 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:16:01,982 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:16:02,013 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:16:02,037 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:16:02,039 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:16:02,101 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:16:02,102 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:16:02,102 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:16:02,103 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:16:02,103 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:16:02,106 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:16:02,108 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:16:02,160 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:16:02,320 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:16:04,461 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:16:04,462 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:16:04,500 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:16:04,501 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:16:04 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:16:04,717 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:16:04,736 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:16:04,736 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:16:04,737 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:16:04,737 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:16:04,738 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:16:04,738 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:16:04,739 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:16:04,741 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:16:04,752 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.853300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.175900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.740200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.871700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.719500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.604100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.356500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.142700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.373700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.359600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.061200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.221000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.284900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.992800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.039300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.987200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.913500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.044100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.904200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.106700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.994700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.875500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.113000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.905700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.995600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.892300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.697300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.833700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.590700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.672900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.931700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.753800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.847200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.599600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.820900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.796200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.872400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.675900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.750100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.621500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.839000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.693000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.657800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.608700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.622300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.659300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.680700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.674800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.709700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.681700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.827600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.544700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.533800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.621800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.564400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.714400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.699700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.639400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.436300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.627000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.434100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.381900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.633600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.419800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.660500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.523100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.379800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.499200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.535300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.466300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.420800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.253000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.477300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.493100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.342500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.434300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:19:00,596 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:19:00,640 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   259078GF\n",
      "  train_loss               =     2.8659\n",
      "  train_runtime            = 0:02:55.85\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.746\n",
      "  train_steps_per_second   =      5.686\n"
     ]
    }
   ],
   "source": [
    "result_dirs_20 = []\n",
    "for lr in lrs:\n",
    "    result_dirs_20.append(run_translation_func(lr, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e623ea0-2eca-4281-bbe8-cca340c920b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1509] 2023-03-21 02:19:00,679 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:19:00,680 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:19:00 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:19:00 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpv3mgwlxn/runs/Mar21_02-19-00_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpv3mgwlxn,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpv3mgwlxn,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:19:00 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:19:01 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:19:01 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:19:01 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:19:01 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b9973bda214b92b4b6256e25c2bedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:19:01,128 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:19:01,130 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:19:01,159 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:19:01,186 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:19:01,187 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:19:01,250 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:19:01,250 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:19:01,251 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:19:01,251 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:19:01,252 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:19:01,255 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:19:01,256 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:19:01,308 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:19:01,470 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:19:03,599 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:19:03,600 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:19:03,638 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:19:03,639 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:19:03 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:19:03,842 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:19:03,861 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:19:03,862 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:19:03,862 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:19:03,863 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:19:03,863 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:19:03,864 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:19:03,864 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:19:03,866 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:19:03,877 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.279700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.537300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.501800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.729900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.306400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.456300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.188600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.398500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.384900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.238600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.189100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.949500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>5.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.055800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>5.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>4.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.057200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.898900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>5.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.722500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.771300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.845300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.869400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.897900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.778200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.798700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>4.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.891900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>4.718600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.913200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.709800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>4.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.707100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.785800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.756500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.805500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.692700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.658400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>4.918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>4.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.800500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.815900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>4.801600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.789100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>4.762100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.696600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>4.717600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>4.629500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>4.486800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.586500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:21:59,371 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:21:59,414 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:21:59,445 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:21:59,446 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =       5.02\n",
      "  train_runtime            = 0:02:55.50\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.791\n",
      "  train_steps_per_second   =      5.698\n",
      "03/21/2023 02:21:59 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:21:59 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpozm971_m/runs/Mar21_02-21-59_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpozm971_m,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpozm971_m,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:21:59 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:21:59 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:21:59 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:21:59 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:21:59 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93ad2e6e8db4220b0851cc331b379a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:21:59,891 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:21:59,893 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:21:59,930 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:21:59,956 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:21:59,957 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:22:00,025 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:22:00,026 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:22:00,027 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:22:00,027 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:22:00,028 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:22:00,031 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:22:00,032 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:22:00,086 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:22:00,248 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:22:02,342 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:22:02,344 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:22:02,384 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:22:02,385 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:22:02 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:22:02,607 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:22:02,626 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:22:02,626 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:22:02,627 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:22:02,627 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:22:02,628 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:22:02,628 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:22:02,629 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:22:02,630 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:22:02,644 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.441500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.776000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.279700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.537300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.674700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.501800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.546100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.205400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.238100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.729900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.547500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.418800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.306400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.492600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.301900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.214900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.456300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.290300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.128300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.118100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.246400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.188600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.398500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.223600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>5.384900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.238600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>5.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.189100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.943000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.068900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.949500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>5.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.055800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.098400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>5.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>4.903100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.057200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.898900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>5.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.722500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.771300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.980300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.845300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.869400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.897900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.760400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.778200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.798700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.647500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.106800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>4.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.944900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.891900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>4.718600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.913200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.709800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>4.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.707100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.715100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.785800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.756500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.805500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.692700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.784300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.658400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>4.918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>4.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.800500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.815900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.640600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.836500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>4.801600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.789100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>4.762100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.620400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.696600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>4.717600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>4.629500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>4.486800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.586500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:24:59,872 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:24:59,912 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:24:59,943 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:24:59,944 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =       5.02\n",
      "  train_runtime            = 0:02:57.24\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.568\n",
      "  train_steps_per_second   =      5.642\n",
      "03/21/2023 02:24:59 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:24:59 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp3uubewoh/runs/Mar21_02-24-59_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp3uubewoh,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp3uubewoh,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:25:00 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:25:00 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:25:00 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:25:00 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:25:00 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d7d364cd5f4e54ac3feabec2cf842c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:25:00,354 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:25:00,356 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:25:00,397 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:25:00,433 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:25:00,435 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:25:00,505 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:25:00,506 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:25:00,506 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:25:00,507 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:25:00,507 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:25:00,510 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:25:00,512 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:25:00,565 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:25:00,727 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:25:02,829 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:25:02,830 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:25:02,865 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:25:02,866 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:25:02 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:25:03,089 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:25:03,108 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:25:03,108 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:25:03,109 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:25:03,110 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:25:03,110 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:25:03,111 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:25:03,111 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:25:03,113 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:25:03,124 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:53, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.507600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.715200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.735800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.654200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.926700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.923700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.510300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.523400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.317200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.562100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.395700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.418600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.161700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.280600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.325400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.331700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.335700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.167900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.314700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.119800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.291300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.280900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.230600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.924300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.953200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.997600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.814500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:27:56,760 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:27:56,801 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:27:56,833 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:27:56,834 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     3.3884\n",
      "  train_runtime            = 0:02:53.64\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     23.035\n",
      "  train_steps_per_second   =      5.759\n",
      "03/21/2023 02:27:56 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:27:56 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmprtigpejq/runs/Mar21_02-27-56_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmprtigpejq,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmprtigpejq,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:27:57 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:27:57 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:27:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:27:57 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:27:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f2a3a6c990460ebdb7f8f1e63cceea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:27:57,269 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:27:57,270 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:27:57,300 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:27:57,326 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:27:57,327 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:27:57,390 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:27:57,390 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:27:57,391 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:27:57,391 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:27:57,392 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:27:57,396 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:27:57,398 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:27:57,449 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:27:57,610 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:27:59,724 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:27:59,725 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:27:59,762 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:27:59,763 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:27:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:28:00,022 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:28:00,042 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:28:00,043 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:28:00,043 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:28:00,043 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:28:00,044 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:28:00,044 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:28:00,045 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:28:00,047 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:28:00,060 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:52, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.507600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.715200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.687000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.321800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.313300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.986000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.951600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.735800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.654200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.926700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.923700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.405700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.647900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.510300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.424200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.523400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.317200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.318200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.562100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.407300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.395700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.285500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.418600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.252900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.161700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.280600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.325400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.331700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.335700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.331800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.167900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.260600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.314700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.348400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.119800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.132100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.304800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.327800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.291300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.114500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.105300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.306100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.115600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.280900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.043100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.361800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.291800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.179000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.339900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.187000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.232200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.046300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.144100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.230600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.203600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.095600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.958600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.113300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.924300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.122000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.071800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.953200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.997600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.814500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:30:52,777 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:30:52,820 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:30:52,851 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:30:52,852 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     3.3884\n",
      "  train_runtime            = 0:02:52.73\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     23.157\n",
      "  train_steps_per_second   =      5.789\n",
      "03/21/2023 02:30:52 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:30:52 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpurtkotw5/runs/Mar21_02-30-52_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpurtkotw5,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpurtkotw5,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:30:53 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:30:53 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:30:53 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:30:53 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:30:53 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7c2cab17594a1eab67f5d15ee74b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:30:53,295 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:30:53,296 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:30:53,326 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:30:53,352 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:30:53,354 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:30:53,415 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:30:53,416 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:30:53,417 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:30:53,418 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:30:53,418 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:30:53,422 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:30:53,423 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:30:53,474 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:30:53,633 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:30:55,725 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:30:55,726 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:30:55,762 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:30:55,763 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:30:55 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:30:56,028 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:30:56,047 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:30:56,047 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:30:56,047 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:30:56,048 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:30:56,048 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:30:56,049 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:30:56,049 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:30:56,051 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:30:56,064 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.336900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.914200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.520500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.401400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.653800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.607800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.514500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.406600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.237700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.990100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.952300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.962900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.891500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.844600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.910600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.862200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.697100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.861600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.791800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.695100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.631600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.864300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.856400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.815400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.840600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.861200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.728700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.659200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.682700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.605200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.423700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.690400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.611800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.599200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.587200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.644900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.513800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.478500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.376000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:33:55,091 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:33:55,133 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:33:55,164 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:33:55,165 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     4.0009\n",
      "  train_runtime            = 0:02:59.03\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.341\n",
      "  train_steps_per_second   =      5.585\n",
      "03/21/2023 02:33:55 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:33:55 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp9gwwwaz4/runs/Mar21_02-33-55_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp9gwwwaz4,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp9gwwwaz4,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:33:55 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:33:55 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:33:55 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:33:55 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:33:55 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6d86a89e0b4a1180ea7e7fcbae4934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:33:55,588 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:33:55,590 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:33:55,619 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:33:55,644 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:33:55,646 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:33:55,703 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:33:55,703 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:33:55,704 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:33:55,705 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:33:55,705 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:33:55,709 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:33:55,710 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:33:55,761 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:33:55,923 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:33:58,138 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:33:58,139 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:33:58,181 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:33:58,182 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:33:58 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:33:58,394 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:33:58,414 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:33:58,414 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:33:58,415 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:33:58,415 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:33:58,416 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:33:58,416 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:33:58,417 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:33:58,419 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:33:58,430 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.983000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.217800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.336900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.914200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.792500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.520500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.401400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.869800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.653800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.607800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.514500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.159000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.406600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.237700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.124700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.179400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.974300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.259900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.062300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.140800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.122700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.990100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.694800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.952300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.935200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.962900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.891500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.987100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.844600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.910600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.862200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.933000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.697100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.704100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.861600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.812000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.791800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.695100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.669500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.631600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.864300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.664000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.924200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.577500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.856400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.815400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.558200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.840600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.653100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.861200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.612500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.728700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.695800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.588000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.720400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.659400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.659200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.560800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.682700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.605200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.680500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.423700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.694500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.690400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.536000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.617400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.611800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.599200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.587200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.644900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.513800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.478500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.376000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:36:57,563 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:36:57,602 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:36:57,633 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:36:57,633 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     4.0009\n",
      "  train_runtime            = 0:02:59.14\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.328\n",
      "  train_steps_per_second   =      5.582\n",
      "03/21/2023 02:36:57 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:36:57 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpfl7p47bi/runs/Mar21_02-36-57_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpfl7p47bi,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpfl7p47bi,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:36:57 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:36:57 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:36:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:36:58 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:36:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d67a11c6844541b4890ffb43cdfe66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:36:58,059 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:36:58,061 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:36:58,090 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:36:58,116 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:36:58,118 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:36:58,178 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:36:58,179 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:36:58,179 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:36:58,180 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:36:58,180 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:36:58,184 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:36:58,185 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:36:58,238 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:36:58,398 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:37:00,590 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:37:00,592 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:37:00,630 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:37:00,631 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:37:00 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:37:00,852 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:37:00,871 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:37:00,871 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:37:00,872 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:37:00,872 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:37:00,873 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:37:00,874 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:37:00,875 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:37:00,876 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:37:00,889 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:53, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.523900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.624100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.359100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.172900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.895300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.808800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.056400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.939900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.839300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.884300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.820800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.890500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.767400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.964300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.782400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.805200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.772100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.777800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.684700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.723500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.836600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.640400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.797600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.641700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.640700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.563700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.847400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.725500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.563400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.495700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.617700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.546300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.577100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.585500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.725800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.632900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.447400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.513700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.629100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.585300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.582100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.432700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.522600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.333000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:39:54,173 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:39:54,211 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:39:54,240 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:39:54,240 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     2.8596\n",
      "  train_runtime            = 0:02:53.29\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     23.082\n",
      "  train_steps_per_second   =       5.77\n",
      "03/21/2023 02:39:54 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:39:54 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpp4siu314/runs/Mar21_02-39-54_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpp4siu314,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpp4siu314,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:39:54 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:39:54 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:39:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:39:54 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:39:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2899c39c5da409fa5a3dcaa1de1a720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:39:54,690 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:39:54,692 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:39:54,723 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:39:54,749 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:39:54,751 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:39:54,815 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:39:54,816 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:39:54,817 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:39:54,818 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:39:54,818 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:39:54,821 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:39:54,822 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:39:54,875 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:39:55,040 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:39:57,132 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:39:57,133 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:39:57,171 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:39:57,172 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:39:57 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:39:57,393 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:39:57,413 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:39:57,414 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:39:57,414 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:39:57,415 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:39:57,415 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:39:57,416 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:39:57,416 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:39:57,419 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:39:57,432 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:58, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.939300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.802100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.523900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.624100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.327700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.465400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.385100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.359100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.172900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.310400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.457400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.197200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.185700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.220700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.939800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.981300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.895300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.808800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.768100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.056400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.093100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.939900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.839300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.884300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.820800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.891200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.890500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.767400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>2.964300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.782400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.805200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.819200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.772100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.777800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.672400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.684700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.877000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.723500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.834000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.836600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.640400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.605900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.797600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.582500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.641700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.640700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.765300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.563700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.737400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.507300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.847400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.725500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.563400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.776800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.495700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.617700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.802300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.546300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.577100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.585500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.601600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.522900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.567600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.387400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.725800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.610600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.632900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.447400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.605300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.525900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.513700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.629100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.585300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.582100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.432700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.522600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.333000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:42:56,352 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:42:56,396 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:42:56,425 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:42:56,426 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     2.8596\n",
      "  train_runtime            = 0:02:58.93\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.355\n",
      "  train_steps_per_second   =      5.589\n",
      "03/21/2023 02:42:56 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:42:56 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp7jb9jzst/runs/Mar21_02-42-56_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp7jb9jzst,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp7jb9jzst,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:42:56 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:42:56 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:42:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:42:56 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:42:56 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf7ecbb69e2f41e7a6dd893c88e0ef25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:42:56,846 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:42:56,847 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:42:56,877 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:42:56,904 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:42:56,906 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:42:56,967 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:42:56,968 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:42:56,968 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:42:56,969 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:42:56,969 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:42:56,972 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:42:56,974 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:42:57,026 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:42:57,185 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:42:59,374 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:42:59,375 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:42:59,415 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:42:59,416 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:42:59 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:42:59,659 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:42:59,677 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:42:59,678 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:42:59,679 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:42:59,679 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:42:59,680 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:42:59,680 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:42:59,681 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:42:59,682 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:42:59,695 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.501600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.774900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.716300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.451700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.201200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.401300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.312400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.335900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.386900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.358100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.251100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.064400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.959600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.927800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.915700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.916900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.915900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.803500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.834300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.976200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.890900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.908700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.966200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.839200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.930300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.846900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.774100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.660100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.992700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.924400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.766400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.909200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.724700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.935600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.718300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.820300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.605700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:45:55,117 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:45:55,161 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:45:55,197 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:45:55,198 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =      3.184\n",
      "  train_runtime            = 0:02:55.43\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =       22.8\n",
      "  train_steps_per_second   =        5.7\n",
      "03/21/2023 02:45:55 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:45:55 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpwrss23lq/runs/Mar21_02-45-55_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpwrss23lq,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpwrss23lq,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:45:55 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:45:55 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:45:55 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:45:55 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:45:55 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01331a71afcb4ba5be24613164915515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:45:55,635 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:45:55,636 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:45:55,665 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:45:55,692 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:45:55,694 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:45:55,751 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:45:55,752 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:45:55,753 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:45:55,753 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:45:55,753 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:45:55,757 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:45:55,758 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:45:55,810 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:45:55,971 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:45:58,188 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:45:58,189 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:45:58,224 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:45:58,225 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:45:58 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:45:58,447 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:45:58,466 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:45:58,467 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:45:58,467 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:45:58,468 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:45:58,468 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:45:58,469 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:45:58,470 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:45:58,472 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:45:58,485 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:55, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>4.501600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>4.411000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.032100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.774900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.655900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.664600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.522200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.436100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.716300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.458600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.451700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.505200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.201200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.439200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.401300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.312400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.316900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.209800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.335900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.101500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.386900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.380800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.358100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.251100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.185600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.194800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>3.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>3.034800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.262900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.992000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.064400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.128600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.126300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.108100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.959600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.166600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.927800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.114600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.124600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.089500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.881900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.915700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.916900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.104900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.915900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.803500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.834300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.848300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.095900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.870600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.976200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.890900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.908700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.966200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.839200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.930300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.846900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.916700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.774100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.660100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.992700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.924400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.766400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.909200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.724700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.935600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.879200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.718300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.820300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.605700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:48:54,157 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:48:54,195 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:48:54,224 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:48:54,225 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =      3.184\n",
      "  train_runtime            = 0:02:55.68\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.768\n",
      "  train_steps_per_second   =      5.692\n",
      "03/21/2023 02:48:54 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:48:54 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpy6btxi5_/runs/Mar21_02-48-54_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpy6btxi5_,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpy6btxi5_,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:48:54 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:48:54 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:48:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:48:54 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:48:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0736be7de946ce97d6ef5a20ed5b4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:48:54,666 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:48:54,668 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:48:54,698 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:48:54,726 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:48:54,727 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:48:54,784 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:48:54,785 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:48:54,786 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:48:54,786 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:48:54,787 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:48:54,789 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:48:54,791 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:48:54,842 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:48:55,004 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:48:57,112 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:48:57,113 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:48:57,149 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:48:57,150 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:48:57 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:48:57,367 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:48:57,478 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:48:57,479 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:48:57,479 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:48:57,480 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:48:57,480 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:48:57,481 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:48:57,481 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:48:57,483 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:48:57,496 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:59, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.855400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.709300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.728800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.680400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.573300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.661200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.776400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.443800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.535400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.644800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.419300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.481100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.419800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.553600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.378800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.174300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.246200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.084600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.165300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.986300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>4.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.265300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.884700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.975900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.173700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.978700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.901200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.069400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.123200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.952800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.780700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.946800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.983300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.692800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:51:56,952 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:51:56,994 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:51:57,025 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:51:57,026 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     4.2372\n",
      "  train_runtime            = 0:02:59.46\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.288\n",
      "  train_steps_per_second   =      5.572\n",
      "03/21/2023 02:51:57 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:51:57 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.005,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp4vpoq4m3/runs/Mar21_02-51-57_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp4vpoq4m3,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp4vpoq4m3,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:51:57 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:51:57 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:51:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:51:57 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:51:57 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24eddaf91a764f12bdb0e45454b4bbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:51:57,431 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:51:57,432 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:51:57,461 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:51:57,488 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:51:57,489 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:51:57,547 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:51:57,548 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:51:57,549 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:51:57,549 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:51:57,550 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:51:57,553 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:51:57,554 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:51:57,606 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:51:57,767 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:51:59,965 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:51:59,966 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:52:00,005 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:52:00,006 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:52:00 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:52:00,222 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:52:00,241 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:52:00,242 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:52:00,242 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:52:00,243 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:52:00,243 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:52:00,243 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:52:00,244 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:52:00,246 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:52:00,259 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.437700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.254200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.114200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>4.855400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.709300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.728800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>4.788000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>4.680400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.573300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>4.661200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.776400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.512000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.443800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.535400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.644800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.419300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.660600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.538700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.481100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.413800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.419800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.350500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.553600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.436500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.288400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.238900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.378800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.174300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.246200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.084600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>4.241800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.165300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.986300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>4.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>4.128200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.119600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.161400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.265300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.984400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>4.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>4.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.148300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.884700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.975900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.206800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.173700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.941900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.070900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.923300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.989300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.069800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.978700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.000800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.901200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.932400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.069400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.123200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.960100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.952800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.780700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.099000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.936700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.960300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.798500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.946800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.983300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.916000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.892800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.809400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.692800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:54:58,317 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:54:58,357 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:54:58,387 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:54:58,388 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     4.2372\n",
      "  train_runtime            = 0:02:58.07\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.463\n",
      "  train_steps_per_second   =      5.616\n",
      "03/21/2023 02:54:58 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:54:58 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpuhkmo8re/runs/Mar21_02-54-58_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpuhkmo8re,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpuhkmo8re,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:54:58 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:54:58 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:54:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:54:58 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:54:58 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384691f780454d4c8922a5bd6009a9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:54:58,891 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:54:58,893 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:54:58,922 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:54:58,946 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:54:58,947 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:54:59,007 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:54:59,007 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:54:59,008 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:54:59,009 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:54:59,009 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:54:59,012 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:54:59,013 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:54:59,065 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:54:59,224 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:55:01,350 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:55:01,350 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:55:01,389 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:55:01,390 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:55:01 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:55:01,669 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:55:01,689 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:55:01,690 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:55:01,690 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:55:01,691 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:55:01,691 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:55:01,692 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:55:01,692 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:55:01,694 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:55:01,707 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.824500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.529600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.716100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.315400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.210100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.982700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.260300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.998600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.859900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.776700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.909300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.861700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.879500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.944200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.811600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.807100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.887100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.677700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.815500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.841300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.826300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.656500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.812600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.558800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.825600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.726800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.600600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.766900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.745100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.786400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.525200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.658400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.543600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.570500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.603500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.600200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.609400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.719800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.425300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.744200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.598100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.612200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.638500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.564200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.375900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 02:57:53,882 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 02:57:53,924 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1509] 2023-03-21 02:57:53,956 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1290] 2023-03-21 02:57:53,957 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     2.8793\n",
      "  train_runtime            = 0:02:52.18\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =      23.23\n",
      "  train_steps_per_second   =      5.808\n",
      "03/21/2023 02:57:53 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/21/2023 02:57:53 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=0.99,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpq3gjnfwf/runs/Mar21_02-57-53_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpq3gjnfwf,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpq3gjnfwf,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=32,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/21/2023 02:57:54 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:57:54 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/21/2023 02:57:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/21/2023 02:57:54 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/21/2023 02:57:54 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb40cae814324bfcbcd34b86edb8d884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-21 02:57:54,459 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:57:54,461 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-21 02:57:54,490 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:57:54,517 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:57:54,518 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:57:54,578 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:57:54,579 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:57:54,580 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:57:54,580 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-21 02:57:54,581 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-21 02:57:54,586 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-21 02:57:54,587 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-21 02:57:54,641 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:57:54,800 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-21 02:57:56,911 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-21 02:57:56,912 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-21 02:57:56,951 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-21 02:57:56,952 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/21/2023 02:57:56 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-21 02:57:57,173 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1745] 2023-03-21 02:57:57,191 >> ***** Running training *****\n",
      "[INFO|trainer.py:1746] 2023-03-21 02:57:57,192 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1747] 2023-03-21 02:57:57,192 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1748] 2023-03-21 02:57:57,193 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1749] 2023-03-21 02:57:57,193 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1750] 2023-03-21 02:57:57,194 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1751] 2023-03-21 02:57:57,194 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1753] 2023-03-21 02:57:57,196 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-21 02:57:57,208 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:06, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.593200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.927900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.824500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.529600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.716100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.450100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.412000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.315400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.203800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.228500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.210100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.268900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.982700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.260300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.998600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.859900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.776700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.155300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.909300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.861700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.879500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>2.816200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.944200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.811600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>2.808100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.807100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.887100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.837100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.677700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.688100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.920500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.733600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.815500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.841300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.667400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.810900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.826300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.656500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.626800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.677600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.812600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.630400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.558800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.825600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.726800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.600600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.766900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.745100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.786400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.525200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.658400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.825100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.543600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.570500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.599300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.603500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.529000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.687300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.600200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.710300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.609400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.368000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.719800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.425300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.744200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.598100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.612200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.460600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.638500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.520100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.539200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.658500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.599700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.611900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.393100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.564200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.375900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2019] 2023-03-21 03:01:03,633 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-21 03:01:03,677 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248406GF\n",
      "  train_loss               =     2.8793\n",
      "  train_runtime            = 0:03:06.43\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     21.455\n",
      "  train_steps_per_second   =      5.364\n"
     ]
    }
   ],
   "source": [
    "result_dirs_32 = []\n",
    "for lr in lrs:\n",
    "    result_dirs_32.append(run_translation_func(lr, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b84b8dc-2cac-4a92-8d3a-cec921908513",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_seed(result_dirs, name):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(4)\n",
    "    ax = fig.add_subplot(111)\n",
    "    c=0\n",
    "    tflag=1\n",
    "    tflaglabel=[' ','run-1 ','run-2 ']\n",
    "    tcolors=[' ','ro','k-']\n",
    "    offsets = [0.5]*len(result_dirs)\n",
    "    offsets[-1]=-0\n",
    "    offsets[-2]=-0\n",
    "\n",
    "    for r in result_dirs:\n",
    "        alllogs = json.load(open(f'{r}/trainer_state.json'))\n",
    "        d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "        x1 = np.array(d1)[:,0]\n",
    "        y1 = np.array(d1)[:,2]\n",
    "        \n",
    "        tmplabel = tflaglabel[tflag] + str(lrs[c])\n",
    "        \n",
    "        line1, = ax.plot(x1, y1, tcolors[tflag], label=tmplabel,markersize=3)\n",
    "        \n",
    "        ax.annotate(lrs[c], xy=(x1[-1], y1[-1]), xytext=(x1[-1]+150, y1[-1]+offsets[c]),\n",
    "            arrowprops=dict(facecolor='black',arrowstyle=\"->\", connectionstyle=\"arc3\"))\n",
    "        \n",
    "        if c==len(result_dirs)-1:\n",
    "            plt.text(1100, 5.8, 'Learning \\nRate')\n",
    "                  \n",
    "        tflag*=-1\n",
    "        c+=1\n",
    "\n",
    "    # plt.legend()\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "755fc0b5-b57a-4ccb-9392-037159b9455d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d75e8dc5-6d12-4db2-af14-c6dd3a813869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_dirs_42' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-647cfae13bfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dirs_42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Seed 1 (Loss)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'result_dirs_42' is not defined"
     ]
    }
   ],
   "source": [
    "plot_seed(result_dirs_42, 'Seed 1 (Loss)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "c24659a5-66e0-41de-aeea-43898e7d6ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_seed(result_dirs_20, 'Seed 2 (Loss)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "ea6ce877-3492-4b46-a2d3-74d4bc6b39d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_seed(result_dirs_32, 'Seed 3 (Loss)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b48dfa-8d33-4963-87b9-37a27070558f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0dc0206d-2be0-4ed8-8b61-f5e3f9a330bf",
   "metadata": {},
   "source": [
    "# Skipping LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "298cee92-dd1f-4ea3-8abe-7558c21ffbde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation import run_translation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db1afa2d-e210-4360-99f9-ed9cbcf3a78f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_translation_func_c(lr, seed:int, critical_step:int, start_LR:float, end_LR:float):\n",
    "\n",
    "    tmp_dir = get_auto_remove_tmp_dir()\n",
    "    testargs = f\"\"\"\n",
    "        run_translation.py\n",
    "        --model_name_or_path google/long-t5-tglobal-base\n",
    "        --source_lang en\n",
    "        --target_lang fr\n",
    "        --dataset_name news_commentary\n",
    "        --dataset_config_name en-fr\n",
    "        --output_dir {tmp_dir}\n",
    "        --overwrite_output_dir\n",
    "        --max_steps=1000\n",
    "        --warmup_steps=0\n",
    "        --do_train\n",
    "        --learning_rate={lr}\n",
    "        --per_device_train_batch_size=4\n",
    "        --per_device_eval_batch_size=4\n",
    "        --predict_with_generate\n",
    "        --save_strategy no\n",
    "        --logging_steps 10\n",
    "        --lr_scheduler_type constant_with_step\n",
    "        --factor {end_LR/start_LR}\n",
    "        --critical_step {critical_step}\n",
    "        --seed {seed}\n",
    "    \"\"\".split()\n",
    "    \n",
    "    print(testargs)\n",
    "\n",
    "    with patch.object(sys, \"argv\", testargs):\n",
    "        run_translation.main()\n",
    "        result = get_results(tmp_dir)\n",
    "        # print(result[\"eval_bleu\"]>30)\n",
    "    \n",
    "    return tmp_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b90a2a7-e576-47e0-aba5-e9f6086fc675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiments = [(2000,1e-6,1e-6),\n",
    "              (2000, 1e-3, 1e-3),\n",
    "              (100,1e-6, 1e-3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7b7b40b-88d7-46b9-bce6-c9e56accb0d9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|training_args.py:1511] 2023-03-22 03:28:25,381 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-22 03:28:25,382 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run_translation.py', '--model_name_or_path', 'google/long-t5-tglobal-base', '--source_lang', 'en', '--target_lang', 'fr', '--dataset_name', 'news_commentary', '--dataset_config_name', 'en-fr', '--output_dir', '/tmp/tmphdw_n_iq', '--overwrite_output_dir', '--max_steps=1000', '--warmup_steps=0', '--do_train', '--learning_rate=1e-06', '--per_device_train_batch_size=4', '--per_device_eval_batch_size=4', '--predict_with_generate', '--save_strategy', 'no', '--logging_steps', '10', '--lr_scheduler_type', 'constant_with_step', '--factor', '1.0', '--critical_step', '2000', '--seed', '42']\n",
      "03/22/2023 03:28:25 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/22/2023 03:28:25 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=2000.0,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=1.0,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmphdw_n_iq/runs/Mar22_03-28-25_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_step,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmphdw_n_iq,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmphdw_n_iq,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/22/2023 03:28:25 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/22/2023 03:28:25 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/22/2023 03:28:25 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/22/2023 03:28:25 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/22/2023 03:28:25 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f210acfa4245f794005e0aeab6adcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-22 03:28:25,836 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:28:25,839 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-22 03:28:25,960 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-22 03:28:26,013 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:28:26,015 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:28:26,085 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:28:26,086 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:28:26,086 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:28:26,087 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:28:26,087 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-22 03:28:26,091 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:28:26,092 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-22 03:28:26,145 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-22 03:28:26,307 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-22 03:28:28,424 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-22 03:28:28,425 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-22 03:28:28,465 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-22 03:28:28,466 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/22/2023 03:28:28 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-22 03:28:28,685 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "/root/transformers/src/transformers/optimization.py:460: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "[INFO|trainer.py:1758] 2023-03-22 03:28:28,705 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-22 03:28:28,706 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1760] 2023-03-22 03:28:28,706 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-22 03:28:28,707 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1762] 2023-03-22 03:28:28,707 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1763] 2023-03-22 03:28:28,708 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-22 03:28:28,708 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-22 03:28:28,710 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-22 03:28:28,724 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/root/transformers/src/transformers/modeling_utils.py:785: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  \"The `device` argument is deprecated and will be removed in v5 of Transformers.\", FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting constant with step scheduler: 2000.0 1.0\n",
      "Constant step settings: factor=1.0 critical_step=2000.0\n",
      "1.0 2000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.596900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.656200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>5.562800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.116000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>5.325200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>5.424400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>5.175300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>5.466400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.508200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>5.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>5.216100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>5.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>5.077100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.174100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>5.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>5.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>5.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>5.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.163000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>5.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.960500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>5.163700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.918800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>5.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.955200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>5.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>5.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>5.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>5.132300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>4.742100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>5.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.875300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>4.795600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>5.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>5.071100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>5.180400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.770100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>4.757800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>4.971600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>4.746300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>5.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.920100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>5.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>4.863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>4.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>4.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.900900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>4.668000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>4.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>4.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>4.859500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.798400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>5.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>4.730200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>4.779100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>4.729500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.033900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>4.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>4.665300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>4.889800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>4.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.731900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>4.837600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>4.832600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>4.734500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>4.737200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.683100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>4.704300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>4.596800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>4.848000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>4.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>4.592500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>4.611600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>4.781300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>4.613900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.693400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>4.545500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>4.783300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>4.733100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>4.644200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.622000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>4.479200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>4.609800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>4.512400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>4.527400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.699200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-22 03:31:26,325 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-22 03:31:26,368 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1511] 2023-03-22 03:31:26,400 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-22 03:31:26,400 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     4.9908\n",
      "  train_runtime            = 0:02:57.61\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.521\n",
      "  train_steps_per_second   =       5.63\n",
      "['run_translation.py', '--model_name_or_path', 'google/long-t5-tglobal-base', '--source_lang', 'en', '--target_lang', 'fr', '--dataset_name', 'news_commentary', '--dataset_config_name', 'en-fr', '--output_dir', '/tmp/tmp5yfal9u5', '--overwrite_output_dir', '--max_steps=1000', '--warmup_steps=0', '--do_train', '--learning_rate=0.001', '--per_device_train_batch_size=4', '--per_device_eval_batch_size=4', '--predict_with_generate', '--save_strategy', 'no', '--logging_steps', '10', '--lr_scheduler_type', 'constant_with_step', '--factor', '1.0', '--critical_step', '2000', '--seed', '42']\n",
      "03/22/2023 03:31:26 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/22/2023 03:31:26 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=2000.0,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=1.0,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmp5yfal9u5/runs/Mar22_03-31-26_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_step,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmp5yfal9u5,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmp5yfal9u5,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/22/2023 03:31:26 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/22/2023 03:31:26 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/22/2023 03:31:26 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/22/2023 03:31:26 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/22/2023 03:31:26 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d396feba61444369ba0f9a5dc30c2281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-22 03:31:26,838 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:31:26,840 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-22 03:31:26,868 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-22 03:31:26,895 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:31:26,897 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:31:26,972 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:31:26,973 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:31:26,973 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:31:26,974 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:31:26,975 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-22 03:31:26,978 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:31:26,979 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-22 03:31:27,033 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-22 03:31:27,195 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-22 03:31:29,304 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-22 03:31:29,305 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-22 03:31:29,343 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-22 03:31:29,344 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/22/2023 03:31:29 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-22 03:31:29,561 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-03-22 03:31:29,580 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-22 03:31:29,581 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1760] 2023-03-22 03:31:29,582 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-22 03:31:29,582 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1762] 2023-03-22 03:31:29,583 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1763] 2023-03-22 03:31:29,583 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-22 03:31:29,584 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-22 03:31:29,585 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-22 03:31:29,601 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting constant with step scheduler: 2000.0 1.0\n",
      "Constant step settings: factor=1.0 critical_step=2000.0\n",
      "1.0 2000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 03:00, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>4.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.930100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>3.831500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>3.749200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>3.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>3.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>3.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.396100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>3.480500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.372400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>3.378600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>3.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.436200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.220400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.329500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.208200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.248500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.209600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.264200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.113100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.765400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.964600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>2.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.975200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>2.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>2.901700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.990900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>2.776200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.685300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.862600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>2.963700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.887700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>2.922500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.106100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.837000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.624900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.844900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>2.857600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>2.963600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.891000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.572600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.862700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.561300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.658700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.756900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.805400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.419000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.742300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.672900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.817100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.745400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.551300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.574500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.603200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.657900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.606300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.686200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.508400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.635800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.756200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.532800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.513300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.641900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.576800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.531000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.336900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.646800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.665700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.578500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.459100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.414400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.461900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.506900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.433600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.478200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.397200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.556900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.314900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-22 03:34:30,464 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-22 03:34:30,508 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n",
      "[INFO|training_args.py:1511] 2023-03-22 03:34:30,540 >> PyTorch: setting up devices\n",
      "[INFO|training_args.py:1292] 2023-03-22 03:34:30,540 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     2.8765\n",
      "  train_runtime            = 0:03:00.87\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.114\n",
      "  train_steps_per_second   =      5.529\n",
      "['run_translation.py', '--model_name_or_path', 'google/long-t5-tglobal-base', '--source_lang', 'en', '--target_lang', 'fr', '--dataset_name', 'news_commentary', '--dataset_config_name', 'en-fr', '--output_dir', '/tmp/tmpt5hta5ng', '--overwrite_output_dir', '--max_steps=1000', '--warmup_steps=0', '--do_train', '--learning_rate=1e-06', '--per_device_train_batch_size=4', '--per_device_eval_batch_size=4', '--predict_with_generate', '--save_strategy', 'no', '--logging_steps', '10', '--lr_scheduler_type', 'constant_with_step', '--factor', '1000.0000000000001', '--critical_step', '100', '--seed', '42']\n",
      "03/22/2023 03:34:30 - WARNING - translation.run_translation - Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
      "03/22/2023 03:34:30 - INFO - translation.run_translation - Training/evaluation parameters Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "critical_step=100.0,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=False,\n",
      "do_train=True,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "factor=1000.0000000000001,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=1e-06,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/tmp/tmpt5hta5ng/runs/Mar22_03-34-30_datascience-1-0-ml-g5-16xlarge-88bed6742e077c889d617cb2c9e3,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=10,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=constant_with_step,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=1000,\n",
      "metric_for_best_model=None,\n",
      "min_lr=0.001,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=/tmp/tmpt5hta5ng,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "patience=10,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "predict_with_generate=True,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tmp/tmpt5hta5ng,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=no,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "smooth=False,\n",
      "sortish_sampler=False,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "03/22/2023 03:34:30 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/news_commentary/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/22/2023 03:34:30 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "03/22/2023 03:34:30 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n",
      "03/22/2023 03:34:30 - WARNING - datasets.builder - Found cached dataset news_commentary (/root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4)\n",
      "03/22/2023 03:34:30 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44f0d1ed69047ecb5b395fa63a58942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:668] 2023-03-22 03:34:31,002 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:34:31,004 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:478] 2023-03-22 03:34:31,035 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:668] 2023-03-22 03:34:31,058 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:34:31,060 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:34:31,123 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/spiece.model\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:34:31,123 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:34:31,124 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:34:31,124 >> loading file special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2023-03-22 03:34:31,125 >> loading file tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:668] 2023-03-22 03:34:31,128 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/config.json\n",
      "[INFO|configuration_utils.py:720] 2023-03-22 03:34:31,129 >> Model config LongT5Config {\n",
      "  \"_name_or_path\": \"google/long-t5-tglobal-base\",\n",
      "  \"architectures\": [\n",
      "    \"LongT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"encoder_attention_type\": \"transient-global\",\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"global_block_size\": 16,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"local_radius\": 127,\n",
      "  \"model_type\": \"longt5\",\n",
      "  \"n_positions\": 4096,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.27.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2398] 2023-03-22 03:34:31,182 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/pytorch_model.bin\n",
      "[INFO|configuration_utils.py:575] 2023-03-22 03:34:31,341 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:3019] 2023-03-22 03:34:33,439 >> All model checkpoint weights were used when initializing LongT5ForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:3028] 2023-03-22 03:34:33,440 >> All the weights of LongT5ForConditionalGeneration were initialized from the model checkpoint at google/long-t5-tglobal-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LongT5ForConditionalGeneration for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-03-22 03:34:33,476 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--google--long-t5-tglobal-base/snapshots/aecb1376e5bd78db32ebc5c9deb257449b9e2b21/generation_config.json\n",
      "[INFO|configuration_utils.py:575] 2023-03-22 03:34:33,477 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.27.0.dev0\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03/22/2023 03:34:33 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /root/.cache/huggingface/datasets/news_commentary/en-fr/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4/cache-d623078f28b76c49.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:543] 2023-03-22 03:34:33,693 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "[INFO|trainer.py:1758] 2023-03-22 03:34:33,714 >> ***** Running training *****\n",
      "[INFO|trainer.py:1759] 2023-03-22 03:34:33,714 >>   Num examples = 209479\n",
      "[INFO|trainer.py:1760] 2023-03-22 03:34:33,715 >>   Num Epochs = 1\n",
      "[INFO|trainer.py:1761] 2023-03-22 03:34:33,715 >>   Instantaneous batch size per device = 4\n",
      "[INFO|trainer.py:1762] 2023-03-22 03:34:33,716 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "[INFO|trainer.py:1763] 2023-03-22 03:34:33,716 >>   Gradient Accumulation steps = 1\n",
      "[INFO|trainer.py:1764] 2023-03-22 03:34:33,717 >>   Total optimization steps = 1000\n",
      "[INFO|trainer.py:1766] 2023-03-22 03:34:33,720 >>   Number of trainable parameters = 247587456\n",
      "[WARNING|logging.py:280] 2023-03-22 03:34:33,734 >> You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting constant with step scheduler: 100.0 1000.0000000000001\n",
      "Constant step settings: factor=1000.0000000000001 critical_step=100.0\n",
      "1000.0000000000001 100.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 02:57, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>5.946500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>5.596700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.337900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.518900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.487800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.357100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.311900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>4.531500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>4.078300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>3.954900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>3.677100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>3.667600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>3.640900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>3.561400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>3.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>3.453800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.435800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>3.386200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>3.256700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>3.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>3.158300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>3.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>3.216000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>3.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>3.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>3.096000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.151200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>3.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>3.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>3.096700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>3.285200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>3.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>2.820700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>2.983100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>3.144500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>3.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.049000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>3.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>3.191500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>2.897200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>2.900400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>2.686800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>2.895500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>2.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.064200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.805900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>2.721200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>2.991000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>2.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>2.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>2.959200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>2.648000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>2.852900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>2.711400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>2.808200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.852400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>2.508000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>2.799700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>2.782700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>2.914500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>2.819700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>2.627900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>2.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>2.699600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>2.721100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.655300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>2.624100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>2.697100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>2.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>2.646100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>2.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>2.631800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>2.524200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>2.832500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>2.709200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.607400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>2.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>2.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>2.731800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>2.746400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>2.602800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>2.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>2.528900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>2.679600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>2.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.795300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>2.432600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>2.596100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>2.491500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>2.462800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>2.621400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>2.472100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>2.380700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>2.603400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.404000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:2032] 2023-03-22 03:37:31,399 >> \n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "[INFO|modelcard.py:449] 2023-03-22 03:37:31,450 >> Dropping the following result as it does not have all the necessary fields:\n",
      "{'task': {'name': 'Translation', 'type': 'translation'}, 'dataset': {'name': 'news_commentary en-fr', 'type': 'news_commentary', 'config': 'en-fr', 'split': 'train', 'args': 'en-fr'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       0.02\n",
      "  total_flos               =   248650GF\n",
      "  train_loss               =     3.1729\n",
      "  train_runtime            = 0:02:57.67\n",
      "  train_samples            =     209479\n",
      "  train_samples_per_second =     22.513\n",
      "  train_steps_per_second   =      5.628\n"
     ]
    }
   ],
   "source": [
    "result_dirs_42 = []\n",
    "for exp in experiments:\n",
    "    result_dirs_42.append(run_translation_func_c(lr=exp[1],seed=42,critical_step=exp[0],start_LR=exp[1],end_LR=exp[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ab702e2-2278-4d78-8418-34105551d58b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_exps(result_dirs, name):\n",
    "    fig = plt.figure()\n",
    "    fig.set_figheight(4)\n",
    "    ax = fig.add_subplot(111)\n",
    "    c=0\n",
    "    tflag=1\n",
    "    tflaglabel=[' ','run-1 ','run-2 ']\n",
    "    tcolors=['r-','g-','b-']\n",
    "    offsets = [0, 0.25, 1]\n",
    "\n",
    "    for r in result_dirs:\n",
    "        alllogs = json.load(open(f'{r}/trainer_state.json'))\n",
    "        d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "        x1 = np.array(d1)[:,0]\n",
    "        y1 = np.array(d1)[:,2]\n",
    "        \n",
    "        if experiments[c][1]==experiments[c][2]:\n",
    "            tmplabel = str(experiments[c][1])\n",
    "        else:\n",
    "            tmplabel = f\"{experiments[c][1]} -to- {experiments[c][2]}\"\n",
    "        \n",
    "        line1, = ax.plot(x1, y1, tcolors[c], label=tmplabel,markersize=3)\n",
    "        \n",
    "        ax.annotate(tmplabel, xy=(x1[-1], y1[-1]), xytext=(x1[-1]+120, y1[-1]+offsets[c]),\n",
    "            arrowprops=dict(facecolor='black',arrowstyle=\"->\", connectionstyle=\"arc3\"))\n",
    "        \n",
    "        \n",
    "        \n",
    "        if c==len(result_dirs)-1:\n",
    "            plt.text(1100, 5.8, 'Learning \\nRate')\n",
    "                  \n",
    "        tflag*=-1\n",
    "        c+=1\n",
    "\n",
    "    # plt.legend()\n",
    "    plt.title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b46416fb-82dc-48dd-9500-0ade50fab851",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_exps(result_dirs_42, 'Skip LR experiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb517c40-59f4-4bba-b9b8-0cdc85b05df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{result_dirs_42[0]}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "alllogs = json.load(open(f'{result_dirs_42[1]}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "alllogs = json.load(open(f'{result_dirs_42[2]}/trainer_state.json'))\n",
    "d3 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7630957e-8159-42bf-acc5-1eeb5e00d586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LRs')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x2 = np.array(d1)[:,0] \n",
    "y2 = np.array(d1)[:,1]\n",
    "line1, = ax.plot(x2, y2, 'r-', label='Run 1')\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "line1, = ax.plot(x2, y2, 'g-', label='Run 2')\n",
    "\n",
    "x2 = np.array(d3)[:,0] \n",
    "y2 = np.array(d3)[:,1]\n",
    "line1, = ax.plot(x2, y2, 'b-', label='Run 3')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9331de0d-012b-40c4-ba8d-1b0021608841",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08909999999999973"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2[-1][-1] - d3[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc4b86-2f98-4095-9304-31a025a609c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
