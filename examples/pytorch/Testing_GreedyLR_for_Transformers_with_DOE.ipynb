{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109ba453-d065-4aa3-ab70-a054b49a28d0",
   "metadata": {},
   "source": [
    "# Testing â­ GreedLR Scheduler for ðŸ¤— Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4542c5-c0fa-44fb-bcfc-9552c2a7c3d4",
   "metadata": {},
   "source": [
    "## 0. Design of Experiments Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2e215f-5b09-4b4e-9979-faef46387bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461fb42-4c25-4641-a32f-83564f030217",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70989bbb-9b5f-4ba4-a175-f710c052492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    'seed': ['42'],\n",
    "    'do_train': ['True'],\n",
    "    'save_strategy': ['no'],\n",
    "    'logging_steps': ['10']\n",
    "}\n",
    "\n",
    "\n",
    "variable_params = {\n",
    "    'model_name_or_path': ['bigscience/bloom-560m'],\n",
    "    'dataset_name': ['truthfulqa'],\n",
    "    'max_steps': ['1000'],\n",
    "    'optim': ['adamw'],\n",
    "    'lr_scheduler_type': ['greedylr'],\n",
    "    'per_device_train_batch_size': ['8'],\n",
    "    'rank': ['4'],\n",
    "    \n",
    "}\n",
    "\n",
    "# TODO: Create dictionary to lookup model-specific variable params (e.g. lr, lr_scheduler_type)\n",
    "\n",
    "all_params = {**fixed_params, **variable_params}\n",
    "all_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e1b27-591e-4148-8f8a-309edcb86da0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Define Individual Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c23a7-d784-48d3-89b4-fc40133c753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(parameters):\n",
    "    params = \" \".join([f\"--{k} {v}\" for k, v in parameters.items()])\n",
    "    \n",
    "    # TODO: need to abstract out LoRA rank (and other key PEFT config parameters) as an argument for the experiment\n",
    "    \n",
    "    tmp_dir = get_auto_remove_tmp_dir()\n",
    "    testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    {params}\n",
    "    --output_dir {tmp_dir}\n",
    "    \"\"\".split()\n",
    "    \n",
    "    with patch.object(sys, \"argv\", testargs):\n",
    "        run_qa.main()\n",
    "        result = get_results(tmp_dir)\n",
    "    \n",
    "    all_logs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "    loss_metrics = [ (l['step'], l['learning_rate'], l['loss']) for l in all_logs['log_history'][:-1] ]\n",
    "    \n",
    "    return loss_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da0efb-87e9-49b8-8dd1-163e41a3e2e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Loop across all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d64eb5-e3e5-429c-9baa-96ff8e07dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_results = []\n",
    "print('List of Experiments:')\n",
    "for values in itertools.product(*all_params.values()):\n",
    "    params = dict(zip(all_params.keys(), values))\n",
    "    # TODO Add model-specific parameters to params dict\n",
    "    print(params)\n",
    "    print()\n",
    "    # result = run_experiment(params)\n",
    "    # experiment_results.append((params, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b914b-acf0-48f5-b745-930861dfb814",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4: Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c25989-592e-4e55-93a8-c8ac71ebe806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(experiment_results, columns=['Parameters', 'Results'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0597f30-7aec-496a-8946-863c815749b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./greedyLR_experiment_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8d55d-acf7-4bdf-90da-59eeabba227f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5: Analyze & Graph results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169f1bc-bcfd-4d15-92f1-38b2e7feeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4360d05-6e8a-4951-a611-7b4b345a71b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ff579-2386-4114-b011-92c064f6f2ee",
   "metadata": {},
   "source": [
    "### Need to reinstall from source to register changes\n",
    "\n",
    "(may need to restart kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97b0058d-4f24-43e4-af9d-510a5f02247d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate>=0.12.0 (from -r translation/requirements.txt (line 1))\n",
      "  Obtaining dependency information for accelerate>=0.12.0 from https://files.pythonhosted.org/packages/10/d3/5382aa337d3e67214003a17b06bfc07cf0334356b4e8aaf3b12b0d38c83f/accelerate-0.20.3-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-0.20.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting datasets>=1.8.0 (from -r translation/requirements.txt (line 2))\n",
      "  Obtaining dependency information for datasets>=1.8.0 from https://files.pythonhosted.org/packages/12/17/95e48481a826f85c918e0610257de493164096e29fe16ec408c0b862e057/datasets-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sentencepiece!=0.1.92 (from -r translation/requirements.txt (line 3))\n",
      "  Using cached sentencepiece-0.1.99-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from -r translation/requirements.txt (line 4)) (4.23.4)\n",
      "Collecting sacrebleu>=1.4.12 (from -r translation/requirements.txt (line 5))\n",
      "  Using cached sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "Collecting py7zr (from -r translation/requirements.txt (line 6))\n",
      "  Obtaining dependency information for py7zr from https://files.pythonhosted.org/packages/2c/da/155bb1f692c067b9213c9c7b8c19a012a65027399606d623a25dfb1d3af1/py7zr-0.20.6-py3-none-any.whl.metadata\n",
      "  Downloading py7zr-0.20.6-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting torch>=1.3 (from -r translation/requirements.txt (line 7))\n",
      "  Using cached torch-1.13.1-cp37-cp37m-manylinux1_x86_64.whl (887.5 MB)\n",
      "Collecting evaluate (from -r translation/requirements.txt (line 8))\n",
      "  Using cached evaluate-0.4.0-py3-none-any.whl (81 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (20.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (5.6.7)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from accelerate>=0.12.0->-r translation/requirements.txt (line 1)) (6.0.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (12.0.1)\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets>=1.8.0->-r translation/requirements.txt (line 2))\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.31.0)\n",
      "Collecting tqdm>=4.62.1 (from datasets>=1.8.0->-r translation/requirements.txt (line 2))\n",
      "  Obtaining dependency information for tqdm>=4.62.1 from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets>=1.8.0->-r translation/requirements.txt (line 2))\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/53/d3/01b60fb043086f941b932df1463f9b637c45ecdc846481c331fa31bd7ed1/xxhash-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading xxhash-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.8.5)\n",
      "Collecting huggingface-hub<1.0.0,>=0.11.0 (from datasets>=1.8.0->-r translation/requirements.txt (line 2))\n",
      "  Obtaining dependency information for huggingface-hub<1.0.0,>=0.11.0 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets>=1.8.0->-r translation/requirements.txt (line 2)) (6.7.0)\n",
      "Collecting portalocker (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5))\n",
      "  Using cached portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (2023.6.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (0.4.3)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.7/site-packages (from sacrebleu>=1.4.12->-r translation/requirements.txt (line 5)) (4.9.3)\n",
      "Collecting texttable (from py7zr->-r translation/requirements.txt (line 6))\n",
      "  Using cached texttable-1.6.7-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pycryptodomex>=3.6.6 (from py7zr->-r translation/requirements.txt (line 6))\n",
      "  Obtaining dependency information for pycryptodomex>=3.6.6 from https://files.pythonhosted.org/packages/45/09/ce11344724e674957402b5f3c0d663388f755ecd1c864f0c405b5f959bd8/pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pyzstd>=0.14.4 (from py7zr->-r translation/requirements.txt (line 6))\n",
      "  Obtaining dependency information for pyzstd>=0.14.4 from https://files.pythonhosted.org/packages/87/22/b2d13e1d2d749e6b78afd0968e164d8cbfde55975ce2449bf836ccccd9fe/pyzstd-0.15.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pyzstd-0.15.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting pyppmd<1.1.0,>=0.18.1 (from py7zr->-r translation/requirements.txt (line 6))\n",
      "  Using cached pyppmd-1.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "Collecting pybcj>=0.6.0 (from py7zr->-r translation/requirements.txt (line 6))\n",
      "  Using cached pybcj-1.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
      "Collecting multivolumefile>=0.2.3 (from py7zr->-r translation/requirements.txt (line 6))\n",
      "  Using cached multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Collecting brotli>=1.0.9 (from py7zr->-r translation/requirements.txt (line 6))\n",
      "  Using cached Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357 kB)\n",
      "Collecting inflate64>=0.3.1 (from py7zr->-r translation/requirements.txt (line 6))\n",
      "  Using cached inflate64-0.3.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.3->-r translation/requirements.txt (line 7)) (4.7.1)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch>=1.3->-r translation/requirements.txt (line 7))\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch>=1.3->-r translation/requirements.txt (line 7))\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch>=1.3->-r translation/requirements.txt (line 7))\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch>=1.3->-r translation/requirements.txt (line 7))\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3->-r translation/requirements.txt (line 7)) (65.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.3->-r translation/requirements.txt (line 7)) (0.41.0)\n",
      "Collecting responses<0.19 (from evaluate->-r translation/requirements.txt (line 8))\n",
      "  Using cached responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (0.13.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (3.0.12)\n",
      "Collecting packaging>=20.0 (from accelerate>=0.12.0->-r translation/requirements.txt (line 1))\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2023.7.22)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.2.0)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets>=1.8.0->-r translation/requirements.txt (line 2))\n",
      "  Downloading multiprocess-0.70.14-py37-none-any.whl (115 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.8.0->-r translation/requirements.txt (line 2)) (1.14.0)\n",
      "Using cached accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
      "Using cached datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "Downloading py7zr-0.20.6-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.7/66.7 kB\u001b[0m \u001b[31m911.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pycryptodomex-3.18.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "Using cached pyzstd-0.15.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (410 kB)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m194.6/194.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: texttable, sentencepiece, brotli, xxhash, tqdm, pyzstd, pyppmd, pycryptodomex, portalocker, packaging, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, multivolumefile, dill, sacrebleu, responses, pybcj, nvidia-cudnn-cu11, multiprocess, inflate64, huggingface-hub, torch, py7zr, accelerate, datasets, evaluate\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.42.1\n",
      "    Uninstalling tqdm-4.42.1:\n",
      "      Successfully uninstalled tqdm-4.42.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.1\n",
      "    Uninstalling packaging-20.1:\n",
      "      Successfully uninstalled packaging-20.1\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.7\n",
      "    Uninstalling dill-0.3.7:\n",
      "      Successfully uninstalled dill-0.3.7\n",
      "  Attempting uninstall: multiprocess\n",
      "    Found existing installation: multiprocess 0.70.15\n",
      "    Uninstalling multiprocess-0.70.15:\n",
      "      Successfully uninstalled multiprocess-0.70.15\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\n",
      "pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\n",
      "spyder 4.0.1 requires pyqt5<5.13; python_version >= \"3\", which is not installed.\n",
      "spyder 4.0.1 requires pyqtwebengine<5.13; python_version >= \"3\", which is not installed.\n",
      "notebook 6.5.5 requires pyzmq<25,>=17, but you have pyzmq 25.1.0 which is incompatible.\n",
      "pathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.6 which is incompatible.\n",
      "pathos 0.3.1 requires multiprocess>=0.70.15, but you have multiprocess 0.70.14 which is incompatible.\n",
      "sparkmagic 0.20.4 requires nest-asyncio==1.5.5, but you have nest-asyncio 1.5.7 which is incompatible.\n",
      "spyder 4.0.1 requires jedi==0.14.1, but you have jedi 0.18.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.20.3 brotli-1.0.9 datasets-2.13.1 dill-0.3.6 evaluate-0.4.0 huggingface-hub-0.16.4 inflate64-0.3.1 multiprocess-0.70.14 multivolumefile-0.2.3 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 packaging-23.1 portalocker-2.7.0 py7zr-0.20.6 pybcj-1.0.1 pycryptodomex-3.18.0 pyppmd-1.0.0 pyzstd-0.15.9 responses-0.18.0 sacrebleu-2.3.1 sentencepiece-0.1.99 texttable-1.6.7 torch-1.13.1 tqdm-4.66.1 xxhash-3.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Obtaining file:///root/greedylr/transformers\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.27.0.dev1)\n",
      "  Using cached tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (4.66.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.27.0.dev1) (6.7.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev1) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers==4.27.0.dev1) (4.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.27.0.dev1) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.27.0.dev1) (2023.7.22)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building editable for transformers (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-4.27.0.dev1-0.editable-py3-none-any.whl size=34559 sha256=fb990019a7dee965fdd668212b31f4607698d879559af31e121d5da28f2d302d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z0v5lnut/wheels/84/7f/15/ad855ae7ed1dcc0871f5cf718971541ee74815e192adf1297c\n",
      "Successfully built transformers\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.27.0.dev1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Obtaining file:///root/greedylr/peft\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from peft==0.4.0.dev0) (1.21.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from peft==0.4.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.7/site-packages (from peft==0.4.0.dev0) (5.6.7)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from peft==0.4.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from peft==0.4.0.dev0) (1.13.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from peft==0.4.0.dev0) (4.27.0.dev1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.7/site-packages (from peft==0.4.0.dev0) (0.20.3)\n",
      "Collecting safetensors (from peft==0.4.0.dev0)\n",
      "  Obtaining dependency information for safetensors from https://files.pythonhosted.org/packages/a2/04/e55780fcb9e1a1e4bf22b881146087d9b13f60b9ab1a30c773dd398d5f65/safetensors-0.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.7/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.7/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.7/site-packages (from torch>=1.13.0->peft==0.4.0.dev0) (11.7.99)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.4.0.dev0) (65.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.13.0->peft==0.4.0.dev0) (0.41.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->peft==0.4.0.dev0) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.7/site-packages (from transformers->peft==0.4.0.dev0) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->peft==0.4.0.dev0) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers->peft==0.4.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers->peft==0.4.0.dev0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers->peft==0.4.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers->peft==0.4.0.dev0) (6.7.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers->peft==0.4.0.dev0) (2023.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers->peft==0.4.0.dev0) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->peft==0.4.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->peft==0.4.0.dev0) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->peft==0.4.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->peft==0.4.0.dev0) (2023.7.22)\n",
      "Downloading safetensors-0.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: peft\n",
      "  Building editable for peft (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peft: filename=peft-0.4.0.dev0-0.editable-py3-none-any.whl size=12339 sha256=f3712b4a0dca4a3d5e3831d99d28e944248707b205ff0b96624502c8be55d986\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-rit5xmfa/wheels/b7/88/e1/54712dce34e164c6100c42f4dc1f99deb3403e904b54fbfa08\n",
      "Successfully built peft\n",
      "\u001b[33mDEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: safetensors, peft\n",
      "Successfully installed peft-0.4.0.dev0 safetensors-0.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r translation/requirements.txt\n",
    "%pip install -e ~/greedylr/transformers/ #Or wherever you downloaded this source \n",
    "%pip install -e ~/greedylr/peft/ #Or wherever you downloaded this source "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea6e78-81cf-414a-a3d4-0a25fe776125",
   "metadata": {},
   "source": [
    "Add test folders to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b2dee55-2640-4b77-a261-b81d634e8530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "SRC_DIRS = [\n",
    "    os.path.join('./', dirname) for dirname in [\n",
    "        \"text-generation\",\n",
    "        \"text-classification\",\n",
    "        \"token-classification\",\n",
    "        \"language-modeling\",\n",
    "        \"multiple-choice\",\n",
    "        \"question-answering\",\n",
    "        \"summarization\",\n",
    "        \"translation\",\n",
    "        \"image-classification\",\n",
    "        \"speech-recognition\",\n",
    "        \"audio-classification\",\n",
    "        \"speech-pretraining\",\n",
    "        \"image-pretraining\",\n",
    "        \"semantic-segmentation\",\n",
    "    ]\n",
    "]\n",
    "sys.path.extend(SRC_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c394a69-2fa5-4b3a-928b-ea8c8d7e5bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation import run_translation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import * \n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b803785-a826-44cc-808f-ae4e7c53ab73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a8cb0-9242-4b31-a495-3a68de2dde60",
   "metadata": {},
   "source": [
    "### Default AdamW_HF with LambdaLR (linear, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193adaa-5083-48cb-993e-2c753f4f447a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path bigscience/mt0-small\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name opus100\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca578d-b857-4b0f-9973-77ca99913e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7667a-875f-410b-89a7-8c9207fcc745",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With GreedyLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b9170-1e41-441c-b2d1-e6799ab74db0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path bigscience/mt0-small\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name opus100\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca37c9e-a80a-40e8-982f-319a088edad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d4f6b-5eda-4e06-89c4-1d608d2e886e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696dc61a-178f-4213-98c9-130d03d5b38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafae40a-f887-47ab-8f5e-1948128b8d72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-',label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-',label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c195ead-5cf7-46ac-899b-02bf7b4c75ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098f795-a6d1-42f7-9dc8-bc8ea4562be5",
   "metadata": {},
   "source": [
    "### With GreedyLR + PEFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d11716-41cf-4880-92df-37cc126c3cf1",
   "metadata": {},
   "source": [
    "Notes\n",
    "- bigscience/mt0-large: runs into OOM error (TBD: is this unusual for a g5.16x instance?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce876a6e-b2b1-44c7-9f22-7739d6aa61cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "# from sagemaker.remote_function import remote\n",
    "# @remote(instance_type=\"ml.m5.2xlarge\", dependencies='./translation/requirements.txt')\n",
    "# def divide(x, y):\n",
    "#     return x / y\n",
    "\n",
    "# divide(2, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c025cc53-8617-4faa-879a-5e0223d5bd1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from peft import get_peft_config, get_peft_model, LoraConfig, TaskType\n",
    "# TODO: submit lora_config parameters as arguments to Hf Trainer\n",
    "\n",
    "# lora_config = LoraConfig(\n",
    "#         task_type=TaskType.SEQ_2_SEQ_LM, \n",
    "#         inference_mode=False, \n",
    "#         r=8, \n",
    "#         lora_alpha=32, \n",
    "#         lora_dropout=0.1\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055d25d-61cd-45b3-b63e-2bb2cbe22aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path bigscience/mt0-small\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name opus100\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ab680-fd85-46cc-9ef6-8f81deb76f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "# d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115a290-e232-48ff-9d07-25258114d98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba47ad-c989-41c3-9361-2693c7704f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f28f81-276f-4e43-a8a4-33b2bcd06bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline + PEFT')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR + PEFT')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25ad45-c6b8-4091-b93d-a5206990710e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-',label='baseline + PEFT')\n",
    "line2, = ax.plot(x2, y2, 'r-',label='GreedyLR + PEFT')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01f00a-27ca-42bf-a99c-fe7464535971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c77c7e-75eb-4946-8fa9-1665c89e96ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de744-e910-4bd1-86f8-b4e388d58a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_qa as run_squad\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e736f06-d6e3-46af-a6e4-317ff5623090",
   "metadata": {},
   "source": [
    "### Default ADAMHF / Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8317c07-cd7b-4130-a7ca-af5448577575",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    --model_name_or_path xlm-roberta-base\n",
    "    --dataset_name squad\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=2\n",
    "    --per_device_eval_batch_size=1\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "    # --lr_scheduler_type cosine_with_restarts\n",
    "    # --optim adafactor\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_squad.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5ed56-53bc-47fc-b58e-933d60d304ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b40af-44d6-44fb-9880-338c3b01ac17",
   "metadata": {},
   "source": [
    "### Greedy LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fabf8-33f9-497a-a361-2597cd1b5de4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    --model_name_or_path xlm-roberta-base\n",
    "    --dataset_name squad\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --per_device_eval_batch_size=2\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_squad.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c2f59-2765-4f74-9860-d616bab549c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641246a-0668-4fcd-a298-1f9eb9f68ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6e45a-246d-4aa5-83e0-f508cf5536ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55deca4e-7319-4529-a03d-c27624fe977f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de0731-21f6-4e6a-9cf4-5594cd7b00db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae73ed-7336-4eb2-bed2-3ffe8e522976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b274bc4-e96e-4e39-82ab-1f0eadecbe20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_image_classification\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22a59a-5a94-4488-bd6e-f2e8e7b7062a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_image_classification.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path google/vit-base-patch16-224\n",
    "    --dataset_name Maysee/tiny-imagenet\n",
    "    --do_train\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 64\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --metric_for_best_model accuracy\n",
    "    --max_steps 1000\n",
    "    --train_val_split 0.2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --ignore_mismatched_sizes True\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_image_classification.main()\n",
    "    result = get_results(tmp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6856c7-3c94-4d27-823b-16e9c981d5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a269d-2d96-4e5c-99d9-b91d08622b1f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_image_classification.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path google/vit-base-patch16-224\n",
    "    --dataset_name Maysee/tiny-imagenet\n",
    "    --do_train\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 64\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --metric_for_best_model accuracy\n",
    "    --max_steps 1000\n",
    "    --train_val_split 0.2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --ignore_mismatched_sizes True\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_image_classification.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63602e64-b64d-477b-b5f9-580a93df158b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505dbd11-fa02-46c7-afbb-4009dfcb2db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f3ee3-50c8-4d94-83c4-67e700e5b1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd835ef-3593-4fe7-85c8-8f09302cc9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcba56-8e88-48cd-9386-2b0984ecbf9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8bfe8-edd4-4b51-9349-c4d4c7cf9bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r semantic-segmentation/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344751db-124f-42bb-bcd0-3cc75df01fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_semantic_segmentation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4a94f-2496-4a89-8892-09edc996f069",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_semantic_segmentation.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path nvidia/mit-b0\n",
    "    --dataset_name segments/sidewalk-semantic\n",
    "    --dataset_config mini\n",
    "    --do_train\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --max_steps 1000\n",
    "    --learning_rate=1e-3\n",
    "    --per_device_train_batch_size=2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_semantic_segmentation.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645266d4-aed7-473a-83d3-6b48b4562bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86863b-662e-4ca3-8dc5-d3275eb11540",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_semantic_segmentation.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path nvidia/mit-b0\n",
    "    --dataset_name segments/sidewalk-semantic\n",
    "    --do_train\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --max_steps 1000\n",
    "    --learning_rate=1e-3\n",
    "    --per_device_train_batch_size=4\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_semantic_segmentation.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4007fc-f5f2-40f3-9954-804ce3812da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4186932-ff3f-43b9-86fd-293951cb677b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7461d1-1d45-440b-a654-e439dcf1c108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331de07-cf21-40e3-bc97-3bc147e5656d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dafeeb-7e9b-49c2-9c3a-6dc03db10093",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af4175-63f1-47e7-aa37-ae71aec292c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --use-deprecated=legacy-resolver rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20f913-05cc-474b-8886-a2d6a5d5dcf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip --no-cache-dir install -r summarization/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2b1a0-b4a7-462d-adb5-6076675eec6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install absl-py nltk numpy six>=1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbb974-af08-41f2-8718-6bc5983c07f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip==21.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b41854-4f84-4557-a72e-fb2a3ab1f0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-cache-dir rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a9769-eec2-4f73-8e61-7447ef7c4ea6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_summarization\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c263c4-2bc0-496c-ba1e-c5bcbef474be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_summarization.py\n",
    "    --model_name_or_path facebook/bart-base\n",
    "    --dataset_name amazon_reviews_multi\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=8\n",
    "    --predict_with_generate\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --fp16 true\n",
    "    --optim adagrad\n",
    "    --lr_scheduler_type polynomial\n",
    "\"\"\".split()\n",
    "\n",
    "testargs.append('--source_prefix')\n",
    "testargs.append(\"summarize: \")\n",
    "\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_summarization.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e007896-d24b-4fcc-a585-b84ad272bb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3daf4e3-e9f3-4f15-89de-32d6eebfe7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %store -r d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1968bf-c8b0-48e3-8cdf-510d13852d78",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_summarization.py\n",
    "    --model_name_or_path facebook/bart-base\n",
    "    --dataset_name amazon_reviews_multi\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=8\n",
    "    --predict_with_generate\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --fp16 true\n",
    "    --optim adagrad\n",
    "\"\"\".split()\n",
    "\n",
    "testargs.append('--source_prefix')\n",
    "testargs.append(\"summarize: \")\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_summarization.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d516204-cac8-4bdd-a0dd-fdcc7a4350c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e284eb8-79ef-4b6e-987a-48cdcc4d9f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f5dc8-44e1-4255-825c-f9c2650843e4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5453585-e436-40b4-b42d-d8b35f816e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_figheight(4)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d308c02-f959-49e3-8029-50ba050fd3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f284a-2457-4a23-938d-24d584e46bd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172ddfa-22b7-4424-b931-25c1fe38aa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_wav2vec2_pretraining_no_trainer\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7c8e0-692f-4cd1-8420-744d7d9a5756",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r speech-pretraining/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e45a3-da26-48a4-9623-2abd6bcb99f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_wav2vec2_pretraining_no_trainer.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path hf-internal-testing/tiny-random-wav2vec2\n",
    "    --dataset_name librispeech_asr\n",
    "    --dataset_config_names clean\n",
    "    --dataset_split_names validation\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 4\n",
    "    --per_device_eval_batch_size 4\n",
    "    --preprocessing_num_workers 16\n",
    "    --max_train_steps 2\n",
    "    --validation_split_percentage 5\n",
    "    --seed 42\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_wav2vec2_pretraining_no_trainer.main()\n",
    "    model = Wav2Vec2ForPreTraining.from_pretrained(tmp_dir)\n",
    "    self.assertIsNotNone(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396d71f-11fb-491b-98e3-4900184830bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c0a34-9136-4218-b4a5-3703ae93ce15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_ner\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a28beb-ea88-4d61-9f8c-16c91b2b3ead",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -r token-classification/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b5fb1-13da-43ba-89dc-99b594551d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a645e9-48cc-4da9-b59f-e8f3d8ea03eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_ner.py\n",
    "    --model_name_or_path camembert/camembert-large\n",
    "    --dataset_name xglue\n",
    "    --dataset_config ner\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --do_train\n",
    "    --max_steps=1000\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=16\n",
    "    --save_strategy no\n",
    "    --seed 42\n",
    "    --logging_steps 10\n",
    "    --fp16 true\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "#     --lr_scheduler_type greedy\n",
    "#     --logging_steps 10\n",
    "#     --min_lr=1e-5\n",
    "#     --smooth True\n",
    "#     --patience 10\n",
    "#     --factor 0.95\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_ner.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    \n",
    "    \n",
    "    # --optim: invalid choice: 'as' (choose from 'adamw_hf', 'adamw_torch', 'adamw_torch_xla', 'adamw_apex_fused', 'adafactor', 'adamw_bnb_8bit', 'adamw_anyprecision', 'sgd', 'adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fc7c6-da67-4367-9820-370063359ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad74ccd-b3d8-4d3e-9468-12472ca06f4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_ner.py\n",
    "    --model_name_or_path camembert/camembert-large\n",
    "    --dataset_name xglue\n",
    "    --dataset_config ner\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --do_train\n",
    "    --max_steps=1000\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=16\n",
    "    --save_strategy no\n",
    "    --seed 42\n",
    "    --logging_steps 10\n",
    "    --fp16 true\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --fp16 True\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_ner.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff33a14-c3bf-4e9d-b2a1-b06e9082151d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b17c0-a916-4fe5-aca3-d7941246655a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081d889-fe76-4eb1-9929-2516536573e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_figheight(4)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb029095-b388-4802-b5d4-43fa1a787665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(d1[-1][int(0.1*len(d1[-1]))-1] > d2[-1][int(0.1*len(d2[-1]))-1])\n",
    "# print(d1[-1][int(0.5*len(d1[-1]))-1] > d2[-1][int(0.5*len(d2[-1]))-1])\n",
    "# print(d1[-1][int(1*len(d1[-1]))-1] > d2[-1][int(1*len(d2[-1]))-1])\n",
    "\n",
    "\n",
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df4887-3e62-44aa-9e86-20effde50418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "SRC_DIRS = [\n",
    "    os.path.join('./', dirname) for dirname in [\n",
    "        \"text-generation\",\n",
    "        \"text-classification\",\n",
    "        \"token-classification\",\n",
    "        \"language-modeling\",\n",
    "        \"multiple-choice\",\n",
    "        \"question-answering\",\n",
    "        \"summarization\",\n",
    "        \"translation\",\n",
    "        \"image-classification\",\n",
    "        \"speech-recognition\",\n",
    "        \"audio-classification\",\n",
    "        \"speech-pretraining\",\n",
    "        \"image-pretraining\",\n",
    "        \"semantic-segmentation\",\n",
    "    ]\n",
    "]\n",
    "sys.path.extend(SRC_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5bd42-3a1e-4492-a885-94c16bea8176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22c63d-c80d-42fd-941a-f3cce42bd534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
