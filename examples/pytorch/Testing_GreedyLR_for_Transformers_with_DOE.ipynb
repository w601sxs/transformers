{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109ba453-d065-4aa3-ab70-a054b49a28d0",
   "metadata": {},
   "source": [
    "# Testing ⏭ GreedLR Scheduler for 🤗 Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4542c5-c0fa-44fb-bcfc-9552c2a7c3d4",
   "metadata": {},
   "source": [
    "## 0. Design of Experiments Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e215f-5b09-4b4e-9979-faef46387bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4461fb42-4c25-4641-a32f-83564f030217",
   "metadata": {},
   "source": [
    "### Step 1: Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70989bbb-9b5f-4ba4-a175-f710c052492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_params = {\n",
    "    'seed': ['42'],\n",
    "    'do_train': ['True'],\n",
    "    'save_strategy': ['no'],\n",
    "    'logging_steps': ['10']\n",
    "}\n",
    "\n",
    "\n",
    "variable_params = {\n",
    "    'model_name_or_path': ['bigscience/bloom-560m'],\n",
    "    'dataset_name': ['truthfulqa'],\n",
    "    'max_steps': ['1000'],\n",
    "    'optim': ['adamw'],\n",
    "    'lr_scheduler_type': ['greedylr'],\n",
    "    'per_device_train_batch_size': ['8'],\n",
    "    'rank': ['4'],\n",
    "    \n",
    "}\n",
    "\n",
    "# TODO: Create dictionary to lookup model-specific variable params (e.g. lr, lr_scheduler_type)\n",
    "\n",
    "all_params = {**fixed_params, **variable_params}\n",
    "all_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e1b27-591e-4148-8f8a-309edcb86da0",
   "metadata": {},
   "source": [
    "## Step 2: Define Individual Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c23a7-d784-48d3-89b4-fc40133c753e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(parameters):\n",
    "    params = \" \".join([f\"--{k} {v}\" for k, v in parameters.items()])\n",
    "    \n",
    "    # TODO: need to abstract out LoRA rank (and other key PEFT config parameters) as an argument for the experiment\n",
    "    \n",
    "    tmp_dir = get_auto_remove_tmp_dir()\n",
    "    testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    {params}\n",
    "    --output_dir {tmp_dir}\n",
    "    \"\"\".split()\n",
    "    \n",
    "    with patch.object(sys, \"argv\", testargs):\n",
    "        run_qa.main()\n",
    "        result = get_results(tmp_dir)\n",
    "    \n",
    "    all_logs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "    loss_metrics = [ (l['step'], l['learning_rate'], l['loss']) for l in all_logs['log_history'][:-1] ]\n",
    "    \n",
    "    return loss_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88da0efb-87e9-49b8-8dd1-163e41a3e2e1",
   "metadata": {},
   "source": [
    "## Step 3: Loop across all experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d64eb5-e3e5-429c-9baa-96ff8e07dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_results = []\n",
    "print('List of Experiments:')\n",
    "for values in itertools.product(*all_params.values()):\n",
    "    params = dict(zip(all_params.keys(), values))\n",
    "    # TODO Add model-specific parameters to params dict\n",
    "    print(params)\n",
    "    print()\n",
    "    # result = run_experiment(params)\n",
    "    # experiment_results.append((params, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0b914b-acf0-48f5-b745-930861dfb814",
   "metadata": {},
   "source": [
    "## Step 4: Store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c25989-592e-4e55-93a8-c8ac71ebe806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(experiment_results, columns=['Parameters', 'Results'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0597f30-7aec-496a-8946-863c815749b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('./greedyLR_experiment_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd8d55d-acf7-4bdf-90da-59eeabba227f",
   "metadata": {},
   "source": [
    "## Step 5: Analyze & Graph results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169f1bc-bcfd-4d15-92f1-38b2e7feeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4360d05-6e8a-4951-a611-7b4b345a71b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607ff579-2386-4114-b011-92c064f6f2ee",
   "metadata": {},
   "source": [
    "### Need to reinstall from source to register changes\n",
    "\n",
    "(may need to restart kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0058d-4f24-43e4-af9d-510a5f02247d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r translation/requirements.txt\n",
    "%pip install -e ~/greedylr/transformers/ #Or wherever you downloaded this source \n",
    "%pip install -e ~/greedylr/peft/ #Or wherever you downloaded this source "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea6e78-81cf-414a-a3d4-0a25fe776125",
   "metadata": {},
   "source": [
    "Add test folders to PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2dee55-2640-4b77-a261-b81d634e8530",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "SRC_DIRS = [\n",
    "    os.path.join('./', dirname) for dirname in [\n",
    "        \"text-generation\",\n",
    "        \"text-classification\",\n",
    "        \"token-classification\",\n",
    "        \"language-modeling\",\n",
    "        \"multiple-choice\",\n",
    "        \"question-answering\",\n",
    "        \"summarization\",\n",
    "        \"translation\",\n",
    "        \"image-classification\",\n",
    "        \"speech-recognition\",\n",
    "        \"audio-classification\",\n",
    "        \"speech-pretraining\",\n",
    "        \"image-pretraining\",\n",
    "        \"semantic-segmentation\",\n",
    "    ]\n",
    "]\n",
    "sys.path.extend(SRC_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c394a69-2fa5-4b3a-928b-ea8c8d7e5bf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from translation import run_translation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import * \n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b803785-a826-44cc-808f-ae4e7c53ab73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install sacremoses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16a8cb0-9242-4b31-a495-3a68de2dde60",
   "metadata": {},
   "source": [
    "### Default AdamW_HF with LambdaLR (linear, default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b193adaa-5083-48cb-993e-2c753f4f447a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path bigscience/mt0-small\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name opus100\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ca578d-b857-4b0f-9973-77ca99913e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c7667a-875f-410b-89a7-8c9207fcc745",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With GreedyLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b9170-1e41-441c-b2d1-e6799ab74db0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path bigscience/mt0-small\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name opus100\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca37c9e-a80a-40e8-982f-319a088edad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783d4f6b-5eda-4e06-89c4-1d608d2e886e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696dc61a-178f-4213-98c9-130d03d5b38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafae40a-f887-47ab-8f5e-1948128b8d72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-',label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-',label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c195ead-5cf7-46ac-899b-02bf7b4c75ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098f795-a6d1-42f7-9dc8-bc8ea4562be5",
   "metadata": {},
   "source": [
    "### With GreedyLR + PEFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d11716-41cf-4880-92df-37cc126c3cf1",
   "metadata": {},
   "source": [
    "Notes\n",
    "- bigscience/mt0-large: runs into OOM error (TBD: is this unusual for a g5.16x instance?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f4e2a7-bf6b-40e1-98db-24c125388522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.remote_function import remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce876a6e-b2b1-44c7-9f22-7739d6aa61cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "# @remote(instance_type=\"ml.m5.2xlarge\", dependencies='./translation/requirements.txt')\n",
    "# def divide(x, y):\n",
    "#     return x / y\n",
    "\n",
    "# divide(2, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055d25d-61cd-45b3-b63e-2bb2cbe22aa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_translation.py\n",
    "    --model_name_or_path bigscience/mt0-small\n",
    "    --source_lang de\n",
    "    --target_lang en\n",
    "    --dataset_name opus100\n",
    "    --dataset_config_name de-en\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    \n",
    "    run_translation.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    # print(result[\"eval_bleu\"]>30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ab680-fd85-46cc-9ef6-8f81deb76f56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "# d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2115a290-e232-48ff-9d07-25258114d98a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba47ad-c989-41c3-9361-2693c7704f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f28f81-276f-4e43-a8a4-33b2bcd06bce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline + PEFT')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR + PEFT')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f25ad45-c6b8-4091-b93d-a5206990710e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-',label='baseline + PEFT')\n",
    "line2, = ax.plot(x2, y2, 'r-',label='GreedyLR + PEFT')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01f00a-27ca-42bf-a99c-fe7464535971",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c77c7e-75eb-4946-8fa9-1665c89e96ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2. Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350de744-e910-4bd1-86f8-b4e388d58a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_qa as run_squad\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e736f06-d6e3-46af-a6e4-317ff5623090",
   "metadata": {},
   "source": [
    "### Default ADAMHF / Adafactor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8317c07-cd7b-4130-a7ca-af5448577575",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    --model_name_or_path xlm-roberta-base\n",
    "    --dataset_name squad\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=2\n",
    "    --per_device_eval_batch_size=1\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "    # --lr_scheduler_type cosine_with_restarts\n",
    "    # --optim adafactor\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_squad.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5ed56-53bc-47fc-b58e-933d60d304ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b40af-44d6-44fb-9880-338c3b01ac17",
   "metadata": {},
   "source": [
    "### Greedy LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2fabf8-33f9-497a-a361-2597cd1b5de4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_qa.py\n",
    "    --model_name_or_path xlm-roberta-base\n",
    "    --dataset_name squad\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=5000\n",
    "    --warmup_steps=0\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=4\n",
    "    --per_device_eval_batch_size=2\n",
    "    --lr_scheduler_type greedy\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_squad.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c2f59-2765-4f74-9860-d616bab549c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641246a-0668-4fcd-a298-1f9eb9f68ff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e6e45a-246d-4aa5-83e0-f508cf5536ef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55deca4e-7319-4529-a03d-c27624fe977f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4de0731-21f6-4e6a-9cf4-5594cd7b00db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae73ed-7336-4eb2-bed2-3ffe8e522976",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b274bc4-e96e-4e39-82ab-1f0eadecbe20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_image_classification\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22a59a-5a94-4488-bd6e-f2e8e7b7062a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_image_classification.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path google/vit-base-patch16-224\n",
    "    --dataset_name Maysee/tiny-imagenet\n",
    "    --do_train\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 64\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --metric_for_best_model accuracy\n",
    "    --max_steps 1000\n",
    "    --train_val_split 0.2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --ignore_mismatched_sizes True\n",
    "    --seed 42\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_image_classification.main()\n",
    "    result = get_results(tmp_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6856c7-3c94-4d27-823b-16e9c981d5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a269d-2d96-4e5c-99d9-b91d08622b1f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_image_classification.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path google/vit-base-patch16-224\n",
    "    --dataset_name Maysee/tiny-imagenet\n",
    "    --do_train\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 64\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --metric_for_best_model accuracy\n",
    "    --max_steps 1000\n",
    "    --train_val_split 0.2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --ignore_mismatched_sizes True\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_image_classification.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63602e64-b64d-477b-b5f9-580a93df158b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505dbd11-fa02-46c7-afbb-4009dfcb2db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f3ee3-50c8-4d94-83c4-67e700e5b1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd835ef-3593-4fe7-85c8-8f09302cc9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcba56-8e88-48cd-9386-2b0984ecbf9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8bfe8-edd4-4b51-9349-c4d4c7cf9bab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r semantic-segmentation/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344751db-124f-42bb-bcd0-3cc75df01fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_semantic_segmentation\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4a94f-2496-4a89-8892-09edc996f069",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_semantic_segmentation.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path nvidia/mit-b0\n",
    "    --dataset_name segments/sidewalk-semantic\n",
    "    --dataset_config mini\n",
    "    --do_train\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --max_steps 1000\n",
    "    --learning_rate=1e-3\n",
    "    --per_device_train_batch_size=2\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_semantic_segmentation.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645266d4-aed7-473a-83d3-6b48b4562bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86863b-662e-4ca3-8dc5-d3275eb11540",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_semantic_segmentation.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path nvidia/mit-b0\n",
    "    --dataset_name segments/sidewalk-semantic\n",
    "    --do_train\n",
    "    --remove_unused_columns False\n",
    "    --overwrite_output_dir True\n",
    "    --max_steps 1000\n",
    "    --learning_rate=1e-3\n",
    "    --per_device_train_batch_size=4\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_semantic_segmentation.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4007fc-f5f2-40f3-9954-804ce3812da1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4186932-ff3f-43b9-86fd-293951cb677b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7461d1-1d45-440b-a654-e439dcf1c108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "fig.set_figheight(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5331de07-cf21-40e3-bc97-3bc147e5656d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dafeeb-7e9b-49c2-9c3a-6dc03db10093",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5af4175-63f1-47e7-aa37-ae71aec292c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --use-deprecated=legacy-resolver rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20f913-05cc-474b-8886-a2d6a5d5dcf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip --no-cache-dir install -r summarization/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a2b1a0-b4a7-462d-adb5-6076675eec6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install absl-py nltk numpy six>=1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dbb974-af08-41f2-8718-6bc5983c07f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade pip==21.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b41854-4f84-4557-a72e-fb2a3ab1f0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install --no-cache-dir rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a9769-eec2-4f73-8e61-7447ef7c4ea6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_summarization\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *\n",
    "\n",
    "def get_results(output_dir):\n",
    "    results = {}\n",
    "    path = os.path.join(output_dir, \"all_results.json\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        raise ValueError(f\"can't find {path}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c263c4-2bc0-496c-ba1e-c5bcbef474be",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_summarization.py\n",
    "    --model_name_or_path facebook/bart-base\n",
    "    --dataset_name amazon_reviews_multi\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=8\n",
    "    --predict_with_generate\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --fp16 true\n",
    "    --optim adagrad\n",
    "    --lr_scheduler_type polynomial\n",
    "\"\"\".split()\n",
    "\n",
    "testargs.append('--source_prefix')\n",
    "testargs.append(\"summarize: \")\n",
    "\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_summarization.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e007896-d24b-4fcc-a585-b84ad272bb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3daf4e3-e9f3-4f15-89de-32d6eebfe7a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %store -r d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1968bf-c8b0-48e3-8cdf-510d13852d78",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_summarization.py\n",
    "    --model_name_or_path facebook/bart-base\n",
    "    --dataset_name amazon_reviews_multi\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --max_steps=1000\n",
    "    --do_train\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=8\n",
    "    --predict_with_generate\n",
    "    --save_strategy no\n",
    "    --logging_steps 10\n",
    "    --seed 42\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --fp16 true\n",
    "    --optim adagrad\n",
    "\"\"\".split()\n",
    "\n",
    "testargs.append('--source_prefix')\n",
    "testargs.append(\"summarize: \")\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_summarization.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d516204-cac8-4bdd-a0dd-fdcc7a4350c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e284eb8-79ef-4b6e-987a-48cdcc4d9f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f5dc8-44e1-4255-825c-f9c2650843e4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5453585-e436-40b4-b42d-d8b35f816e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_figheight(4)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d308c02-f959-49e3-8029-50ba050fd3a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d1[-1][-1] - d2[-1][-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0f284a-2457-4a23-938d-24d584e46bd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172ddfa-22b7-4424-b931-25c1fe38aa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_wav2vec2_pretraining_no_trainer\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a7c8e0-692f-4cd1-8420-744d7d9a5756",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -r speech-pretraining/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e45a3-da26-48a4-9623-2abd6bcb99f5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_wav2vec2_pretraining_no_trainer.py\n",
    "    --output_dir {tmp_dir}\n",
    "    --model_name_or_path hf-internal-testing/tiny-random-wav2vec2\n",
    "    --dataset_name librispeech_asr\n",
    "    --dataset_config_names clean\n",
    "    --dataset_split_names validation\n",
    "    --learning_rate 1e-4\n",
    "    --per_device_train_batch_size 4\n",
    "    --per_device_eval_batch_size 4\n",
    "    --preprocessing_num_workers 16\n",
    "    --max_train_steps 2\n",
    "    --validation_split_percentage 5\n",
    "    --seed 42\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_wav2vec2_pretraining_no_trainer.main()\n",
    "    model = Wav2Vec2ForPreTraining.from_pretrained(tmp_dir)\n",
    "    self.assertIsNotNone(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6396d71f-11fb-491b-98e3-4900184830bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c0a34-9136-4218-b4a5-3703ae93ce15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import run_ner\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import ViTMAEForPreTraining, Wav2Vec2ForPreTraining\n",
    "from transformers.testing_utils import CaptureLogger, TestCasePlus, get_gpu_count, slow, torch_device\n",
    "from transformers.utils import is_apex_available\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a28beb-ea88-4d61-9f8c-16c91b2b3ead",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install -r token-classification/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b5fb1-13da-43ba-89dc-99b594551d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a645e9-48cc-4da9-b59f-e8f3d8ea03eb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_ner.py\n",
    "    --model_name_or_path camembert/camembert-large\n",
    "    --dataset_name xglue\n",
    "    --dataset_config ner\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --do_train\n",
    "    --max_steps=1000\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=16\n",
    "    --save_strategy no\n",
    "    --seed 42\n",
    "    --logging_steps 10\n",
    "    --fp16 true\n",
    "    --optim sgd\n",
    "    --lr_scheduler_type constant_with_warmup\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "#     --lr_scheduler_type greedy\n",
    "#     --logging_steps 10\n",
    "#     --min_lr=1e-5\n",
    "#     --smooth True\n",
    "#     --patience 10\n",
    "#     --factor 0.95\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_ner.main()\n",
    "    result = get_results(tmp_dir)\n",
    "    \n",
    "    \n",
    "    # --optim: invalid choice: 'as' (choose from 'adamw_hf', 'adamw_torch', 'adamw_torch_xla', 'adamw_apex_fused', 'adafactor', 'adamw_bnb_8bit', 'adamw_anyprecision', 'sgd', 'adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363fc7c6-da67-4367-9820-370063359ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d1 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "!rm -r pymp*\n",
    "!rm -r ./tmp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad74ccd-b3d8-4d3e-9468-12472ca06f4f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_dir = get_auto_remove_tmp_dir()\n",
    "testargs = f\"\"\"\n",
    "    run_ner.py\n",
    "    --model_name_or_path camembert/camembert-large\n",
    "    --dataset_name xglue\n",
    "    --dataset_config ner\n",
    "    --output_dir {tmp_dir}\n",
    "    --overwrite_output_dir\n",
    "    --do_train\n",
    "    --max_steps=1000\n",
    "    --learning_rate=1e-4\n",
    "    --per_device_train_batch_size=16\n",
    "    --save_strategy no\n",
    "    --seed 42\n",
    "    --logging_steps 10\n",
    "    --fp16 true\n",
    "    --lr_scheduler_type greedy\n",
    "    --logging_steps 10\n",
    "    --min_lr=1e-5\n",
    "    --smooth True\n",
    "    --patience 10\n",
    "    --factor 0.95\n",
    "    --fp16 True\n",
    "    --optim sgd\n",
    "\"\"\".split()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with patch.object(sys, \"argv\", testargs):\n",
    "    run_ner.main()\n",
    "    result = get_results(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff33a14-c3bf-4e9d-b2a1-b06e9082151d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alllogs = json.load(open(f'{tmp_dir}/trainer_state.json'))\n",
    "d2 = [ (l['step'], l['learning_rate'], l['loss']) for l in alllogs['log_history'][:-1] ]\n",
    "\n",
    "!rm -r {tmp_dir}\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b17c0-a916-4fe5-aca3-d7941246655a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,1]\n",
    "\n",
    "x2 = np.array(d2)[:,0] \n",
    "y2 = np.array(d2)[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_figheight(4)\n",
    "ax = fig.add_subplot(111)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('LRs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d081d889-fe76-4eb1-9929-2516536573e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x1 = np.array(d1)[:,0]\n",
    "y1 = np.array(d1)[:,2]\n",
    "\n",
    "x2 = np.array(d2)[:,0]\n",
    "y2 = np.array(d2)[:,2]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fig.set_figheight(4)\n",
    "line1, = ax.plot(x1, y1, 'b-', label='baseline')\n",
    "line2, = ax.plot(x2, y2, 'r-', label='GreedyLR')\n",
    "plt.legend()\n",
    "plt.title('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb029095-b388-4802-b5d4-43fa1a787665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(d1[-1][int(0.1*len(d1[-1]))-1] > d2[-1][int(0.1*len(d2[-1]))-1])\n",
    "# print(d1[-1][int(0.5*len(d1[-1]))-1] > d2[-1][int(0.5*len(d2[-1]))-1])\n",
    "# print(d1[-1][int(1*len(d1[-1]))-1] > d2[-1][int(1*len(d2[-1]))-1])\n",
    "\n",
    "\n",
    "d1[-1][-1] - d2[-1][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df4887-3e62-44aa-9e86-20effde50418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "SRC_DIRS = [\n",
    "    os.path.join('./', dirname) for dirname in [\n",
    "        \"text-generation\",\n",
    "        \"text-classification\",\n",
    "        \"token-classification\",\n",
    "        \"language-modeling\",\n",
    "        \"multiple-choice\",\n",
    "        \"question-answering\",\n",
    "        \"summarization\",\n",
    "        \"translation\",\n",
    "        \"image-classification\",\n",
    "        \"speech-recognition\",\n",
    "        \"audio-classification\",\n",
    "        \"speech-pretraining\",\n",
    "        \"image-pretraining\",\n",
    "        \"semantic-segmentation\",\n",
    "    ]\n",
    "]\n",
    "sys.path.extend(SRC_DIRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5bd42-3a1e-4492-a885-94c16bea8176",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a22c63d-c80d-42fd-941a-f3cce42bd534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g5.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
